{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 32,
    "train_loss": [
        1.8427693843841553,
        1.9008584022521973,
        1.9796161651611328,
        2.0255355834960938,
        2.0868279933929443,
        1.6827175617218018,
        2.0511837005615234,
        1.8193455934524536,
        1.7911568880081177,
        1.6060009002685547,
        1.5675050020217896,
        1.6851669549942017,
        1.6843069791793823,
        1.7681183815002441,
        1.589095115661621,
        1.7482038736343384,
        1.610899567604065,
        1.3667057752609253,
        1.583631157875061,
        1.7607043981552124,
        1.8450497388839722,
        1.3123568296432495,
        1.6103715896606445,
        1.6694852113723755,
        1.7345476150512695,
        1.7120413780212402,
        1.633772850036621,
        1.8332017660140991,
        1.772348403930664,
        1.4486356973648071,
        1.593096375465393,
        1.8613003492355347
    ],
    "val_loss": [
        1.793514370918274,
        1.588678002357483,
        1.5258830785751343,
        1.5890930891036987,
        1.7660068273544312,
        1.9941762685775757,
        2.216020107269287,
        2.374511957168579,
        2.4598777294158936,
        2.477674722671509,
        2.4662258625030518,
        2.43263840675354,
        2.3887548446655273,
        2.3416082859039307,
        2.2850916385650635,
        2.2559120655059814,
        2.2282841205596924,
        2.2021493911743164,
        2.176914691925049,
        2.156926155090332,
        2.140071153640747,
        2.133631706237793,
        2.1268372535705566,
        2.1213958263397217,
        2.117379665374756,
        2.1135220527648926,
        2.110316753387451,
        2.1082961559295654,
        2.1055619716644287,
        2.1028025150299072,
        2.099884271621704,
        2.0974581241607666,
        2.0949230194091797
    ],
    "train_accuracy": [
        0.3125,
        0.3125,
        0.25,
        0.0625,
        0.0625,
        0.375,
        0.1875,
        0.3125,
        0.1875,
        0.375,
        0.3125,
        0.3125,
        0.125,
        0.1875,
        0.1875,
        0.1875,
        0.25,
        0.4375,
        0.5,
        0.1875,
        0.1875,
        0.5,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.375,
        0.125,
        0.3125,
        0.3125,
        0.4375,
        0.125
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.5,
        0.4166666567325592,
        0.1666666716337204,
        0.0,
        0.0,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602
    ],
    "epoch_times": [
        0.24545741081237793,
        0.2029731273651123,
        0.20067477226257324,
        0.20055079460144043,
        0.20104670524597168,
        0.20177054405212402,
        0.20029139518737793,
        0.20151853561401367,
        0.2009730339050293,
        0.2005913257598877,
        0.20237517356872559,
        0.20275497436523438,
        0.2046525478363037,
        0.20193219184875488,
        0.201674222946167,
        0.20166707038879395,
        0.20162606239318848,
        0.20025944709777832,
        0.20038390159606934,
        0.2019672393798828,
        0.20245099067687988,
        0.20245885848999023,
        0.20202279090881348,
        0.20244860649108887,
        0.20245647430419922,
        0.20398759841918945,
        0.2005162239074707,
        0.20169663429260254,
        0.20195317268371582,
        0.2008371353149414,
        0.20149946212768555,
        0.19985270500183105
    ]
}