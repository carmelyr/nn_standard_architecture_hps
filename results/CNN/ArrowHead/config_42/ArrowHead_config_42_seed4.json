{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1089844650306,
        "kernel_size": 6,
        "learning_rate": 0.000216213952,
        "num_filters": 160,
        "num_layers": 5,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "ArrowHead",
        "train_size": 58,
        "val_size": 14,
        "input_shape": [
            1,
            251
        ],
        "num_classes": 3
    },
    "epochs": 31,
    "train_loss": [
        1.2653074264526367,
        0.7312557697296143,
        0.6112814545631409,
        0.4376623034477234,
        0.42197293043136597,
        0.35336625576019287,
        0.29779359698295593,
        0.2609862983226776,
        0.24855127930641174,
        0.2271423190832138,
        0.16372184455394745,
        0.19582900404930115,
        0.20375336706638336,
        0.22419430315494537,
        0.16014833748340607,
        0.12174297124147415,
        0.1030614823102951,
        0.11795669794082642,
        0.09116221219301224,
        0.11005441099405289,
        0.0691845640540123,
        0.06386688351631165,
        0.12022274732589722,
        0.035568587481975555,
        0.06272988021373749,
        0.034429196268320084,
        0.03591884672641754,
        0.06688395142555237,
        0.14332707226276398,
        0.02715606987476349,
        0.030505385249853134
    ],
    "val_loss": [
        1.0972741842269897,
        1.0977535247802734,
        1.0979859828948975,
        1.0981807708740234,
        1.0986710786819458,
        1.0997523069381714,
        1.1012967824935913,
        1.104000210762024,
        1.1082277297973633,
        1.1148067712783813,
        1.1234650611877441,
        1.1375761032104492,
        1.1595224142074585,
        1.1912766695022583,
        1.2342833280563354,
        1.2813130617141724,
        1.3519881963729858,
        1.4173742532730103,
        1.4973877668380737,
        1.6214591264724731,
        1.7809056043624878,
        1.9354139566421509,
        2.0102500915527344,
        2.170046091079712,
        2.405121326446533,
        2.583717107772827,
        2.6006827354431152,
        2.612231731414795,
        2.9056968688964844,
        2.9110608100891113,
        2.533442258834839,
        2.455040693283081
    ],
    "train_accuracy": [
        0.2931034564971924,
        0.6724137663841248,
        0.7413793206214905,
        0.8275862336158752,
        0.8448275923728943,
        0.8620689511299133,
        0.9137930870056152,
        0.931034505367279,
        0.8965517282485962,
        0.931034505367279,
        0.9482758641242981,
        0.931034505367279,
        0.9137930870056152,
        0.9482758641242981,
        0.9655172228813171,
        0.9655172228813171,
        0.9655172228813171,
        0.9655172228813171,
        0.982758641242981,
        0.9655172228813171,
        0.982758641242981,
        0.982758641242981,
        0.9482758641242981,
        1.0,
        0.982758641242981,
        1.0,
        1.0,
        0.9655172228813171,
        0.9482758641242981,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.3571428656578064,
        0.4285714626312256,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.4285714626312256,
        0.5,
        0.5,
        0.4285714626312256,
        0.4285714626312256,
        0.4285714626312256,
        0.4285714626312256,
        0.4285714626312256,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.3571428656578064,
        0.4285714626312256
    ],
    "epoch_times": [
        0.21267151832580566,
        0.024988174438476562,
        0.022770404815673828,
        0.0232086181640625,
        0.023838281631469727,
        0.025051116943359375,
        0.023825883865356445,
        0.02338886260986328,
        0.025598526000976562,
        0.023151874542236328,
        0.022906064987182617,
        0.02408146858215332,
        0.02297687530517578,
        0.023049116134643555,
        0.022283315658569336,
        0.022831439971923828,
        0.023378372192382812,
        0.02308964729309082,
        0.022543668746948242,
        0.0226900577545166,
        0.022465229034423828,
        0.023164033889770508,
        0.02318716049194336,
        0.02324843406677246,
        0.02379298210144043,
        0.023560762405395508,
        0.023472309112548828,
        0.02469158172607422,
        0.02348494529724121,
        0.0246274471282959,
        0.023812055587768555
    ]
}