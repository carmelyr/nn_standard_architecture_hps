{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0078882678643,
        "kernel_size": 5,
        "learning_rate": 0.0045123278898,
        "num_filters": 195,
        "num_layers": 3,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.7766844034194946,
        1.7297887802124023,
        1.1376475095748901,
        0.9020749926567078,
        0.7950034737586975,
        0.7553289532661438,
        0.7333000302314758,
        0.6357213854789734,
        0.5475847125053406,
        0.5155079364776611,
        0.4336930215358734,
        0.517158567905426,
        0.39623507857322693,
        0.6161622405052185,
        0.3939826488494873,
        0.39066120982170105,
        0.37311244010925293,
        0.3778876066207886,
        0.3236840069293976,
        0.31841662526130676,
        0.36820706725120544,
        0.3003968596458435,
        0.2312016636133194,
        0.31283441185951233,
        0.30701103806495667,
        0.3193649649620056,
        0.3897207975387573,
        0.25276437401771545,
        0.21266736090183258,
        0.24754850566387177,
        0.24601131677627563
    ],
    "val_loss": [
        1.6011037826538086,
        1.589394211769104,
        1.5910024642944336,
        1.6386966705322266,
        1.6637039184570312,
        1.6474138498306274,
        1.6822093725204468,
        1.6932802200317383,
        1.806970238685608,
        1.7653001546859741,
        1.6215249300003052,
        1.7261685132980347,
        1.932266116142273,
        1.972263216972351,
        2.01049542427063,
        2.1999363899230957,
        2.0276994705200195,
        2.091531991958618,
        2.11203670501709,
        1.8780258893966675,
        1.701174259185791,
        1.7127591371536255,
        1.7458213567733765,
        1.778952956199646,
        1.9141095876693726,
        1.996300220489502,
        2.4964687824249268,
        2.653676748275757,
        1.8121131658554077,
        1.7196999788284302,
        1.8158737421035767,
        1.914499282836914
    ],
    "train_accuracy": [
        0.2083333283662796,
        0.375,
        0.5625,
        0.6041666865348816,
        0.7708333134651184,
        0.7083333134651184,
        0.75,
        0.7291666865348816,
        0.7916666865348816,
        0.7916666865348816,
        0.875,
        0.7291666865348816,
        0.8333333134651184,
        0.8125,
        0.8541666865348816,
        0.9166666865348816,
        0.8958333134651184,
        0.8541666865348816,
        0.8541666865348816,
        0.8541666865348816,
        0.8125,
        0.8958333134651184,
        0.9375,
        0.875,
        0.875,
        0.875,
        0.8333333134651184,
        0.8958333134651184,
        0.9375,
        0.8541666865348816,
        0.9166666865348816
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.4166666567325592,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.3333333432674408,
        0.4166666567325592
    ],
    "epoch_times": [
        0.1912059783935547,
        0.04384183883666992,
        0.026520729064941406,
        0.03268766403198242,
        0.022918224334716797,
        0.02347397804260254,
        0.0228579044342041,
        0.02461981773376465,
        0.02244877815246582,
        0.022150754928588867,
        0.02150583267211914,
        0.022832155227661133,
        0.020800352096557617,
        0.02628803253173828,
        0.022130727767944336,
        0.02937483787536621,
        0.02192234992980957,
        0.022979259490966797,
        0.02233600616455078,
        0.021985292434692383,
        0.0281829833984375,
        0.023006200790405273,
        0.02211737632751465,
        0.02424454689025879,
        0.02502751350402832,
        0.02247142791748047,
        0.021590709686279297,
        0.02356433868408203,
        0.025735139846801758,
        0.023336410522460938,
        0.02238941192626953
    ]
}