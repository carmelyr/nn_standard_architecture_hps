{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1448636024401,
        "ff_dim": 331,
        "hidden_units": 347,
        "learning_rate": 1.84210549e-05,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 6.33151081e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 32,
    "train_loss": [
        3.0696640014648438,
        2.546846866607666,
        2.0268492698669434,
        2.1741342544555664,
        1.6006745100021362,
        1.4517080783843994,
        1.566031813621521,
        1.4848623275756836,
        1.4797002077102661,
        2.0903661251068115,
        1.6990944147109985,
        1.6573255062103271,
        1.399182915687561,
        1.6032540798187256,
        1.53404700756073,
        1.474510669708252,
        1.7613837718963623,
        1.796324610710144,
        1.5837210416793823,
        1.6945043802261353,
        1.8503745794296265,
        1.4786810874938965,
        1.626926302909851,
        1.3481521606445312,
        1.9252724647521973,
        1.4888830184936523,
        1.6118055582046509,
        1.5482966899871826,
        1.6164627075195312,
        1.7309834957122803,
        1.460807204246521,
        1.550395131111145
    ],
    "val_loss": [
        2.3299779891967773,
        1.9625482559204102,
        1.8274807929992676,
        1.861566424369812,
        1.9471454620361328,
        2.0806357860565186,
        2.249819040298462,
        2.3948311805725098,
        2.483098268508911,
        2.50107741355896,
        2.5005056858062744,
        2.4857499599456787,
        2.454923152923584,
        2.4174787998199463,
        2.373760461807251,
        2.3492648601531982,
        2.3229312896728516,
        2.298374891281128,
        2.271557331085205,
        2.2417027950286865,
        2.2154176235198975,
        2.203989267349243,
        2.192025899887085,
        2.1829230785369873,
        2.174478769302368,
        2.1675868034362793,
        2.161998748779297,
        2.1576929092407227,
        2.153947353363037,
        2.1512420177459717,
        2.1496474742889404,
        2.14745831489563,
        2.1451618671417236
    ],
    "train_accuracy": [
        0.0625,
        0.125,
        0.1875,
        0.0625,
        0.3125,
        0.4375,
        0.3125,
        0.3125,
        0.4375,
        0.125,
        0.4375,
        0.375,
        0.5,
        0.375,
        0.25,
        0.3125,
        0.1875,
        0.25,
        0.25,
        0.3125,
        0.25,
        0.5,
        0.25,
        0.4375,
        0.125,
        0.5,
        0.1875,
        0.3125,
        0.25,
        0.25,
        0.5,
        0.25
    ],
    "val_accuracy": [
        0.25,
        0.25,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.0833333358168602,
        0.25,
        0.25,
        0.25,
        0.25,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.18506264686584473,
        0.1770155429840088,
        0.17573261260986328,
        0.17884111404418945,
        0.17493343353271484,
        0.17595291137695312,
        0.17429471015930176,
        0.1750028133392334,
        0.1763765811920166,
        0.17842960357666016,
        0.17445611953735352,
        0.17546367645263672,
        0.17665743827819824,
        0.17569494247436523,
        0.17691469192504883,
        0.17618870735168457,
        0.17553329467773438,
        0.1743636131286621,
        0.17635893821716309,
        0.17600798606872559,
        0.17483854293823242,
        0.17554688453674316,
        0.17509174346923828,
        0.17569351196289062,
        0.17447686195373535,
        0.17548918724060059,
        0.17454934120178223,
        0.17483282089233398,
        0.1773848533630371,
        0.17591047286987305,
        0.17651748657226562,
        0.17571258544921875
    ]
}