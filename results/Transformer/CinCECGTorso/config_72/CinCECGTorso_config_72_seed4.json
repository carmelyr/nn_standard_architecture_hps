{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0740313187916,
        "ff_dim": 391,
        "hidden_units": 325,
        "learning_rate": 0.0001399254532,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 3.79775821e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        1.7282639741897583,
        1.326678991317749,
        1.4284594058990479,
        1.3266628980636597,
        1.3957655429840088,
        1.2650666236877441,
        1.6155292987823486,
        1.317752480506897,
        1.0505160093307495,
        0.8911715149879456,
        1.0917125940322876,
        0.9443739652633667,
        0.8108863234519958,
        0.6546318531036377,
        0.7281833291053772,
        0.9144648313522339,
        0.943462610244751,
        0.6057406067848206,
        0.7314659953117371,
        0.7832399010658264,
        0.4385339617729187,
        0.6750785112380981,
        0.5321088433265686,
        0.7739967703819275,
        0.5431623458862305,
        0.5493057370185852,
        0.6588668823242188,
        0.5636613368988037,
        0.40062958002090454,
        0.729782223701477,
        0.5012217164039612,
        0.3809617757797241,
        0.553244411945343,
        0.4431760907173157,
        0.4290274679660797
    ],
    "val_loss": [
        2.0318603515625,
        1.5165494680404663,
        1.3484456539154053,
        1.2451059818267822,
        1.2572444677352905,
        1.232972264289856,
        1.2505065202713013,
        1.4695241451263428,
        1.3222501277923584,
        1.31279456615448,
        1.5074334144592285,
        1.268604040145874,
        1.4565093517303467,
        1.6939401626586914,
        1.4994114637374878,
        1.5672080516815186,
        1.9196758270263672,
        1.688011646270752,
        1.6164681911468506,
        1.6531864404678345,
        1.7821124792099,
        1.8648542165756226,
        1.7889080047607422,
        1.739217758178711,
        1.8003015518188477,
        1.949232816696167,
        2.0036840438842773,
        2.001258134841919,
        1.9884006977081299,
        1.9980064630508423,
        1.9710382223129272,
        2.0137412548065186,
        2.042663812637329,
        2.0750246047973633,
        2.084115505218506,
        2.05855655670166
    ],
    "train_accuracy": [
        0.125,
        0.375,
        0.375,
        0.3125,
        0.375,
        0.1875,
        0.125,
        0.4375,
        0.5625,
        0.4375,
        0.5,
        0.5,
        0.75,
        0.625,
        0.625,
        0.5,
        0.5625,
        0.8125,
        0.625,
        0.6875,
        0.875,
        0.75,
        0.9375,
        0.625,
        0.8125,
        0.75,
        0.75,
        0.75,
        0.875,
        0.6875,
        0.9375,
        0.9375,
        0.75,
        0.75,
        0.8125
    ],
    "val_accuracy": [
        0.125,
        0.125,
        0.25,
        0.4375,
        0.375,
        0.4375,
        0.375,
        0.3125,
        0.5,
        0.3125,
        0.375,
        0.5,
        0.5,
        0.3125,
        0.5,
        0.5,
        0.375,
        0.4375,
        0.5625,
        0.5,
        0.4375,
        0.4375,
        0.4375,
        0.5,
        0.5,
        0.5,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375
    ],
    "epoch_times": [
        1.6729750633239746,
        1.6742277145385742,
        1.673570156097412,
        1.6732876300811768,
        1.6761445999145508,
        1.6764767169952393,
        1.6749444007873535,
        1.6777048110961914,
        1.6761126518249512,
        1.6748945713043213,
        1.6750271320343018,
        1.677441120147705,
        1.6758100986480713,
        1.6761150360107422,
        1.676882028579712,
        1.679001808166504,
        1.675513505935669,
        1.6780426502227783,
        1.6767535209655762,
        1.6795415878295898,
        1.6805026531219482,
        1.6799821853637695,
        1.6786377429962158,
        1.6773500442504883,
        1.6772656440734863,
        1.6803686618804932,
        1.6810369491577148,
        1.677306890487671,
        1.6786274909973145,
        1.6783182621002197,
        1.6800222396850586,
        1.679760456085205,
        1.6795597076416016,
        1.6800484657287598,
        1.6806528568267822
    ]
}