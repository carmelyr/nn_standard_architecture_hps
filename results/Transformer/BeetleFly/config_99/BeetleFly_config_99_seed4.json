{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1800727611378,
        "ff_dim": 262,
        "hidden_units": 108,
        "learning_rate": 0.0001524232413,
        "num_heads": 8,
        "num_layers": 3,
        "pooling": "max",
        "weight_decay": 8.98632135e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        1.6697176694869995,
        1.3717740774154663,
        1.0869677066802979,
        0.8384220600128174,
        0.8077054023742676,
        0.7110454440116882,
        0.9199638962745667,
        0.6725379228591919,
        0.9620238542556763,
        0.9367177486419678,
        0.7860342264175415,
        0.6814867854118347,
        0.77116459608078,
        0.7417246699333191,
        0.7184587717056274,
        0.7159168720245361,
        0.6442950963973999,
        0.5016177892684937,
        0.8142263889312744,
        0.6758304834365845,
        0.6802021265029907,
        0.7217727303504944,
        0.6446067690849304,
        0.8259764909744263,
        0.7528140544891357,
        0.7488711476325989,
        0.7963528037071228,
        0.6985366940498352,
        0.6901945471763611,
        0.5814768075942993,
        0.8056558966636658,
        0.8153505921363831,
        0.64766925573349,
        0.7924272418022156
    ],
    "val_loss": [
        2.0616047382354736,
        1.3381017446517944,
        0.8324804902076721,
        0.6006525158882141,
        0.5924311280250549,
        0.686493992805481,
        0.7630336880683899,
        0.812727689743042,
        0.8341004252433777,
        0.831043541431427,
        0.8014935851097107,
        0.7815954685211182,
        0.7543432116508484,
        0.7251871824264526,
        0.6958754658699036,
        0.66852867603302,
        0.6406635046005249,
        0.6291653513908386,
        0.6223514080047607,
        0.6151615381240845,
        0.6076402068138123,
        0.6024060249328613,
        0.5983027815818787,
        0.597055196762085,
        0.5966657996177673,
        0.5965226888656616,
        0.5972753167152405,
        0.5981433391571045,
        0.5997105836868286,
        0.6008837819099426,
        0.6017664670944214,
        0.6031526923179626,
        0.6045939922332764,
        0.6060050129890442,
        0.6073133945465088
    ],
    "train_accuracy": [
        0.53125,
        0.5625,
        0.5,
        0.53125,
        0.5,
        0.625,
        0.375,
        0.5625,
        0.46875,
        0.46875,
        0.53125,
        0.59375,
        0.6875,
        0.5,
        0.59375,
        0.5625,
        0.65625,
        0.75,
        0.46875,
        0.59375,
        0.53125,
        0.5625,
        0.65625,
        0.5625,
        0.59375,
        0.5625,
        0.46875,
        0.59375,
        0.5625,
        0.71875,
        0.5625,
        0.5,
        0.6875,
        0.5625
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.1741955280303955,
        0.05306243896484375,
        0.05115699768066406,
        0.051377296447753906,
        0.05164504051208496,
        0.05282783508300781,
        0.05322575569152832,
        0.05441117286682129,
        0.05280494689941406,
        0.05295896530151367,
        0.05405163764953613,
        0.05573844909667969,
        0.05486750602722168,
        0.055857181549072266,
        0.05448627471923828,
        0.05789470672607422,
        0.05504465103149414,
        0.055265188217163086,
        0.05539989471435547,
        0.05473136901855469,
        0.05574345588684082,
        0.05592775344848633,
        0.055230140686035156,
        0.05521583557128906,
        0.05588936805725098,
        0.05537867546081543,
        0.05523967742919922,
        0.05474734306335449,
        0.0553286075592041,
        0.05536341667175293,
        0.05506587028503418,
        0.05545496940612793,
        0.05510544776916504,
        0.05537605285644531
    ]
}