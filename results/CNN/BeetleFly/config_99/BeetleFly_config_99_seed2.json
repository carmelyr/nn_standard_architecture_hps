{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1094612738984,
        "kernel_size": 5,
        "learning_rate": 0.0094414308661,
        "num_filters": 213,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 33,
    "train_loss": [
        0.7670661211013794,
        0.6634711623191833,
        0.2911924421787262,
        0.2618004083633423,
        0.21112625300884247,
        0.15780559182167053,
        0.11866927891969681,
        0.09832166135311127,
        0.09392397850751877,
        0.06127793714404106,
        0.05656900629401207,
        0.048384275287389755,
        0.03392058238387108,
        0.04358351230621338,
        0.02248532511293888,
        0.023714693263173103,
        0.011634261347353458,
        0.007841771468520164,
        0.010940694250166416,
        0.005841200239956379,
        0.006842463742941618,
        0.005174688529223204,
        0.004461605567485094,
        0.009160560555756092,
        0.0035166400484740734,
        0.0020024951081722975,
        0.002987427171319723,
        0.0029152657371014357,
        0.0034456606954336166,
        0.003315604291856289,
        0.0012081030290573835,
        0.0011162299197167158,
        0.0011436790227890015
    ],
    "val_loss": [
        0.663630485534668,
        0.9016987681388855,
        0.7775518894195557,
        0.7461009621620178,
        1.1694514751434326,
        1.6590237617492676,
        2.156466007232666,
        2.5185110569000244,
        2.7475504875183105,
        2.868682861328125,
        2.9654617309570312,
        3.0927846431732178,
        3.2672109603881836,
        3.4337520599365234,
        3.57062029838562,
        3.6753857135772705,
        3.7924351692199707,
        3.8693509101867676,
        3.9361138343811035,
        3.976865768432617,
        4.000461578369141,
        4.020289421081543,
        4.036444664001465,
        4.039809703826904,
        4.054738998413086,
        4.072426795959473,
        4.091113090515137,
        4.109983444213867,
        4.128821849822998,
        4.158734321594238,
        4.205600738525391,
        4.25127649307251,
        4.295915603637695,
        4.337912559509277
    ],
    "train_accuracy": [
        0.46875,
        0.75,
        0.90625,
        0.84375,
        0.90625,
        1.0,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.18405866622924805,
        0.057512521743774414,
        0.021335840225219727,
        0.02065730094909668,
        0.019916534423828125,
        0.019655942916870117,
        0.018655776977539062,
        0.019582748413085938,
        0.021869421005249023,
        0.022811412811279297,
        0.019813060760498047,
        0.018792152404785156,
        0.0209503173828125,
        0.019470691680908203,
        0.018915176391601562,
        0.01924300193786621,
        0.02057623863220215,
        0.022298812866210938,
        0.01917576789855957,
        0.021529436111450195,
        0.02073979377746582,
        0.022434234619140625,
        0.01999640464782715,
        0.016704320907592773,
        0.017400026321411133,
        0.021290063858032227,
        0.01715993881225586,
        0.017137527465820312,
        0.016657114028930664,
        0.016866207122802734,
        0.016786575317382812,
        0.016436338424682617,
        0.022608041763305664
    ]
}