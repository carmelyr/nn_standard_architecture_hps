{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0927954665632,
        "ff_dim": 704,
        "hidden_units": 480,
        "learning_rate": 4.09657925e-05,
        "num_heads": 7,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 3.9851944e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 38,
    "train_loss": [
        1.3592851161956787,
        0.7691137790679932,
        1.0097776651382446,
        1.1832979917526245,
        0.9360576868057251,
        0.7978124618530273,
        0.6677812933921814,
        0.6770110130310059,
        0.8392642140388489,
        0.838625967502594,
        0.7269592881202698,
        0.6699580550193787,
        0.7795792818069458,
        0.8319844007492065,
        0.6758750081062317,
        0.6204471588134766,
        0.6304642558097839,
        0.7543233633041382,
        0.6773275136947632,
        0.7237375378608704,
        0.7157799601554871,
        0.6241307854652405,
        0.6387853622436523,
        0.6409673094749451,
        0.6274470686912537,
        0.7513741850852966,
        0.5703447461128235,
        0.5857443809509277,
        0.6161929368972778,
        0.6846388578414917,
        0.633140504360199,
        0.6089800000190735,
        0.639751672744751,
        0.7898837327957153,
        0.6871684193611145,
        0.6090624928474426,
        0.6135579943656921,
        0.6056232452392578
    ],
    "val_loss": [
        1.1634480953216553,
        0.8209003210067749,
        2.174586057662964,
        2.4175662994384766,
        2.040318727493286,
        1.3844256401062012,
        0.81259685754776,
        0.6726177930831909,
        0.6693994402885437,
        0.7323769927024841,
        0.8703643083572388,
        1.0176891088485718,
        1.1668280363082886,
        1.1806864738464355,
        1.067469835281372,
        0.9875041842460632,
        0.9173322916030884,
        0.876630425453186,
        0.8817408084869385,
        0.8936235904693604,
        0.9200737476348877,
        0.9284733533859253,
        0.9343219995498657,
        0.9405394196510315,
        0.9316158890724182,
        0.9235028624534607,
        0.921044647693634,
        0.9195704460144043,
        0.9195530414581299,
        0.9203199744224548,
        0.9186363220214844,
        0.9207367300987244,
        0.9173414707183838,
        0.9194245338439941,
        0.922577977180481,
        0.9264128804206848,
        0.9328528642654419,
        0.936639130115509,
        0.9404845237731934
    ],
    "train_accuracy": [
        0.46875,
        0.40625,
        0.59375,
        0.5625,
        0.59375,
        0.5,
        0.625,
        0.65625,
        0.46875,
        0.40625,
        0.53125,
        0.65625,
        0.53125,
        0.46875,
        0.65625,
        0.6875,
        0.71875,
        0.46875,
        0.5625,
        0.5625,
        0.53125,
        0.625,
        0.65625,
        0.625,
        0.5625,
        0.34375,
        0.625,
        0.65625,
        0.59375,
        0.625,
        0.6875,
        0.5625,
        0.59375,
        0.5625,
        0.53125,
        0.75,
        0.71875,
        0.625
    ],
    "val_accuracy": [
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.75,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.18580937385559082,
        0.15921378135681152,
        0.15837788581848145,
        0.15890932083129883,
        0.15909242630004883,
        0.15868711471557617,
        0.15960907936096191,
        0.15868520736694336,
        0.15694093704223633,
        0.16018986701965332,
        0.15944242477416992,
        0.15837836265563965,
        0.1594841480255127,
        0.1599433422088623,
        0.17166566848754883,
        0.16312384605407715,
        0.16245722770690918,
        0.16030359268188477,
        0.15926074981689453,
        0.16304731369018555,
        0.16133856773376465,
        0.15860557556152344,
        0.1700136661529541,
        0.1597762107849121,
        0.16013503074645996,
        0.15862655639648438,
        0.15753793716430664,
        0.16041207313537598,
        0.15879082679748535,
        0.16312050819396973,
        0.16060447692871094,
        0.1617259979248047,
        0.1616072654724121,
        0.15749692916870117,
        0.15694332122802734,
        0.1632833480834961,
        0.16358232498168945,
        0.16028404235839844
    ]
}