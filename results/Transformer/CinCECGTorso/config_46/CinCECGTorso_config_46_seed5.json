{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.27932214181,
        "ff_dim": 639,
        "hidden_units": 208,
        "learning_rate": 1.02616986e-05,
        "num_heads": 5,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 8.28719202e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 34,
    "train_loss": [
        1.965962529182434,
        2.3505709171295166,
        1.416910171508789,
        1.8080545663833618,
        1.8805466890335083,
        1.3516746759414673,
        1.7316744327545166,
        1.6512800455093384,
        1.5785751342773438,
        1.4068044424057007,
        1.7715575695037842,
        1.6660921573638916,
        1.716044306755066,
        1.5601680278778076,
        1.4180891513824463,
        1.3919377326965332,
        1.5140094757080078,
        1.619941234588623,
        1.5720669031143188,
        1.5552356243133545,
        1.8099644184112549,
        1.2449934482574463,
        1.679815411567688,
        1.44997239112854,
        1.4504255056381226,
        1.5001424551010132,
        1.3102983236312866,
        1.3454636335372925,
        1.7496743202209473,
        1.8460726737976074,
        1.6057394742965698,
        1.6508246660232544,
        1.6706746816635132,
        1.4652824401855469
    ],
    "val_loss": [
        1.5351020097732544,
        1.424208164215088,
        1.3407526016235352,
        1.2778139114379883,
        1.2591744661331177,
        1.276140809059143,
        1.3319296836853027,
        1.4192017316818237,
        1.501975655555725,
        1.5976650714874268,
        1.7080878019332886,
        1.7561832666397095,
        1.8057690858840942,
        1.8548328876495361,
        1.9091682434082031,
        1.9432240724563599,
        1.9743458032608032,
        1.993533968925476,
        2.00951886177063,
        2.027696132659912,
        2.042067050933838,
        2.0581369400024414,
        2.0683302879333496,
        2.0729568004608154,
        2.0781421661376953,
        2.0826852321624756,
        2.0871083736419678,
        2.0913281440734863,
        2.097978115081787,
        2.1009535789489746,
        2.1049530506134033,
        2.1081957817077637,
        2.1095142364501953,
        2.1118040084838867,
        2.113961935043335
    ],
    "train_accuracy": [
        0.1875,
        0.125,
        0.5,
        0.25,
        0.25,
        0.4375,
        0.25,
        0.125,
        0.125,
        0.375,
        0.25,
        0.125,
        0.0625,
        0.25,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.25,
        0.375,
        0.3125,
        0.3125,
        0.1875,
        0.25,
        0.25,
        0.3125,
        0.4375,
        0.375,
        0.125,
        0.1875,
        0.25,
        0.125,
        0.3125,
        0.1875
    ],
    "val_accuracy": [
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.1875,
        0.1875,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125
    ],
    "epoch_times": [
        1.2239933013916016,
        1.2229199409484863,
        1.2201998233795166,
        1.2281959056854248,
        1.2230498790740967,
        1.218930959701538,
        1.2200343608856201,
        1.2204809188842773,
        1.2195944786071777,
        1.2193615436553955,
        1.223294734954834,
        1.2207221984863281,
        1.2191588878631592,
        1.2209053039550781,
        1.2209806442260742,
        1.2205591201782227,
        1.2195439338684082,
        1.2199690341949463,
        1.2205841541290283,
        1.2230281829833984,
        1.2196369171142578,
        1.2199110984802246,
        1.2209746837615967,
        1.2198314666748047,
        1.2196424007415771,
        1.2210772037506104,
        1.2222135066986084,
        1.2269580364227295,
        1.2215056419372559,
        1.2205100059509277,
        1.220836877822876,
        1.2223625183105469,
        1.2224366664886475,
        1.2210819721221924
    ]
}