{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1745348366843,
        "ff_dim": 385,
        "hidden_units": 161,
        "learning_rate": 1.39996323e-05,
        "num_heads": 3,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 7.0120995e-06
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 32,
    "train_loss": [
        1.5279085636138916,
        1.523862600326538,
        1.755724549293518,
        1.338500738143921,
        1.4682565927505493,
        1.6506961584091187,
        1.3585280179977417,
        1.5876892805099487,
        1.3626251220703125,
        1.2778544425964355,
        1.458543300628662,
        1.4215136766433716,
        1.4832690954208374,
        1.3883336782455444,
        1.4066752195358276,
        1.2672934532165527,
        1.2783483266830444,
        1.4796864986419678,
        1.1856465339660645,
        1.2626631259918213,
        1.576831579208374,
        1.4582016468048096,
        1.336116075515747,
        1.4606331586837769,
        1.4610981941223145,
        1.4249838590621948,
        1.5944995880126953,
        1.4745901823043823,
        1.306364893913269,
        1.2647908926010132,
        1.4997615814208984,
        1.3474669456481934
    ],
    "val_loss": [
        1.3831651210784912,
        1.382502555847168,
        1.377089023590088,
        1.3849289417266846,
        1.402116298675537,
        1.4212093353271484,
        1.4271314144134521,
        1.425991177558899,
        1.4215736389160156,
        1.4210559129714966,
        1.422079086303711,
        1.4222216606140137,
        1.4242204427719116,
        1.4268369674682617,
        1.4322105646133423,
        1.4357725381851196,
        1.4385032653808594,
        1.4372152090072632,
        1.4397211074829102,
        1.4394984245300293,
        1.4391080141067505,
        1.4396125078201294,
        1.4404313564300537,
        1.439175009727478,
        1.439892053604126,
        1.4402049779891968,
        1.440186858177185,
        1.440069317817688,
        1.4401822090148926,
        1.4404044151306152,
        1.4404765367507935,
        1.4404100179672241,
        1.4398980140686035
    ],
    "train_accuracy": [
        0.25,
        0.3125,
        0.3125,
        0.4375,
        0.3125,
        0.3125,
        0.1875,
        0.3125,
        0.3125,
        0.4375,
        0.375,
        0.25,
        0.1875,
        0.1875,
        0.4375,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.4375,
        0.1875,
        0.1875,
        0.4375,
        0.375,
        0.25,
        0.375,
        0.25,
        0.3125,
        0.375,
        0.5,
        0.3125,
        0.5
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.3125,
        0.25,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125
    ],
    "epoch_times": [
        0.37112998962402344,
        0.3215675354003906,
        0.3218238353729248,
        0.3235630989074707,
        0.3240494728088379,
        0.3228933811187744,
        0.3217601776123047,
        0.3222846984863281,
        0.3214881420135498,
        0.32299304008483887,
        0.3208131790161133,
        0.3243391513824463,
        0.32367801666259766,
        0.32254600524902344,
        0.32741856575012207,
        0.32192206382751465,
        0.3233470916748047,
        0.32330846786499023,
        0.3231377601623535,
        0.32235193252563477,
        0.3225083351135254,
        0.32269811630249023,
        0.32416796684265137,
        0.3228933811187744,
        0.32190704345703125,
        0.3237879276275635,
        0.32576704025268555,
        0.3224508762359619,
        0.32277536392211914,
        0.3236823081970215,
        0.32543516159057617,
        0.32335829734802246
    ]
}