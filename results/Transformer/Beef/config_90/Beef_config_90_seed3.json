{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2078706140663,
        "ff_dim": 417,
        "hidden_units": 309,
        "learning_rate": 0.0001992767244,
        "num_heads": 3,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 3.60552825e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 34,
    "train_loss": [
        1.8822335004806519,
        2.1040074825286865,
        1.6100142002105713,
        1.6134018898010254,
        1.8585069179534912,
        1.4789042472839355,
        1.7357475757598877,
        1.7939413785934448,
        1.4959431886672974,
        1.7120012044906616,
        1.501554012298584,
        1.313313364982605,
        1.2543784379959106,
        1.431471824645996,
        1.6427841186523438,
        1.3140043020248413,
        1.4790735244750977,
        1.4415236711502075,
        1.267122507095337,
        1.3816635608673096,
        1.4169962406158447,
        0.8779053688049316,
        1.3703569173812866,
        1.2019199132919312,
        1.3664350509643555,
        1.3956748247146606,
        1.3421002626419067,
        0.7636624574661255,
        1.0026689767837524,
        1.435133934020996,
        1.1250560283660889,
        0.907543420791626,
        1.6334861516952515,
        1.2615904808044434
    ],
    "val_loss": [
        2.4288833141326904,
        2.876173257827759,
        4.02427339553833,
        2.0971641540527344,
        1.3965067863464355,
        1.4257698059082031,
        1.9479938745498657,
        2.324734926223755,
        2.3012616634368896,
        2.015568494796753,
        1.7916399240493774,
        1.6798051595687866,
        1.612882137298584,
        1.6492840051651,
        1.8186893463134766,
        2.0304417610168457,
        2.001298189163208,
        1.9074444770812988,
        1.804888367652893,
        1.7244234085083008,
        1.6901354789733887,
        1.7202867269515991,
        1.7674952745437622,
        1.7651714086532593,
        1.7733945846557617,
        1.780403971672058,
        1.7878750562667847,
        1.7980469465255737,
        1.810867428779602,
        1.8157716989517212,
        1.8191231489181519,
        1.8210474252700806,
        1.8276232481002808,
        1.8332802057266235,
        1.8354533910751343
    ],
    "train_accuracy": [
        0.25,
        0.125,
        0.375,
        0.4375,
        0.125,
        0.4375,
        0.3125,
        0.25,
        0.25,
        0.375,
        0.3125,
        0.4375,
        0.5,
        0.375,
        0.3125,
        0.375,
        0.5,
        0.5,
        0.4375,
        0.625,
        0.4375,
        0.8125,
        0.5625,
        0.5625,
        0.5625,
        0.4375,
        0.3125,
        0.6875,
        0.625,
        0.4375,
        0.5625,
        0.5625,
        0.4375,
        0.5625
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.3333333432674408,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.0833333358168602,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.3333333432674408,
        0.25,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592
    ],
    "epoch_times": [
        0.3411741256713867,
        0.15758180618286133,
        0.1541304588317871,
        0.15467619895935059,
        0.15457987785339355,
        0.15605878829956055,
        0.155989408493042,
        0.15503621101379395,
        0.15515398979187012,
        0.15552663803100586,
        0.15766191482543945,
        0.15466690063476562,
        0.1555321216583252,
        0.15447592735290527,
        0.1546790599822998,
        0.15579795837402344,
        0.15751290321350098,
        0.15679693222045898,
        0.15633440017700195,
        0.15577006340026855,
        0.15642404556274414,
        0.15817856788635254,
        0.16012883186340332,
        0.15575480461120605,
        0.15397286415100098,
        0.1570754051208496,
        0.1537642478942871,
        0.15491771697998047,
        0.15614795684814453,
        0.15464162826538086,
        0.1545882225036621,
        0.15459394454956055,
        0.15534305572509766,
        0.15628290176391602
    ]
}