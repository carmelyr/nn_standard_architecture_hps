{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.068110276744,
        "ff_dim": 279,
        "hidden_units": 444,
        "learning_rate": 1.63705046e-05,
        "num_heads": 8,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 2.56177413e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 34,
    "train_loss": [
        2.098510503768921,
        1.8774664402008057,
        1.6558949947357178,
        1.303300142288208,
        1.8081836700439453,
        1.2585883140563965,
        1.3254047632217407,
        1.202531337738037,
        1.4405829906463623,
        1.1586471796035767,
        1.2648557424545288,
        1.2871063947677612,
        1.1819396018981934,
        1.1713095903396606,
        1.2802369594573975,
        1.1650431156158447,
        1.4110660552978516,
        1.3777917623519897,
        1.2904701232910156,
        1.2656230926513672,
        1.0814751386642456,
        1.1687251329421997,
        0.9865610003471375,
        1.3823809623718262,
        1.0563762187957764,
        0.9981943368911743,
        1.0782986879348755,
        1.0357977151870728,
        1.0831547975540161,
        1.2359750270843506,
        1.2351949214935303,
        1.356911063194275,
        1.1065706014633179,
        1.293434977531433
    ],
    "val_loss": [
        2.6773931980133057,
        2.199594497680664,
        1.7869375944137573,
        1.5037161111831665,
        1.4664692878723145,
        1.512351393699646,
        1.5545412302017212,
        1.6236834526062012,
        1.6427632570266724,
        1.6295710802078247,
        1.6102646589279175,
        1.6004667282104492,
        1.610906720161438,
        1.6234321594238281,
        1.6482065916061401,
        1.6713231801986694,
        1.6875663995742798,
        1.7034517526626587,
        1.7136651277542114,
        1.7306166887283325,
        1.7448034286499023,
        1.7636557817459106,
        1.7841981649398804,
        1.787073016166687,
        1.7852911949157715,
        1.7820119857788086,
        1.7767521142959595,
        1.7773809432983398,
        1.774646282196045,
        1.774917483329773,
        1.773553490638733,
        1.7745219469070435,
        1.7738631963729858,
        1.77239990234375,
        1.7709013223648071
    ],
    "train_accuracy": [
        0.3125,
        0.1875,
        0.375,
        0.625,
        0.1875,
        0.375,
        0.375,
        0.5625,
        0.3125,
        0.5625,
        0.375,
        0.25,
        0.3125,
        0.5,
        0.4375,
        0.4375,
        0.4375,
        0.25,
        0.4375,
        0.5625,
        0.5,
        0.4375,
        0.6875,
        0.375,
        0.5,
        0.625,
        0.5,
        0.5,
        0.5625,
        0.4375,
        0.375,
        0.5,
        0.5,
        0.3125
    ],
    "val_accuracy": [
        0.0833333358168602,
        0.0833333358168602,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.4166666567325592,
        0.5,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592
    ],
    "epoch_times": [
        0.4066193103790283,
        0.2694973945617676,
        0.266542911529541,
        0.26712608337402344,
        0.2674272060394287,
        0.2679104804992676,
        0.27098870277404785,
        0.266937255859375,
        0.26777219772338867,
        0.26672887802124023,
        0.26775431632995605,
        0.26845669746398926,
        0.2675042152404785,
        0.2679026126861572,
        0.26784682273864746,
        0.2671070098876953,
        0.26812195777893066,
        0.26915407180786133,
        0.2648608684539795,
        0.2653694152832031,
        0.2682766914367676,
        0.26792263984680176,
        0.265516996383667,
        0.2655494213104248,
        0.2683248519897461,
        0.26683616638183594,
        0.26777076721191406,
        0.26679134368896484,
        0.26685452461242676,
        0.26584315299987793,
        0.26587724685668945,
        0.26845669746398926,
        0.2662785053253174,
        0.2668430805206299
    ]
}