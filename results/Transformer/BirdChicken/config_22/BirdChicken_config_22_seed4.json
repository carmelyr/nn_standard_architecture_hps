{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1909034723157,
        "ff_dim": 962,
        "hidden_units": 194,
        "learning_rate": 0.0005101409637,
        "num_heads": 6,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 6.5419984e-05
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        1.17673921585083,
        3.1663901805877686,
        1.0372016429901123,
        1.101792812347412,
        0.6595503091812134,
        0.8595736026763916,
        0.7877908945083618,
        0.7364007830619812,
        0.7423173785209656,
        0.7363591194152832,
        0.801176130771637,
        0.7718558311462402,
        1.0137826204299927,
        0.7815164923667908,
        0.7357457876205444,
        0.9386743903160095,
        0.7238686084747314,
        0.714396595954895,
        0.8955070376396179,
        0.684769332408905,
        0.7313013076782227,
        0.6931906342506409,
        0.7700267434120178,
        0.7243191599845886,
        0.7218489050865173,
        0.6913095712661743,
        0.6725804805755615,
        0.6815252304077148,
        0.6225083470344543,
        0.6783050298690796,
        0.7884789109230042,
        0.6324188709259033,
        0.9170384407043457,
        0.6077804565429688,
        0.6959523558616638,
        0.6584724187850952
    ],
    "val_loss": [
        0.9422795176506042,
        4.733535289764404,
        0.9421964883804321,
        0.8546313643455505,
        0.8442022204399109,
        0.8773617148399353,
        0.674058198928833,
        0.6763060092926025,
        0.6744861602783203,
        0.899404764175415,
        0.8718770742416382,
        0.7162142395973206,
        0.6742348670959473,
        0.6752142310142517,
        0.6822192668914795,
        0.7407429218292236,
        0.7950077056884766,
        0.7941007614135742,
        0.7483788728713989,
        0.7311123013496399,
        0.7167662978172302,
        0.6992586255073547,
        0.6979215145111084,
        0.7033761739730835,
        0.7210235595703125,
        0.7360512018203735,
        0.7494096159934998,
        0.7640430927276611,
        0.7745722532272339,
        0.7771884799003601,
        0.7721751928329468,
        0.7671913504600525,
        0.7576422691345215,
        0.7460545301437378,
        0.7331361770629883,
        0.721626341342926,
        0.7104898691177368
    ],
    "train_accuracy": [
        0.46875,
        0.53125,
        0.4375,
        0.46875,
        0.59375,
        0.5625,
        0.46875,
        0.5625,
        0.5,
        0.5625,
        0.59375,
        0.5,
        0.40625,
        0.59375,
        0.5625,
        0.46875,
        0.5,
        0.4375,
        0.4375,
        0.5625,
        0.625,
        0.5625,
        0.5,
        0.5,
        0.5625,
        0.65625,
        0.625,
        0.625,
        0.59375,
        0.59375,
        0.53125,
        0.6875,
        0.4375,
        0.59375,
        0.5625,
        0.625
    ],
    "val_accuracy": [
        0.625,
        0.375,
        0.375,
        0.625,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.625,
        0.5,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.1349174976348877,
        0.13042593002319336,
        0.1304340362548828,
        0.1304185390472412,
        0.1315615177154541,
        0.1314072608947754,
        0.132246732711792,
        0.13117694854736328,
        0.13238859176635742,
        0.13199329376220703,
        0.13177156448364258,
        0.13315796852111816,
        0.1313624382019043,
        0.13124608993530273,
        0.13136053085327148,
        0.13210105895996094,
        0.1311490535736084,
        0.13181114196777344,
        0.13137602806091309,
        0.13172483444213867,
        0.13180136680603027,
        0.13191914558410645,
        0.13143372535705566,
        0.13191986083984375,
        0.13151025772094727,
        0.13159465789794922,
        0.1317272186279297,
        0.13159728050231934,
        0.13205885887145996,
        0.13128900527954102,
        0.13225984573364258,
        0.13149738311767578,
        0.13128376007080078,
        0.13110804557800293,
        0.13141441345214844,
        0.13138079643249512
    ]
}