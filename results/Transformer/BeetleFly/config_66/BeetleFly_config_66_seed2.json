{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1448636024401,
        "ff_dim": 331,
        "hidden_units": 347,
        "learning_rate": 1.84210549e-05,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 6.33151081e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.6964195370674133,
        0.7260541319847107,
        0.7926746606826782,
        0.7308436632156372,
        0.8669462203979492,
        0.7695290446281433,
        0.7933937311172485,
        0.6823747754096985,
        0.6478235721588135,
        0.6919988989830017,
        0.6561042070388794,
        0.8380419015884399,
        0.7654044032096863,
        0.8917827010154724,
        0.7789902091026306,
        0.5999902486801147,
        0.6827294230461121,
        0.7422424554824829,
        0.8712359070777893,
        0.7545633912086487,
        0.8443804979324341,
        0.7941935062408447,
        0.5927335023880005,
        0.7261538505554199,
        0.6452615857124329,
        0.7584791779518127,
        0.7468778491020203,
        0.80470871925354,
        0.6578444838523865,
        0.6906511187553406,
        0.8446787595748901
    ],
    "val_loss": [
        1.0071921348571777,
        0.9368718862533569,
        0.9886566996574402,
        1.0695576667785645,
        1.1102999448776245,
        1.1620569229125977,
        1.1765567064285278,
        1.1960678100585938,
        1.207673192024231,
        1.2163169384002686,
        1.227918267250061,
        1.232840895652771,
        1.2317520380020142,
        1.2239130735397339,
        1.2175991535186768,
        1.209296464920044,
        1.2037713527679443,
        1.1966394186019897,
        1.1910152435302734,
        1.1857149600982666,
        1.1824994087219238,
        1.1780742406845093,
        1.1740535497665405,
        1.1700774431228638,
        1.1664952039718628,
        1.1628353595733643,
        1.161285400390625,
        1.160263180732727,
        1.1589657068252563,
        1.1576162576675415,
        1.1560759544372559,
        1.1546138525009155
    ],
    "train_accuracy": [
        0.65625,
        0.5625,
        0.46875,
        0.53125,
        0.40625,
        0.53125,
        0.5625,
        0.65625,
        0.53125,
        0.59375,
        0.65625,
        0.53125,
        0.4375,
        0.53125,
        0.53125,
        0.625,
        0.625,
        0.65625,
        0.46875,
        0.59375,
        0.59375,
        0.5625,
        0.78125,
        0.53125,
        0.6875,
        0.53125,
        0.53125,
        0.5,
        0.65625,
        0.53125,
        0.40625
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.19230294227600098,
        0.1338040828704834,
        0.13226008415222168,
        0.13344168663024902,
        0.13348388671875,
        0.13260531425476074,
        0.1334841251373291,
        0.13344192504882812,
        0.13258981704711914,
        0.13320398330688477,
        0.13277626037597656,
        0.1333169937133789,
        0.13258814811706543,
        0.13253140449523926,
        0.13332796096801758,
        0.13232088088989258,
        0.13443756103515625,
        0.13209939002990723,
        0.13315439224243164,
        0.13449501991271973,
        0.1318359375,
        0.13393878936767578,
        0.13277769088745117,
        0.13356804847717285,
        0.13344907760620117,
        0.13345122337341309,
        0.135009765625,
        0.13422179222106934,
        0.13361787796020508,
        0.13340306282043457,
        0.13242840766906738
    ]
}