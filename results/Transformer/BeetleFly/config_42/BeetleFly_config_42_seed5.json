{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.0403092744102,
        "ff_dim": 422,
        "hidden_units": 132,
        "learning_rate": 0.0007862395322,
        "num_heads": 8,
        "num_layers": 1,
        "pooling": "max",
        "weight_decay": 4.12806002e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8129262924194336,
        0.8481352925300598,
        0.7299399375915527,
        0.7184739112854004,
        0.5748679637908936,
        0.7140153646469116,
        0.55251145362854,
        0.5871390700340271,
        0.6073651909828186,
        0.5489979982376099,
        0.5319448709487915,
        0.577441394329071,
        0.5496816635131836,
        0.4922289252281189,
        0.513371467590332,
        0.47857367992401123,
        0.4327682554721832,
        0.5090859532356262,
        0.40571725368499756,
        0.4583059549331665,
        0.38484978675842285,
        0.4076062738895416,
        0.41687288880348206,
        0.41278693079948425,
        0.4120122492313385,
        0.47532621026039124,
        0.37210333347320557,
        0.38548052310943604,
        0.5068022608757019,
        0.40053296089172363,
        0.376488596200943,
        0.37798064947128296
    ],
    "val_loss": [
        0.6911134123802185,
        1.2031465768814087,
        0.9157254099845886,
        0.9895771741867065,
        1.0759724378585815,
        1.117538332939148,
        1.1453230381011963,
        1.2178786993026733,
        1.298675537109375,
        1.3099534511566162,
        1.3367486000061035,
        1.3469229936599731,
        1.3484066724777222,
        1.3582112789154053,
        1.3712546825408936,
        1.3842576742172241,
        1.3929203748703003,
        1.4044551849365234,
        1.409157633781433,
        1.4165427684783936,
        1.4118202924728394,
        1.4092298746109009,
        1.4098925590515137,
        1.4128363132476807,
        1.4181467294692993,
        1.4278470277786255,
        1.4368327856063843,
        1.4396631717681885,
        1.4411568641662598,
        1.4438817501068115,
        1.4480453729629517,
        1.452277421951294,
        1.4541914463043213
    ],
    "train_accuracy": [
        0.40625,
        0.53125,
        0.5625,
        0.5625,
        0.65625,
        0.4375,
        0.6875,
        0.59375,
        0.75,
        0.59375,
        0.6875,
        0.6875,
        0.71875,
        0.78125,
        0.65625,
        0.78125,
        0.84375,
        0.71875,
        0.84375,
        0.8125,
        0.90625,
        0.71875,
        0.8125,
        0.90625,
        0.8125,
        0.78125,
        0.96875,
        0.84375,
        0.84375,
        0.84375,
        0.90625,
        0.875
    ],
    "val_accuracy": [
        0.625,
        0.25,
        0.625,
        0.625,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.08693337440490723,
        0.03055119514465332,
        0.02769756317138672,
        0.026288270950317383,
        0.026773452758789062,
        0.027545690536499023,
        0.025776147842407227,
        0.025415897369384766,
        0.025859355926513672,
        0.02687525749206543,
        0.02627873420715332,
        0.026953697204589844,
        0.026325225830078125,
        0.025706052780151367,
        0.037581682205200195,
        0.026595354080200195,
        0.026185035705566406,
        0.026388168334960938,
        0.02748560905456543,
        0.02582836151123047,
        0.027313947677612305,
        0.026648521423339844,
        0.027138233184814453,
        0.026550769805908203,
        0.02766132354736328,
        0.027045249938964844,
        0.026517629623413086,
        0.029981136322021484,
        0.02612590789794922,
        0.026392459869384766,
        0.02726888656616211,
        0.028421401977539062
    ]
}