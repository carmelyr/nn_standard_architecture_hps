{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0003685288085,
        "ff_dim": 346,
        "hidden_units": 357,
        "learning_rate": 0.0002554062303,
        "num_heads": 3,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 7.3808537e-06
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        1.6137890815734863,
        1.345682144165039,
        1.1882654428482056,
        0.9684797525405884,
        1.2610067129135132,
        0.8985472917556763,
        0.6833785176277161,
        0.7234559655189514,
        0.49504420161247253,
        0.5472093820571899,
        0.6687772870063782,
        0.30660173296928406,
        0.31213659048080444,
        0.28124475479125977,
        0.18898455798625946,
        0.19020111858844757,
        0.08124004304409027,
        0.3036363422870636,
        0.07208680361509323,
        0.07342529296875,
        0.10909397155046463,
        0.07019352912902832,
        0.052015211433172226,
        0.06285546720027924,
        0.034911561757326126,
        0.07553117722272873,
        0.019082479178905487,
        0.042156532406806946,
        0.021079324185848236,
        0.014311554841697216,
        0.019990818575024605,
        0.023580389097332954,
        0.01976974494755268
    ],
    "val_loss": [
        2.1660408973693848,
        1.6142125129699707,
        1.6841845512390137,
        1.3066768646240234,
        1.3933353424072266,
        1.3455625772476196,
        1.3779736757278442,
        1.4485613107681274,
        1.5372874736785889,
        1.422825813293457,
        1.495640754699707,
        1.5017954111099243,
        1.8559144735336304,
        1.594628930091858,
        1.6469297409057617,
        1.4063410758972168,
        1.4334886074066162,
        1.8484824895858765,
        1.758456826210022,
        1.4055758714675903,
        1.646741509437561,
        1.8880130052566528,
        1.8537391424179077,
        1.696435809135437,
        1.8219610452651978,
        1.9070197343826294,
        1.9568331241607666,
        1.8602269887924194,
        2.0221471786499023,
        1.9386390447616577,
        2.030282974243164,
        2.0550801753997803,
        1.995693325996399,
        2.2635974884033203
    ],
    "train_accuracy": [
        0.4375,
        0.375,
        0.5,
        0.625,
        0.375,
        0.8125,
        0.75,
        0.75,
        0.9375,
        0.75,
        0.6875,
        0.9375,
        0.875,
        0.9375,
        1.0,
        1.0,
        1.0,
        0.9375,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.3125,
        0.125,
        0.0625,
        0.3125,
        0.25,
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.5,
        0.25,
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.25,
        0.3125,
        0.5,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.375,
        0.375,
        0.3125
    ],
    "epoch_times": [
        1.406970739364624,
        1.4115052223205566,
        1.4089219570159912,
        1.4111387729644775,
        1.410801649093628,
        1.4101176261901855,
        1.411088228225708,
        1.4100120067596436,
        1.4125440120697021,
        1.4108846187591553,
        1.4118897914886475,
        1.4089269638061523,
        1.4135053157806396,
        1.4114038944244385,
        1.4122018814086914,
        1.4110252857208252,
        1.415691614151001,
        1.4126558303833008,
        1.4114716053009033,
        1.414980411529541,
        1.4126884937286377,
        1.4142520427703857,
        1.412724256515503,
        1.4134116172790527,
        1.413743495941162,
        1.4129424095153809,
        1.4131927490234375,
        1.414409875869751,
        1.4116325378417969,
        1.4135911464691162,
        1.4130611419677734,
        1.4120805263519287,
        1.4112260341644287
    ]
}