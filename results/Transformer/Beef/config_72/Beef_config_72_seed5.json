{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0740313187916,
        "ff_dim": 391,
        "hidden_units": 325,
        "learning_rate": 0.0001399254532,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 3.79775821e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 37,
    "train_loss": [
        2.227102518081665,
        1.8605694770812988,
        1.450737476348877,
        1.6708617210388184,
        1.6044589281082153,
        1.505782127380371,
        1.151365876197815,
        1.2630165815353394,
        1.356508731842041,
        1.0787900686264038,
        1.0926642417907715,
        1.0746943950653076,
        1.2683253288269043,
        0.7907106876373291,
        1.0437597036361694,
        0.9056622385978699,
        1.1363409757614136,
        1.1019426584243774,
        0.977424681186676,
        0.7924400568008423,
        0.8239644169807434,
        0.9074226021766663,
        0.849970281124115,
        0.7267932891845703,
        0.8853722214698792,
        0.7939359545707703,
        0.9219976663589478,
        0.7841031551361084,
        0.5338118672370911,
        0.7198389172554016,
        0.5135779976844788,
        0.6781308054924011,
        0.8483428955078125,
        0.5890138149261475,
        0.7282416224479675,
        0.636479377746582,
        0.6907477378845215
    ],
    "val_loss": [
        2.0060603618621826,
        2.320810317993164,
        2.175630569458008,
        1.8499736785888672,
        1.8259434700012207,
        1.938090443611145,
        1.7182048559188843,
        1.5725241899490356,
        1.7438462972640991,
        1.7179430723190308,
        1.643837571144104,
        1.6236313581466675,
        1.8107768297195435,
        2.0530054569244385,
        1.9420849084854126,
        1.86709463596344,
        1.9374185800552368,
        2.0320796966552734,
        2.037994623184204,
        2.112399101257324,
        2.122305393218994,
        2.1359119415283203,
        2.124145269393921,
        2.118321657180786,
        2.1124930381774902,
        2.0714402198791504,
        2.071338653564453,
        2.082893133163452,
        2.1106367111206055,
        2.137653350830078,
        2.1487865447998047,
        2.1873013973236084,
        2.1974332332611084,
        2.20503306388855,
        2.1993653774261475,
        2.186671733856201,
        2.1777737140655518,
        2.174398183822632
    ],
    "train_accuracy": [
        0.0625,
        0.1875,
        0.5,
        0.25,
        0.1875,
        0.1875,
        0.5625,
        0.4375,
        0.375,
        0.4375,
        0.625,
        0.625,
        0.4375,
        0.75,
        0.5625,
        0.6875,
        0.5625,
        0.5625,
        0.5625,
        0.75,
        0.625,
        0.625,
        0.6875,
        0.75,
        0.6875,
        0.6875,
        0.6875,
        0.625,
        0.875,
        0.75,
        0.875,
        0.8125,
        0.625,
        0.875,
        0.75,
        0.75,
        0.6875
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.25,
        0.25,
        0.3333333432674408,
        0.25,
        0.25,
        0.5,
        0.5833333730697632,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.4166666567325592,
        0.5,
        0.5,
        0.5833333730697632,
        0.5,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.18757915496826172,
        0.15126752853393555,
        0.15080523490905762,
        0.1503608226776123,
        0.151716947555542,
        0.14824652671813965,
        0.14858293533325195,
        0.14687466621398926,
        0.14667367935180664,
        0.14560890197753906,
        0.14659762382507324,
        0.15005278587341309,
        0.14738178253173828,
        0.14760398864746094,
        0.14658570289611816,
        0.14971709251403809,
        0.14671730995178223,
        0.14785051345825195,
        0.14741992950439453,
        0.149306058883667,
        0.14644193649291992,
        0.14641785621643066,
        0.14739704132080078,
        0.14806509017944336,
        0.1471080780029297,
        0.14931988716125488,
        0.14676356315612793,
        0.14702820777893066,
        0.14587736129760742,
        0.14818978309631348,
        0.15014243125915527,
        0.14739298820495605,
        0.1464083194732666,
        0.14916300773620605,
        0.14639592170715332,
        0.1465904712677002,
        0.1493229866027832
    ]
}