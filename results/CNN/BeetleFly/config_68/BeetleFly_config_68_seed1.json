{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.0437363810925,
        "kernel_size": 4,
        "learning_rate": 0.0003864861313,
        "num_filters": 66,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 37,
    "train_loss": [
        0.736757755279541,
        0.48501139879226685,
        0.4163600206375122,
        0.3448825776576996,
        0.27792149782180786,
        0.2346770316362381,
        0.2124224156141281,
        0.19111567735671997,
        0.16963037848472595,
        0.15303021669387817,
        0.1307617723941803,
        0.10317648202180862,
        0.10243116319179535,
        0.08192837238311768,
        0.0664137452840805,
        0.05760123208165169,
        0.05219180881977081,
        0.03715476766228676,
        0.03655526787042618,
        0.026631854474544525,
        0.023035958409309387,
        0.023444684222340584,
        0.022287268191576004,
        0.012639978900551796,
        0.01058955304324627,
        0.014715207740664482,
        0.008918133564293385,
        0.007538506295531988,
        0.007242581807076931,
        0.0062591275200247765,
        0.005454021506011486,
        0.004257852677255869,
        0.004987715743482113,
        0.004037172999233007,
        0.0042892866767942905,
        0.003426363691687584,
        0.0026893995236605406
    ],
    "val_loss": [
        0.6835241317749023,
        0.6823700070381165,
        0.6816229820251465,
        0.6812448501586914,
        0.6799759864807129,
        0.6756854057312012,
        0.6705777645111084,
        0.6663427948951721,
        0.6664211750030518,
        0.670576810836792,
        0.6790340542793274,
        0.6973996162414551,
        0.7247582674026489,
        0.7506012916564941,
        0.7829563617706299,
        0.8355244994163513,
        0.9148759841918945,
        1.007140874862671,
        1.0972001552581787,
        1.184633731842041,
        1.2733832597732544,
        1.368764042854309,
        1.4814207553863525,
        1.607853651046753,
        1.7421530485153198,
        1.880252480506897,
        2.001483678817749,
        2.1181039810180664,
        2.2363414764404297,
        2.3490023612976074,
        2.459228992462158,
        2.567152261734009,
        2.6765687465667725,
        2.7876298427581787,
        2.9002246856689453,
        3.015784740447998,
        3.1261138916015625,
        3.229132890701294
    ],
    "train_accuracy": [
        0.5,
        0.8125,
        0.78125,
        0.875,
        0.875,
        0.9375,
        0.90625,
        0.9375,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.25,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.375
    ],
    "epoch_times": [
        4.004864931106567,
        0.04681205749511719,
        0.02364492416381836,
        0.023065805435180664,
        0.022233009338378906,
        0.02227783203125,
        0.021956920623779297,
        0.022733211517333984,
        0.02152395248413086,
        0.021212100982666016,
        0.022166013717651367,
        0.021406173706054688,
        0.022530078887939453,
        0.022144079208374023,
        0.022289276123046875,
        0.020624160766601562,
        0.022495031356811523,
        0.022812843322753906,
        0.022596120834350586,
        0.023043155670166016,
        0.023357868194580078,
        0.02271103858947754,
        0.021384000778198242,
        0.022309064865112305,
        0.022928953170776367,
        0.0220489501953125,
        0.023360013961791992,
        0.03793001174926758,
        0.021277189254760742,
        0.021364927291870117,
        0.02166604995727539,
        0.022719144821166992,
        0.021288156509399414,
        0.022075891494750977,
        0.021020174026489258,
        0.021635770797729492,
        0.0229642391204834
    ]
}