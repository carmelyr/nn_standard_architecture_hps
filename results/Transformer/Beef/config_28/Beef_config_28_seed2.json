{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.76175856590271,
        2.041759967803955,
        1.8162343502044678,
        1.535473108291626,
        1.2922425270080566,
        1.903874397277832,
        1.5664708614349365,
        1.7546144723892212,
        1.6703178882598877,
        1.8236653804779053,
        1.3259544372558594,
        1.760427474975586,
        1.344117283821106,
        1.7347570657730103,
        1.711862325668335,
        1.3447760343551636,
        1.5744205713272095,
        1.555712103843689,
        1.684818148612976,
        1.6247444152832031,
        1.4374209642410278,
        1.5722230672836304,
        1.5456855297088623,
        1.8270784616470337,
        1.438732624053955,
        1.5944604873657227,
        1.73776113986969,
        1.6874953508377075,
        1.4732965230941772,
        1.4100441932678223,
        1.7838729619979858
    ],
    "val_loss": [
        1.8183740377426147,
        1.7559609413146973,
        1.793775200843811,
        1.869789958000183,
        1.9767259359359741,
        2.0933148860931396,
        2.189763307571411,
        2.3185393810272217,
        2.367612838745117,
        2.4112250804901123,
        2.432964563369751,
        2.442750930786133,
        2.4376847743988037,
        2.429064989089966,
        2.424146890640259,
        2.41906476020813,
        2.4140126705169678,
        2.406956672668457,
        2.398789644241333,
        2.3871235847473145,
        2.3800737857818604,
        2.373502492904663,
        2.3678629398345947,
        2.3625028133392334,
        2.3568475246429443,
        2.352219343185425,
        2.3504655361175537,
        2.3497304916381836,
        2.3490071296691895,
        2.3476057052612305,
        2.3453238010406494,
        2.34653377532959
    ],
    "train_accuracy": [
        0.3125,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.125,
        0.25,
        0.125,
        0.3125,
        0.1875,
        0.5,
        0.25,
        0.5,
        0.1875,
        0.1875,
        0.5,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.375,
        0.3125,
        0.1875,
        0.4375,
        0.3125,
        0.1875,
        0.1875,
        0.3125,
        0.3125,
        0.125
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.1666666716337204,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602
    ],
    "epoch_times": [
        0.2795834541320801,
        0.2021019458770752,
        0.20191693305969238,
        0.2015380859375,
        0.20336484909057617,
        0.20641255378723145,
        0.20138978958129883,
        0.2029564380645752,
        0.20101284980773926,
        0.20239496231079102,
        0.20105886459350586,
        0.20421528816223145,
        0.20416712760925293,
        0.20456814765930176,
        0.20184588432312012,
        0.20125937461853027,
        0.20185327529907227,
        0.20108604431152344,
        0.2044050693511963,
        0.20275449752807617,
        0.20258021354675293,
        0.20368289947509766,
        0.20211267471313477,
        0.20207810401916504,
        0.2025601863861084,
        0.20513105392456055,
        0.20549750328063965,
        0.2031099796295166,
        0.2025911808013916,
        0.20181059837341309,
        0.20191192626953125
    ]
}