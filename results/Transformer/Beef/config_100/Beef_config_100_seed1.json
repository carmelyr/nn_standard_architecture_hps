{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1745348366843,
        "ff_dim": 385,
        "hidden_units": 161,
        "learning_rate": 1.39996323e-05,
        "num_heads": 3,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 7.0120995e-06
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 33,
    "train_loss": [
        1.9388186931610107,
        1.877432107925415,
        1.7130488157272339,
        1.845321774482727,
        2.0843610763549805,
        1.9274036884307861,
        1.75712251663208,
        1.6532615423202515,
        2.104388475418091,
        1.657804012298584,
        1.6405915021896362,
        1.7642948627471924,
        1.8010553121566772,
        1.8566255569458008,
        1.7440438270568848,
        1.5883276462554932,
        1.8500336408615112,
        1.8911939859390259,
        1.7950730323791504,
        1.718302845954895,
        1.7995694875717163,
        1.6731764078140259,
        1.6557881832122803,
        1.7735645771026611,
        1.8518990278244019,
        1.618138313293457,
        1.54770028591156,
        1.660243034362793,
        1.7004292011260986,
        1.9124407768249512,
        1.6988714933395386,
        1.8371480703353882,
        1.3622697591781616
    ],
    "val_loss": [
        1.6506539583206177,
        1.635766625404358,
        1.630182147026062,
        1.6276847124099731,
        1.6275047063827515,
        1.6306227445602417,
        1.632988452911377,
        1.6343439817428589,
        1.6342772245407104,
        1.63074791431427,
        1.6284550428390503,
        1.6283793449401855,
        1.6285687685012817,
        1.6280875205993652,
        1.6280852556228638,
        1.627549648284912,
        1.6288862228393555,
        1.6290640830993652,
        1.629164218902588,
        1.6297855377197266,
        1.6299773454666138,
        1.6299697160720825,
        1.6302911043167114,
        1.6303414106369019,
        1.6301547288894653,
        1.6298493146896362,
        1.6300350427627563,
        1.6302175521850586,
        1.63047456741333,
        1.630505919456482,
        1.6305359601974487,
        1.6305031776428223,
        1.6303688287734985,
        1.6303133964538574
    ],
    "train_accuracy": [
        0.125,
        0.125,
        0.1875,
        0.0625,
        0.0,
        0.125,
        0.25,
        0.3125,
        0.125,
        0.1875,
        0.375,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.1875,
        0.125,
        0.0625,
        0.3125,
        0.25,
        0.125,
        0.125,
        0.125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.1875,
        0.3125,
        0.25,
        0.25,
        0.3125
    ],
    "val_accuracy": [
        0.25,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204
    ],
    "epoch_times": [
        0.19936537742614746,
        0.0641024112701416,
        0.05633974075317383,
        0.055954694747924805,
        0.05489706993103027,
        0.05076169967651367,
        0.05071592330932617,
        0.052073001861572266,
        0.05077219009399414,
        0.05153465270996094,
        0.05184221267700195,
        0.05121040344238281,
        0.05335402488708496,
        0.052204132080078125,
        0.05075979232788086,
        0.049777984619140625,
        0.05137228965759277,
        0.04751777648925781,
        0.04896044731140137,
        0.04847860336303711,
        0.049771785736083984,
        0.05037260055541992,
        0.05040168762207031,
        0.05138993263244629,
        0.05170083045959473,
        0.05109834671020508,
        0.05124235153198242,
        0.05305838584899902,
        0.05406475067138672,
        0.05499529838562012,
        0.05514717102050781,
        0.054534196853637695,
        0.055346012115478516
    ]
}