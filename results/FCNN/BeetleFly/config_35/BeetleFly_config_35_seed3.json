{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1529760851352,
        "hidden_units": 116,
        "learning_rate": 0.0027616887793,
        "num_layers": 2,
        "weight_decay": 0.0007946044568
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 36,
        "val_size": 9,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.719971776008606,
        0.367230087518692,
        0.2908819615840912,
        0.2117178738117218,
        0.18963132798671722,
        0.19317124783992767,
        0.13246722519397736,
        0.13178062438964844,
        0.1047818511724472,
        0.10880132019519806,
        0.10570025444030762,
        0.049010019749403,
        0.09316638112068176,
        0.03720035403966904,
        0.11827368289232254,
        0.10170677304267883,
        0.04053603112697601,
        0.03581339120864868,
        0.038925863802433014,
        0.12743574380874634,
        0.051385827362537384,
        0.03230138123035431,
        0.052557870745658875,
        0.0391550287604332,
        0.0509854219853878,
        0.059170350432395935,
        0.08135735988616943,
        0.026115424931049347,
        0.026528388261795044,
        0.055106304585933685,
        0.05228778347373009
    ],
    "val_loss": [
        0.65481036901474,
        0.6269543170928955,
        0.6449916362762451,
        0.6743342876434326,
        0.693114697933197,
        0.7839990854263306,
        0.8873696327209473,
        0.8985714316368103,
        0.940936803817749,
        1.0133758783340454,
        1.092443585395813,
        1.354598879814148,
        1.4526698589324951,
        1.2961928844451904,
        1.4153873920440674,
        1.7352306842803955,
        1.9259371757507324,
        1.8436330556869507,
        1.784544825553894,
        1.6935429573059082,
        1.7418406009674072,
        1.4748462438583374,
        1.2633049488067627,
        1.2686594724655151,
        1.2775174379348755,
        1.2300398349761963,
        1.3273546695709229,
        1.4377188682556152,
        1.3328876495361328,
        1.2487438917160034,
        1.3750377893447876,
        1.5004087686538696
    ],
    "train_accuracy": [
        0.5277777910232544,
        0.8333333134651184,
        0.9444444179534912,
        0.9722222089767456,
        1.0,
        1.0,
        1.0,
        1.0,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        1.0,
        1.0,
        1.0,
        0.9722222089767456,
        0.9722222089767456,
        1.0,
        1.0,
        1.0,
        0.9444444179534912,
        1.0,
        1.0,
        0.9722222089767456,
        1.0,
        1.0,
        0.9722222089767456,
        0.9722222089767456,
        1.0,
        1.0,
        0.9722222089767456,
        1.0
    ],
    "val_accuracy": [
        0.7777777910232544,
        0.7777777910232544,
        0.6666666865348816,
        0.6666666865348816,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816
    ],
    "epoch_times": [
        0.013741016387939453,
        0.013025999069213867,
        0.013036727905273438,
        0.013126373291015625,
        0.012918710708618164,
        0.012894868850708008,
        0.012912273406982422,
        0.012935400009155273,
        0.012928009033203125,
        0.013416051864624023,
        0.0129241943359375,
        0.012945890426635742,
        0.012966632843017578,
        0.013025760650634766,
        0.012999773025512695,
        0.012962579727172852,
        0.012969970703125,
        0.012968778610229492,
        0.013063907623291016,
        0.013041496276855469,
        0.012888908386230469,
        0.012982368469238281,
        0.012774229049682617,
        0.012940168380737305,
        0.012921333312988281,
        0.012924909591674805,
        0.012917757034301758,
        0.012979984283447266,
        0.013013124465942383,
        0.012948036193847656,
        0.013128280639648438
    ]
}