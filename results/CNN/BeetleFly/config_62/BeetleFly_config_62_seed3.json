{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1630504700718,
        "kernel_size": 3,
        "learning_rate": 0.0019638118283,
        "num_filters": 124,
        "num_layers": 1,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.8324311375617981,
        0.4903363883495331,
        0.323957234621048,
        0.25793084502220154,
        0.21459907293319702,
        0.17614644765853882,
        0.14907433092594147,
        0.17218554019927979,
        0.13363294303417206,
        0.12370149791240692,
        0.11117348074913025,
        0.103556789457798,
        0.0804390087723732,
        0.07232409715652466,
        0.07671790570020676,
        0.05947934463620186,
        0.05112861096858978,
        0.04831480234861374,
        0.04206518828868866,
        0.03791797161102295,
        0.030682433396577835,
        0.03197883814573288,
        0.03250134363770485,
        0.022523703053593636,
        0.0230731051415205,
        0.019263138994574547,
        0.01753922738134861,
        0.01633152924478054,
        0.012002214789390564,
        0.011244312860071659,
        0.013439616188406944,
        0.01158120483160019,
        0.010371103882789612,
        0.008960194885730743,
        0.007716652471572161
    ],
    "val_loss": [
        0.7166558504104614,
        0.7030502557754517,
        0.7110368013381958,
        0.6849889755249023,
        0.6686667799949646,
        0.6652056574821472,
        0.6739695072174072,
        0.6875013709068298,
        0.720403254032135,
        0.7667720913887024,
        0.8261882066726685,
        0.8877362012863159,
        0.9444823265075684,
        0.9945570230484009,
        1.0382548570632935,
        1.0720423460006714,
        1.0966359376907349,
        1.113418459892273,
        1.1256563663482666,
        1.1406761407852173,
        1.1559549570083618,
        1.1726620197296143,
        1.1876753568649292,
        1.1962369680404663,
        1.2014415264129639,
        1.2095056772232056,
        1.221083641052246,
        1.233599066734314,
        1.252651572227478,
        1.2738884687423706,
        1.3001641035079956,
        1.3301851749420166,
        1.361996054649353,
        1.3965990543365479,
        1.4324018955230713,
        1.4742584228515625
    ],
    "train_accuracy": [
        0.46875,
        0.78125,
        0.90625,
        0.9375,
        0.9375,
        0.96875,
        0.96875,
        0.9375,
        0.9375,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.026293277740478516,
        0.2999293804168701,
        0.02154254913330078,
        0.021918773651123047,
        0.024181604385375977,
        0.02149677276611328,
        0.020485639572143555,
        0.020021438598632812,
        0.019495010375976562,
        0.01740264892578125,
        0.017114877700805664,
        0.016806840896606445,
        0.01714468002319336,
        0.016627073287963867,
        0.016359806060791016,
        0.017894506454467773,
        0.0170443058013916,
        0.01618647575378418,
        0.01621246337890625,
        0.017124176025390625,
        0.017413854598999023,
        0.017800569534301758,
        0.016428232192993164,
        0.02304363250732422,
        0.016672372817993164,
        0.015996217727661133,
        0.016572952270507812,
        0.016321182250976562,
        0.015060186386108398,
        0.01502537727355957,
        0.016658306121826172,
        0.013164043426513672,
        0.01548910140991211,
        0.015375137329101562,
        0.016265153884887695
    ]
}