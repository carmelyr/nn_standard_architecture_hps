{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        1.033923625946045,
        0.8121984601020813,
        0.8526609539985657,
        0.7456735372543335,
        0.7494750618934631,
        0.6722143888473511,
        0.9862707257270813,
        0.7720996737480164,
        0.705127477645874,
        0.8444318771362305,
        0.8298590183258057,
        0.6957900524139404,
        0.781959056854248,
        0.8339067101478577,
        0.9355466961860657,
        0.9439774751663208,
        0.8555282354354858,
        0.8257752656936646,
        0.8230223655700684,
        0.8313316106796265,
        0.777080774307251,
        0.8594621419906616,
        0.8730815052986145,
        0.7031534314155579,
        0.6258273124694824,
        0.9768675565719604,
        0.6191062927246094,
        0.6360902190208435,
        0.7924116253852844,
        0.7297728061676025,
        0.7973272800445557
    ],
    "val_loss": [
        0.56350177526474,
        0.6228104829788208,
        0.7934752702713013,
        1.051692008972168,
        1.2902805805206299,
        1.4318788051605225,
        1.4966310262680054,
        1.5435335636138916,
        1.5324472188949585,
        1.4985084533691406,
        1.4444124698638916,
        1.3813782930374146,
        1.3055657148361206,
        1.2332755327224731,
        1.197367787361145,
        1.1710898876190186,
        1.1489964723587036,
        1.1333768367767334,
        1.116636872291565,
        1.109657645225525,
        1.1061322689056396,
        1.1053959131240845,
        1.1053268909454346,
        1.106050729751587,
        1.1082285642623901,
        1.1091021299362183,
        1.1097462177276611,
        1.1124573945999146,
        1.116023063659668,
        1.1189355850219727,
        1.1217706203460693,
        1.1245439052581787
    ],
    "train_accuracy": [
        0.40625,
        0.5625,
        0.53125,
        0.5,
        0.53125,
        0.53125,
        0.28125,
        0.59375,
        0.625,
        0.46875,
        0.46875,
        0.625,
        0.53125,
        0.46875,
        0.4375,
        0.40625,
        0.40625,
        0.4375,
        0.5,
        0.5,
        0.4375,
        0.4375,
        0.46875,
        0.5625,
        0.65625,
        0.375,
        0.59375,
        0.5625,
        0.5,
        0.625,
        0.5
    ],
    "val_accuracy": [
        0.875,
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.16034173965454102,
        0.1512160301208496,
        0.15156173706054688,
        0.15105605125427246,
        0.15233564376831055,
        0.15331768989562988,
        0.15260744094848633,
        0.15178990364074707,
        0.1521470546722412,
        0.15157318115234375,
        0.15195178985595703,
        0.15271234512329102,
        0.152756929397583,
        0.15255951881408691,
        0.1514899730682373,
        0.1524183750152588,
        0.1518855094909668,
        0.1519153118133545,
        0.15160489082336426,
        0.15257477760314941,
        0.1521294116973877,
        0.1515340805053711,
        0.1511096954345703,
        0.1522834300994873,
        0.15375900268554688,
        0.15298771858215332,
        0.15409016609191895,
        0.15096449851989746,
        0.15020275115966797,
        0.1523425579071045,
        0.15253949165344238
    ]
}