{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.068110276744,
        "ff_dim": 279,
        "hidden_units": 444,
        "learning_rate": 1.63705046e-05,
        "num_heads": 8,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 2.56177413e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.5370713472366333,
        1.7567789554595947,
        1.642014980316162,
        1.4638996124267578,
        1.582506537437439,
        1.6436409950256348,
        1.1591548919677734,
        1.3234933614730835,
        1.3372117280960083,
        1.2703883647918701,
        1.3175493478775024,
        1.2125966548919678,
        1.0797723531723022,
        1.0673494338989258,
        1.094539999961853,
        1.080518126487732,
        1.0363643169403076,
        1.0733577013015747,
        1.182443618774414,
        1.0421152114868164,
        1.3479626178741455,
        1.137576699256897,
        1.223370909690857,
        1.1216744184494019,
        1.1055080890655518,
        1.0057964324951172,
        0.8554267883300781,
        1.1303582191467285,
        1.1031861305236816,
        0.9178326725959778,
        1.2463171482086182
    ],
    "val_loss": [
        1.7149075269699097,
        1.4180556535720825,
        1.5310096740722656,
        1.5463519096374512,
        1.577945351600647,
        1.7063528299331665,
        1.705867886543274,
        1.6748875379562378,
        1.6594585180282593,
        1.6601275205612183,
        1.6745001077651978,
        1.6949290037155151,
        1.709708571434021,
        1.7286648750305176,
        1.7435426712036133,
        1.7501646280288696,
        1.7585283517837524,
        1.7593564987182617,
        1.7533211708068848,
        1.751625895500183,
        1.7522748708724976,
        1.757759928703308,
        1.7618523836135864,
        1.7614521980285645,
        1.7599550485610962,
        1.7606779336929321,
        1.760574221611023,
        1.7616111040115356,
        1.7618012428283691,
        1.7632843255996704,
        1.7632302045822144,
        1.7660255432128906
    ],
    "train_accuracy": [
        0.4375,
        0.25,
        0.3125,
        0.25,
        0.4375,
        0.4375,
        0.5625,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.625,
        0.625,
        0.375,
        0.5625,
        0.625,
        0.5625,
        0.375,
        0.5625,
        0.3125,
        0.4375,
        0.3125,
        0.5625,
        0.625,
        0.375,
        0.5625,
        0.5625,
        0.375,
        0.5625,
        0.3125
    ],
    "val_accuracy": [
        0.25,
        0.5,
        0.5833333730697632,
        0.5833333730697632,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.2742464542388916,
        0.2654683589935303,
        0.2639191150665283,
        0.265047550201416,
        0.2650890350341797,
        0.2648587226867676,
        0.26670217514038086,
        0.2661316394805908,
        0.26439762115478516,
        0.2641563415527344,
        0.265291690826416,
        0.2646496295928955,
        0.26448798179626465,
        0.2678225040435791,
        0.2658514976501465,
        0.26552367210388184,
        0.2651364803314209,
        0.26461362838745117,
        0.26418089866638184,
        0.2677266597747803,
        0.26668405532836914,
        0.2677626609802246,
        0.2656116485595703,
        0.26541924476623535,
        0.26493358612060547,
        0.26511549949645996,
        0.264904260635376,
        0.26555848121643066,
        0.2653689384460449,
        0.26540493965148926,
        0.26546645164489746
    ]
}