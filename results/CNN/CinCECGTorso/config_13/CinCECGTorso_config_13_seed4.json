{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1002373772,
        "kernel_size": 5,
        "learning_rate": 0.000578138975,
        "num_filters": 195,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1,
            1639
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        1.4449172019958496,
        0.9623475074768066,
        0.6842014193534851,
        0.5182638168334961,
        0.44998466968536377,
        0.30636781454086304,
        0.29764267802238464,
        0.28114739060401917,
        0.18126913905143738,
        0.18840913474559784,
        0.16818970441818237,
        0.17032690346240997,
        0.1436072289943695,
        0.0714501440525055,
        0.09080435335636139,
        0.09441381692886353,
        0.05233937129378319,
        0.08187713474035263,
        0.09965988993644714,
        0.04484551399946213,
        0.0699882060289383,
        0.10968874394893646,
        0.08475784957408905,
        0.051094334572553635,
        0.039429064840078354,
        0.034024566411972046,
        0.08130110800266266,
        0.03795202076435089,
        0.04940621554851532,
        0.048641979694366455,
        0.039394743740558624,
        0.02655675634741783,
        0.019971538335084915,
        0.05504186451435089,
        0.037243425846099854
    ],
    "val_loss": [
        1.3820970058441162,
        1.379355788230896,
        1.376215934753418,
        1.3726990222930908,
        1.3701413869857788,
        1.3683006763458252,
        1.3693486452102661,
        1.3736145496368408,
        1.3830357789993286,
        1.3995399475097656,
        1.4211549758911133,
        1.458339810371399,
        1.5210739374160767,
        1.594669222831726,
        1.704444169998169,
        1.8443574905395508,
        1.9773097038269043,
        2.1122920513153076,
        2.254399538040161,
        2.3648617267608643,
        2.474494457244873,
        2.6077256202697754,
        2.680267333984375,
        2.796187162399292,
        2.8777072429656982,
        2.906599760055542,
        2.939399480819702,
        2.9708688259124756,
        3.01959228515625,
        3.1073973178863525,
        3.174227714538574,
        3.1314175128936768,
        3.1330652236938477,
        3.159547805786133,
        3.155832052230835,
        3.111804246902466
    ],
    "train_accuracy": [
        0.28125,
        0.671875,
        0.8125,
        0.875,
        0.84375,
        0.96875,
        0.921875,
        0.9375,
        0.953125,
        0.96875,
        0.953125,
        0.96875,
        0.9375,
        0.984375,
        0.984375,
        0.96875,
        1.0,
        1.0,
        0.984375,
        1.0,
        0.984375,
        0.953125,
        0.96875,
        1.0,
        0.984375,
        1.0,
        0.984375,
        1.0,
        1.0,
        0.984375,
        1.0,
        1.0,
        1.0,
        1.0,
        0.984375
    ],
    "val_accuracy": [
        0.4375,
        0.4375,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.21298480033874512,
        0.030522584915161133,
        0.02033400535583496,
        0.020320892333984375,
        0.01992201805114746,
        0.01975083351135254,
        0.02130436897277832,
        0.021268844604492188,
        0.02579021453857422,
        0.021732568740844727,
        0.021589279174804688,
        0.020292282104492188,
        0.02012920379638672,
        0.01970076560974121,
        0.019863128662109375,
        0.020413875579833984,
        0.020822525024414062,
        0.020323991775512695,
        0.021470069885253906,
        0.020482778549194336,
        0.022101402282714844,
        0.02103114128112793,
        0.020700454711914062,
        0.021680355072021484,
        0.020910978317260742,
        0.02164316177368164,
        0.021287918090820312,
        0.02230381965637207,
        0.025178909301757812,
        0.020551204681396484,
        0.022623538970947266,
        0.023169994354248047,
        0.02031421661376953,
        0.02259993553161621,
        0.020389080047607422
    ]
}