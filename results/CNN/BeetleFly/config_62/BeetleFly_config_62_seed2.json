{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.4221112624768,
        "kernel_size": 7,
        "learning_rate": 0.0026374600237,
        "num_filters": 154,
        "num_layers": 5,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 37,
    "train_loss": [
        0.7860961556434631,
        0.6643748879432678,
        0.6887711882591248,
        0.6930939555168152,
        0.565743625164032,
        0.4694249927997589,
        0.515769898891449,
        0.6322097182273865,
        0.45932599902153015,
        0.4546089470386505,
        0.36552104353904724,
        0.3260681927204132,
        0.27998796105384827,
        0.27115026116371155,
        0.23370349407196045,
        0.3074641823768616,
        0.16680322587490082,
        0.06721358001232147,
        0.14213275909423828,
        0.4440348744392395,
        0.25344347953796387,
        0.07996834814548492,
        0.12093660235404968,
        0.1563538759946823,
        0.09065309911966324,
        0.17798449099063873,
        0.0661744698882103,
        0.09001367539167404,
        0.11902085691690445,
        0.1687895953655243,
        0.06558340042829514,
        0.11473049968481064,
        0.0926746279001236,
        0.05969827622175217,
        0.12225079536437988,
        0.13704586029052734,
        0.053879544138908386
    ],
    "val_loss": [
        0.6847463846206665,
        0.685164213180542,
        0.6854327917098999,
        0.6859050989151001,
        0.6867020130157471,
        0.6855964660644531,
        0.6854255199432373,
        0.68438720703125,
        0.6849781274795532,
        0.6854274868965149,
        0.6893941164016724,
        0.6933603286743164,
        0.7004268169403076,
        0.7100042104721069,
        0.7244755029678345,
        0.7330730557441711,
        0.7429186701774597,
        0.7567684650421143,
        0.7762181758880615,
        0.8091719150543213,
        0.8509300351142883,
        0.9136025905609131,
        0.9912073016166687,
        1.0901752710342407,
        1.2008455991744995,
        1.3340113162994385,
        1.4552923440933228,
        1.558701515197754,
        1.6570792198181152,
        1.74656081199646,
        1.8152806758880615,
        1.9005422592163086,
        1.9659215211868286,
        2.0731468200683594,
        2.1581332683563232,
        2.281681537628174,
        2.3550024032592773,
        2.4525041580200195
    ],
    "train_accuracy": [
        0.59375,
        0.625,
        0.65625,
        0.65625,
        0.6875,
        0.8125,
        0.84375,
        0.71875,
        0.75,
        0.84375,
        0.84375,
        0.8125,
        0.875,
        0.875,
        0.875,
        0.9375,
        0.90625,
        0.96875,
        0.9375,
        0.875,
        0.875,
        1.0,
        0.9375,
        0.9375,
        0.96875,
        0.96875,
        1.0,
        1.0,
        0.96875,
        0.90625,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        0.9375,
        0.9375,
        0.96875
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.3047811985015869,
        0.04252934455871582,
        0.1289384365081787,
        0.06260466575622559,
        0.07746672630310059,
        0.07010173797607422,
        0.06785082817077637,
        0.07016110420227051,
        0.05816292762756348,
        0.06623697280883789,
        0.06928634643554688,
        0.06801319122314453,
        0.07143425941467285,
        0.05647158622741699,
        0.0689077377319336,
        0.06654810905456543,
        0.06361269950866699,
        0.06073474884033203,
        0.06001400947570801,
        0.03116464614868164,
        0.03175163269042969,
        0.06904411315917969,
        0.06894540786743164,
        0.06931757926940918,
        0.0666356086730957,
        0.06878209114074707,
        0.07556486129760742,
        0.060628652572631836,
        0.06414937973022461,
        0.07304239273071289,
        0.05312371253967285,
        0.02981090545654297,
        0.030408620834350586,
        0.07057833671569824,
        0.06571602821350098,
        0.07375764846801758,
        0.06794095039367676
    ]
}