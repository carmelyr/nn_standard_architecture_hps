{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.004576789529,
        "ff_dim": 271,
        "hidden_units": 74,
        "learning_rate": 4.0582752e-05,
        "num_heads": 7,
        "num_layers": 3,
        "pooling": "max",
        "weight_decay": 8.00892986e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        1.4844772815704346,
        1.2609120607376099,
        1.3260256052017212,
        1.2692036628723145,
        1.2170610427856445,
        1.40500009059906,
        1.2468268871307373,
        1.1331411600112915,
        1.158455491065979,
        1.3341912031173706,
        1.2066211700439453,
        1.2024009227752686,
        1.123060703277588,
        1.2781169414520264,
        1.2223049402236938,
        1.182826042175293,
        1.3443535566329956,
        1.216118335723877,
        1.32027006149292,
        1.195768117904663,
        1.0693490505218506,
        1.1520129442214966,
        1.1961153745651245,
        1.2626136541366577,
        1.2423843145370483,
        1.2779608964920044,
        1.1708009243011475,
        1.3057948350906372,
        1.161102533340454,
        1.2149003744125366,
        1.1256508827209473,
        1.357053279876709,
        1.241590976715088,
        1.1745762825012207,
        1.0664547681808472
    ],
    "val_loss": [
        1.5597188472747803,
        1.4278459548950195,
        1.3671704530715942,
        1.341821312904358,
        1.3317084312438965,
        1.3274751901626587,
        1.3537474870681763,
        1.3671119213104248,
        1.3687578439712524,
        1.3647383451461792,
        1.3612784147262573,
        1.3671666383743286,
        1.370301365852356,
        1.3683748245239258,
        1.370650053024292,
        1.3721492290496826,
        1.382939338684082,
        1.3869738578796387,
        1.3890444040298462,
        1.3910092115402222,
        1.3912509679794312,
        1.3920201063156128,
        1.3923076391220093,
        1.3938654661178589,
        1.3950399160385132,
        1.3970179557800293,
        1.3978086709976196,
        1.3972417116165161,
        1.397923231124878,
        1.3989031314849854,
        1.3993680477142334,
        1.399095892906189,
        1.3995286226272583,
        1.399133563041687,
        1.398702621459961,
        1.3981777429580688
    ],
    "train_accuracy": [
        0.375,
        0.375,
        0.4375,
        0.3125,
        0.5,
        0.375,
        0.4375,
        0.6875,
        0.625,
        0.4375,
        0.5625,
        0.4375,
        0.5,
        0.375,
        0.375,
        0.4375,
        0.1875,
        0.5,
        0.375,
        0.5,
        0.625,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.625,
        0.375,
        0.4375,
        0.5,
        0.5625,
        0.3125,
        0.4375,
        0.4375,
        0.5625
    ],
    "val_accuracy": [
        0.0625,
        0.0625,
        0.125,
        0.25,
        0.25,
        0.25,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125
    ],
    "epoch_times": [
        0.5310945510864258,
        0.5280454158782959,
        0.5317885875701904,
        0.5285215377807617,
        0.5292410850524902,
        0.53059983253479,
        0.5297787189483643,
        0.5300531387329102,
        0.5314114093780518,
        0.530426025390625,
        0.5256874561309814,
        0.5280611515045166,
        0.5311121940612793,
        0.5338015556335449,
        0.5340242385864258,
        0.533409595489502,
        0.5396251678466797,
        0.5340862274169922,
        0.5313606262207031,
        0.5318541526794434,
        0.5341246128082275,
        0.5331499576568604,
        0.535036563873291,
        0.5308382511138916,
        0.5309433937072754,
        0.5316786766052246,
        0.5309855937957764,
        0.5356180667877197,
        0.5321710109710693,
        0.5309853553771973,
        0.5315713882446289,
        0.5309741497039795,
        0.5315535068511963,
        0.5346605777740479,
        0.5329205989837646
    ]
}