{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0668866210245,
        "kernel_size": 7,
        "learning_rate": 0.0048811259055,
        "num_filters": 136,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7824084758758545,
        0.41185054183006287,
        0.18397866189479828,
        0.07605689018964767,
        0.02771490253508091,
        0.02590353786945343,
        0.01809118315577507,
        0.014262702316045761,
        0.00786916445940733,
        0.009514611214399338,
        0.006086618639528751,
        0.003900754265487194,
        0.003622252494096756,
        0.0029532217886298895,
        0.0022088089026510715,
        0.002104890998452902,
        0.001722149085253477,
        0.0014896458014845848,
        0.0019543233793228865,
        0.0012008899357169867,
        0.0009691758896224201,
        0.0007629474857822061,
        0.0008648235816508532,
        0.0008953645592555404,
        0.0006537443841807544,
        0.0006615653401240706,
        0.0005145406466908753,
        0.0004374320851638913,
        0.0007797750295139849,
        0.0003440278524067253,
        0.0004236690001562238
    ],
    "val_loss": [
        0.6852340698242188,
        0.6847545504570007,
        0.7652983665466309,
        0.8065727949142456,
        0.8573055863380432,
        0.9390956163406372,
        1.0708394050598145,
        1.2427289485931396,
        1.4389618635177612,
        1.645244836807251,
        1.8552511930465698,
        2.0615921020507812,
        2.263345241546631,
        2.452763795852661,
        2.634838819503784,
        2.803554058074951,
        2.9637866020202637,
        3.1197102069854736,
        3.2638254165649414,
        3.388645648956299,
        3.506442070007324,
        3.6122097969055176,
        3.7116305828094482,
        3.8042562007904053,
        3.884911060333252,
        3.955838203430176,
        4.007180213928223,
        4.060977935791016,
        4.104522705078125,
        4.136376857757568,
        4.166163921356201,
        4.191032886505127
    ],
    "train_accuracy": [
        0.46875,
        0.8125,
        0.90625,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.1765282154083252,
        0.01390218734741211,
        0.012097835540771484,
        0.01312875747680664,
        0.012639999389648438,
        0.012656688690185547,
        0.012263774871826172,
        0.012335062026977539,
        0.012555122375488281,
        0.012898921966552734,
        0.012802839279174805,
        0.013408660888671875,
        0.012654781341552734,
        0.013641357421875,
        0.013133049011230469,
        0.012979745864868164,
        0.013789176940917969,
        0.013220071792602539,
        0.013625144958496094,
        0.013387441635131836,
        0.013269424438476562,
        0.013579130172729492,
        0.013432741165161133,
        0.013042449951171875,
        0.013402700424194336,
        0.013023614883422852,
        0.013308048248291016,
        0.013624429702758789,
        0.012632369995117188,
        0.013083696365356445,
        0.013452291488647461
    ]
}