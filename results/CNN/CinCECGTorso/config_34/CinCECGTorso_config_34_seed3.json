{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.3506901473167,
        "kernel_size": 3,
        "learning_rate": 0.0003137483554,
        "num_filters": 222,
        "num_layers": 2,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1,
            1639
        ],
        "num_classes": 4
    },
    "epochs": 31,
    "train_loss": [
        1.4763550758361816,
        0.9709173440933228,
        0.8106529712677002,
        0.6873757839202881,
        0.5812997817993164,
        0.534130871295929,
        0.5662119388580322,
        0.485264390707016,
        0.4554135799407959,
        0.4613262414932251,
        0.34906286001205444,
        0.38770022988319397,
        0.3702523708343506,
        0.3784918189048767,
        0.34220007061958313,
        0.33364948630332947,
        0.3481743335723877,
        0.2666132152080536,
        0.28756189346313477,
        0.2671462297439575,
        0.31509965658187866,
        0.2481904923915863,
        0.29995664954185486,
        0.25362539291381836,
        0.22229605913162231,
        0.25643759965896606,
        0.23779211938381195,
        0.23189961910247803,
        0.17661885917186737,
        0.212027907371521,
        0.18757089972496033
    ],
    "val_loss": [
        1.3842196464538574,
        1.3854596614837646,
        1.3967902660369873,
        1.4074139595031738,
        1.416304111480713,
        1.4240360260009766,
        1.4328126907348633,
        1.4356986284255981,
        1.4448356628417969,
        1.4579567909240723,
        1.4737939834594727,
        1.5006903409957886,
        1.5185080766677856,
        1.5418816804885864,
        1.5617257356643677,
        1.5738812685012817,
        1.608847975730896,
        1.635147213935852,
        1.6545372009277344,
        1.6713694334030151,
        1.6956077814102173,
        1.7036551237106323,
        1.7045409679412842,
        1.7138819694519043,
        1.7105212211608887,
        1.7073582410812378,
        1.7081702947616577,
        1.6993091106414795,
        1.6932373046875,
        1.698312759399414,
        1.713111162185669,
        1.7134902477264404
    ],
    "train_accuracy": [
        0.28125,
        0.609375,
        0.640625,
        0.75,
        0.828125,
        0.84375,
        0.828125,
        0.875,
        0.890625,
        0.859375,
        0.921875,
        0.90625,
        0.953125,
        0.890625,
        0.890625,
        0.875,
        0.90625,
        0.9375,
        0.9375,
        0.953125,
        0.921875,
        0.90625,
        0.90625,
        0.9375,
        0.953125,
        0.890625,
        0.9375,
        0.921875,
        0.953125,
        0.9375,
        0.96875
    ],
    "val_accuracy": [
        0.1875,
        0.375,
        0.3125,
        0.3125,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.06948733329772949,
        0.14352703094482422,
        0.02269721031188965,
        0.020457744598388672,
        0.023090362548828125,
        0.029714345932006836,
        0.027475833892822266,
        0.02666640281677246,
        0.021675586700439453,
        0.021988868713378906,
        0.020428180694580078,
        0.020523786544799805,
        0.023236989974975586,
        0.029931306838989258,
        0.023119688034057617,
        0.024073362350463867,
        0.023516416549682617,
        0.022405147552490234,
        0.02393341064453125,
        0.02249908447265625,
        0.023421049118041992,
        0.028635501861572266,
        0.026413679122924805,
        0.022218704223632812,
        0.022975921630859375,
        0.022861480712890625,
        0.02224588394165039,
        0.026114463806152344,
        0.026854276657104492,
        0.026082992553710938,
        0.022919416427612305
    ]
}