{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2470582356593,
        "kernel_size": 4,
        "learning_rate": 0.0070681474902,
        "num_filters": 190,
        "num_layers": 4,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.6672995686531067,
        0.615492045879364,
        1.6873815059661865,
        0.5528202056884766,
        0.6933377981185913,
        0.44257187843322754,
        0.4527909755706787,
        0.11037042737007141,
        0.06049956753849983,
        0.11908509582281113,
        0.1348910927772522,
        0.062285732477903366,
        0.009574182331562042,
        0.060974933207035065,
        0.08327063918113708,
        0.0014822218799963593,
        0.0026577517855912447,
        0.000574281089939177,
        0.0009923320030793548,
        0.11473905295133591,
        0.00037787665496580303,
        0.007036459166556597,
        0.0007443162612617016,
        0.002525900024920702,
        0.0004936502082273364,
        0.00015091730165295303,
        0.0007894590962678194,
        0.0011130773928016424,
        0.0008715053554624319,
        0.00023306022922042757,
        0.00034646125277504325
    ],
    "val_loss": [
        0.6983519792556763,
        0.6975995302200317,
        1.5630521774291992,
        4.582061290740967,
        5.780699729919434,
        9.415807723999023,
        13.793100357055664,
        11.779693603515625,
        9.790753364562988,
        8.359952926635742,
        8.3814697265625,
        9.478113174438477,
        10.787555694580078,
        11.732755661010742,
        12.142090797424316,
        11.700981140136719,
        11.073709487915039,
        10.426233291625977,
        9.5523042678833,
        8.863689422607422,
        8.507328033447266,
        8.162343978881836,
        7.900967597961426,
        7.661877632141113,
        7.360892295837402,
        7.098845958709717,
        6.944239616394043,
        6.712518215179443,
        6.53672981262207,
        6.2220139503479,
        5.957781791687012,
        5.710467338562012
    ],
    "train_accuracy": [
        0.6875,
        0.78125,
        0.78125,
        0.84375,
        0.90625,
        0.875,
        0.875,
        0.9375,
        1.0,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.27088403701782227,
        0.04758644104003906,
        0.0814673900604248,
        0.05609393119812012,
        0.030607223510742188,
        0.04310774803161621,
        0.0691683292388916,
        0.0667874813079834,
        0.06132936477661133,
        0.07324051856994629,
        0.03585934638977051,
        0.0408329963684082,
        0.06874728202819824,
        0.07206106185913086,
        0.05508828163146973,
        0.07728743553161621,
        0.06387519836425781,
        0.029027462005615234,
        0.04931235313415527,
        0.06682538986206055,
        0.06632423400878906,
        0.02943730354309082,
        0.03293347358703613,
        0.046657562255859375,
        0.07056474685668945,
        0.07304668426513672,
        0.068206787109375,
        0.08509540557861328,
        0.06370759010314941,
        0.07049322128295898,
        0.07396841049194336
    ]
}