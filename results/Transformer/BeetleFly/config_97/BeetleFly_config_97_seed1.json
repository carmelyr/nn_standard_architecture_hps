{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1683907598725,
        "ff_dim": 673,
        "hidden_units": 447,
        "learning_rate": 0.0003099832182,
        "num_heads": 4,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 8.1860333e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.9678356051445007,
        4.450059413909912,
        1.3474611043930054,
        0.9888321161270142,
        1.2161887884140015,
        0.6749565005302429,
        1.2834807634353638,
        1.16012442111969,
        0.7753637433052063,
        0.8177761435508728,
        0.9448579549789429,
        0.9878889918327332,
        0.8412167429924011,
        0.7358537316322327,
        0.8931511044502258,
        0.9553475379943848,
        0.8627293109893799,
        0.8191115856170654,
        0.6809487342834473,
        0.7611081004142761,
        0.8035999536514282,
        0.7304530143737793,
        0.6874396800994873,
        0.7894648909568787,
        0.5877875089645386,
        0.8130909204483032,
        0.8009423017501831,
        0.8416517376899719,
        0.7215788960456848,
        0.6330418586730957,
        0.7615864276885986,
        0.6846142411231995,
        0.6497566103935242,
        0.7479972243309021,
        0.5788661241531372
    ],
    "val_loss": [
        0.3995771110057831,
        7.636702537536621,
        1.4327218532562256,
        1.0200579166412354,
        0.8525797128677368,
        0.5863763689994812,
        1.7959823608398438,
        1.8389661312103271,
        1.0574198961257935,
        0.6462382674217224,
        0.6963478922843933,
        0.6476601362228394,
        0.7340993881225586,
        1.025747299194336,
        1.1794588565826416,
        1.1351360082626343,
        0.9633369445800781,
        0.7665376663208008,
        0.7034040689468384,
        0.6782185435295105,
        0.6757652759552002,
        0.684738278388977,
        0.7100459933280945,
        0.7708972692489624,
        0.8195501565933228,
        0.8548202514648438,
        0.8729769587516785,
        0.869491457939148,
        0.8470872640609741,
        0.8103512525558472,
        0.7886857986450195,
        0.7664300203323364,
        0.7443833351135254,
        0.729607343673706,
        0.7222989201545715,
        0.7213698029518127
    ],
    "train_accuracy": [
        0.5,
        0.5625,
        0.5,
        0.5,
        0.4375,
        0.59375,
        0.5,
        0.53125,
        0.59375,
        0.59375,
        0.46875,
        0.40625,
        0.4375,
        0.53125,
        0.53125,
        0.5,
        0.59375,
        0.53125,
        0.65625,
        0.5,
        0.5,
        0.53125,
        0.5,
        0.53125,
        0.71875,
        0.53125,
        0.46875,
        0.53125,
        0.5,
        0.625,
        0.625,
        0.5625,
        0.59375,
        0.375,
        0.8125
    ],
    "val_accuracy": [
        1.0,
        0.375,
        0.5,
        0.375,
        0.625,
        0.75,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.75,
        0.75,
        0.75,
        0.375,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.19530105590820312,
        0.15389728546142578,
        0.14118289947509766,
        0.14330744743347168,
        0.14131593704223633,
        0.1419994831085205,
        0.14245939254760742,
        0.1420893669128418,
        0.14186692237854004,
        0.14153385162353516,
        0.14151525497436523,
        0.14193105697631836,
        0.14198970794677734,
        0.1425626277923584,
        0.1421976089477539,
        0.14199447631835938,
        0.1424579620361328,
        0.14252567291259766,
        0.1425158977508545,
        0.1427149772644043,
        0.14356327056884766,
        0.1426701545715332,
        0.14254260063171387,
        0.1433863639831543,
        0.14249396324157715,
        0.14238619804382324,
        0.14309310913085938,
        0.14252471923828125,
        0.14301180839538574,
        0.14328980445861816,
        0.14399051666259766,
        0.14324116706848145,
        0.14330554008483887,
        0.14360427856445312,
        0.14316678047180176
    ]
}