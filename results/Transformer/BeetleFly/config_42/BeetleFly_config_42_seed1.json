{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.0403092744102,
        "ff_dim": 422,
        "hidden_units": 132,
        "learning_rate": 0.0007862395322,
        "num_heads": 8,
        "num_layers": 1,
        "pooling": "max",
        "weight_decay": 4.12806002e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        1.6343930959701538,
        0.9683213233947754,
        0.6899153590202332,
        0.73615962266922,
        0.805083155632019,
        0.6388998031616211,
        0.7019131779670715,
        0.7335214614868164,
        0.5821530818939209,
        0.5729132890701294,
        0.6424230337142944,
        0.562732458114624,
        0.5752672553062439,
        0.4805780351161957,
        0.5345755219459534,
        0.5126567482948303,
        0.48701584339141846,
        0.4956169128417969,
        0.48593464493751526,
        0.4781668782234192,
        0.4562643766403198,
        0.5304885506629944,
        0.4396898150444031,
        0.4512070119380951,
        0.4101279675960541,
        0.46142899990081787,
        0.42344653606414795,
        0.4018093943595886,
        0.4513307511806488,
        0.43894514441490173,
        0.46407046914100647,
        0.4089619815349579,
        0.42937761545181274,
        0.43797361850738525,
        0.4562910199165344,
        0.4172484278678894
    ],
    "val_loss": [
        2.184157133102417,
        0.8299276232719421,
        0.6800740957260132,
        1.0435879230499268,
        1.018599510192871,
        0.7194417715072632,
        0.6251019835472107,
        0.6297940015792847,
        0.6344848871231079,
        0.8185480833053589,
        0.9331582188606262,
        0.8474203944206238,
        0.6859932541847229,
        0.6663490533828735,
        0.6793230772018433,
        0.7272520065307617,
        0.8193531036376953,
        0.8660959601402283,
        0.834155797958374,
        0.7916451096534729,
        0.7384225130081177,
        0.7066926956176758,
        0.6991186141967773,
        0.7100952863693237,
        0.7458598017692566,
        0.7658025026321411,
        0.794900119304657,
        0.8144014477729797,
        0.8180779814720154,
        0.8117631077766418,
        0.7988784909248352,
        0.7936684489250183,
        0.7899384498596191,
        0.7840397953987122,
        0.7802321910858154,
        0.7782553434371948,
        0.7844653129577637
    ],
    "train_accuracy": [
        0.53125,
        0.46875,
        0.53125,
        0.59375,
        0.5,
        0.5625,
        0.5,
        0.5625,
        0.65625,
        0.65625,
        0.53125,
        0.65625,
        0.78125,
        0.8125,
        0.71875,
        0.78125,
        0.84375,
        0.71875,
        0.71875,
        0.78125,
        0.8125,
        0.6875,
        0.875,
        0.8125,
        0.9375,
        0.75,
        0.90625,
        0.8125,
        0.78125,
        0.875,
        0.875,
        0.90625,
        0.84375,
        0.8125,
        0.75,
        0.8125
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.75,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.1706857681274414,
        0.04073286056518555,
        0.035514116287231445,
        0.035054922103881836,
        0.03379201889038086,
        0.03215217590332031,
        0.03048872947692871,
        0.0294492244720459,
        0.028711557388305664,
        0.028191089630126953,
        0.030503034591674805,
        0.02887725830078125,
        0.031017065048217773,
        0.029775142669677734,
        0.028919219970703125,
        0.028792142868041992,
        0.030019521713256836,
        0.028394460678100586,
        0.028703927993774414,
        0.030399560928344727,
        0.02795100212097168,
        0.02952122688293457,
        0.028455257415771484,
        0.02897930145263672,
        0.029789209365844727,
        0.028331279754638672,
        0.027493000030517578,
        0.02662801742553711,
        0.02709031105041504,
        0.02704763412475586,
        0.027578115463256836,
        0.027200698852539062,
        0.027297258377075195,
        0.02737569808959961,
        0.028592586517333984,
        0.02846074104309082
    ]
}