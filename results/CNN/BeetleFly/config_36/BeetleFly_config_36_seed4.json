{
    "hyperparameters": {
        "activation": "tanh",
        "dropout_rate": 0.010687980544,
        "kernel_size": 7,
        "learning_rate": 0.0072781949692,
        "num_filters": 245,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 37,
    "train_loss": [
        0.7631380558013916,
        1.9689260721206665,
        1.6504178047180176,
        0.7509480714797974,
        0.3809998333454132,
        0.40274226665496826,
        0.5793022513389587,
        0.3460710942745209,
        0.1969214528799057,
        0.1748008280992508,
        0.18013538420200348,
        0.17859235405921936,
        0.17900164425373077,
        0.21009744703769684,
        0.19626280665397644,
        0.19056080281734467,
        0.17915749549865723,
        0.18403621017932892,
        0.17474135756492615,
        0.16047486662864685,
        0.15299436450004578,
        0.13643285632133484,
        0.12165211141109467,
        0.10487578064203262,
        0.09829621016979218,
        0.09533566236495972,
        0.0986083447933197,
        0.11083488166332245,
        0.11738788336515427,
        0.11118859797716141,
        0.09832260757684708,
        0.08924351632595062,
        0.0891358032822609,
        0.08521236479282379,
        0.08427414298057556,
        0.08527009934186935,
        0.08652986586093903
    ],
    "val_loss": [
        0.6992340087890625,
        0.7086777687072754,
        2.2158889770507812,
        2.477686882019043,
        1.5430718660354614,
        0.7100234031677246,
        0.6544846296310425,
        0.6387031674385071,
        0.8695927858352661,
        1.2569295167922974,
        1.5962088108062744,
        1.829808235168457,
        1.9730660915374756,
        2.0544629096984863,
        2.210040330886841,
        2.358546495437622,
        2.4486188888549805,
        2.479217529296875,
        2.466247797012329,
        2.4255266189575195,
        2.371192216873169,
        2.321004629135132,
        2.275333881378174,
        2.221982955932617,
        2.1558897495269775,
        2.081916570663452,
        2.0143396854400635,
        1.973220705986023,
        1.9694817066192627,
        2.006173610687256,
        2.084713935852051,
        2.191314935684204,
        2.3100109100341797,
        2.421816825866699,
        2.5200815200805664,
        2.5965921878814697,
        2.650747537612915,
        2.6806392669677734
    ],
    "train_accuracy": [
        0.53125,
        0.4375,
        0.75,
        0.84375,
        0.875,
        0.875,
        0.53125,
        0.9375,
        0.96875,
        0.96875,
        0.9375,
        0.96875,
        0.96875,
        0.9375,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875
    ],
    "val_accuracy": [
        0.375,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.10850644111633301,
        0.021322965621948242,
        0.014734983444213867,
        0.01605081558227539,
        0.014624595642089844,
        0.014542579650878906,
        0.016392946243286133,
        0.015532970428466797,
        0.01520681381225586,
        0.014840841293334961,
        0.015226602554321289,
        0.015164852142333984,
        0.015319347381591797,
        0.015418052673339844,
        0.01504826545715332,
        0.014899730682373047,
        0.01586604118347168,
        0.015119791030883789,
        0.015944480895996094,
        0.015955686569213867,
        0.01519775390625,
        0.016087770462036133,
        0.017420530319213867,
        0.016306161880493164,
        0.016069650650024414,
        0.017916202545166016,
        0.015316963195800781,
        0.015303611755371094,
        0.015503644943237305,
        0.015467166900634766,
        0.01470637321472168,
        0.019603252410888672,
        0.017079830169677734,
        0.016076326370239258,
        0.015213727951049805,
        0.015137434005737305,
        0.014497756958007812
    ]
}