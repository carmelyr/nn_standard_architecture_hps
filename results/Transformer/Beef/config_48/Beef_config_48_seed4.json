{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2443434079187,
        "ff_dim": 419,
        "hidden_units": 482,
        "learning_rate": 8.74643457e-05,
        "num_heads": 5,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 8.01402698e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 35,
    "train_loss": [
        2.143601655960083,
        2.239478588104248,
        1.7879565954208374,
        1.6300181150436401,
        1.8135572671890259,
        1.397157073020935,
        1.6871811151504517,
        1.8045412302017212,
        1.7391830682754517,
        1.6542547941207886,
        1.7793720960617065,
        1.740278720855713,
        1.4318209886550903,
        1.7801356315612793,
        1.4468681812286377,
        1.5993192195892334,
        1.3594112396240234,
        1.4608310461044312,
        1.3437966108322144,
        1.8044995069503784,
        1.4166477918624878,
        1.3210324048995972,
        1.7446213960647583,
        1.4687256813049316,
        1.3257250785827637,
        1.3681800365447998,
        1.7641834020614624,
        1.5138986110687256,
        1.37631356716156,
        1.5496238470077515,
        1.375515103340149,
        1.4283956289291382,
        1.3506693840026855,
        1.291881799697876,
        1.6970957517623901
    ],
    "val_loss": [
        2.4716670513153076,
        1.9251092672348022,
        2.2100229263305664,
        2.0680325031280518,
        1.7781935930252075,
        1.6564397811889648,
        1.7226166725158691,
        1.8087021112442017,
        1.7934675216674805,
        1.779361367225647,
        1.7599977254867554,
        1.7804700136184692,
        1.8402248620986938,
        1.9003111124038696,
        2.015596866607666,
        2.1050291061401367,
        2.162048101425171,
        2.137336015701294,
        2.127176284790039,
        2.1304049491882324,
        2.13210129737854,
        2.139533758163452,
        2.1287200450897217,
        2.123685359954834,
        2.119253158569336,
        2.1148483753204346,
        2.10898756980896,
        2.1014106273651123,
        2.1020047664642334,
        2.1138722896575928,
        2.120542287826538,
        2.124154806137085,
        2.129136085510254,
        2.140610456466675,
        2.1512322425842285,
        2.161033868789673
    ],
    "train_accuracy": [
        0.1875,
        0.0625,
        0.25,
        0.4375,
        0.5,
        0.375,
        0.3125,
        0.25,
        0.25,
        0.3125,
        0.1875,
        0.3125,
        0.1875,
        0.0625,
        0.375,
        0.25,
        0.5625,
        0.375,
        0.5,
        0.3125,
        0.375,
        0.3125,
        0.3125,
        0.5,
        0.3125,
        0.4375,
        0.125,
        0.3125,
        0.3125,
        0.25,
        0.4375,
        0.375,
        0.4375,
        0.375,
        0.375
    ],
    "val_accuracy": [
        0.25,
        0.0833333358168602,
        0.1666666716337204,
        0.0833333358168602,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.25,
        0.3333333432674408,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408
    ],
    "epoch_times": [
        0.13126683235168457,
        0.11270546913146973,
        0.11326360702514648,
        0.11246275901794434,
        0.1122279167175293,
        0.11217880249023438,
        0.11378169059753418,
        0.11344099044799805,
        0.11300969123840332,
        0.11191272735595703,
        0.11232662200927734,
        0.11214518547058105,
        0.11266589164733887,
        0.11301326751708984,
        0.1143043041229248,
        0.1133584976196289,
        0.11285758018493652,
        0.11296272277832031,
        0.11385202407836914,
        0.11365652084350586,
        0.11306619644165039,
        0.11249518394470215,
        0.113555908203125,
        0.1124732494354248,
        0.11198806762695312,
        0.11246657371520996,
        0.11223459243774414,
        0.1121981143951416,
        0.11215806007385254,
        0.1116647720336914,
        0.11258745193481445,
        0.11154580116271973,
        0.11249017715454102,
        0.11218404769897461,
        0.1125185489654541
    ]
}