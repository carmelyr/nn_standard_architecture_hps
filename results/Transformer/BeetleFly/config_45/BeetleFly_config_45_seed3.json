{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1894201741382,
        "ff_dim": 374,
        "hidden_units": 347,
        "learning_rate": 3.86354961e-05,
        "num_heads": 8,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 9.6499281e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.8172264695167542,
        0.8545073866844177,
        0.7012681365013123,
        0.7862668633460999,
        0.823377251625061,
        0.8133238554000854,
        0.8671215772628784,
        0.9315246343612671,
        0.8923954963684082,
        0.8466483354568481,
        0.6471765637397766,
        0.8602586388587952,
        0.8088447451591492,
        1.0212706327438354,
        0.7014338970184326,
        0.7359493970870972,
        0.8211404085159302,
        0.7932205200195312,
        0.9219896793365479,
        0.9865846037864685,
        0.7347027659416199,
        0.6930376887321472,
        0.7464430332183838,
        0.6129492521286011,
        0.624739944934845,
        0.7166364192962646,
        0.6845970749855042,
        0.7221883535385132,
        0.6946219205856323,
        0.7233836650848389,
        0.7806220054626465,
        0.8973982334136963,
        0.7068982124328613,
        0.70979243516922,
        0.6295586228370667
    ],
    "val_loss": [
        0.6688388586044312,
        0.5111963748931885,
        0.49482297897338867,
        0.519834578037262,
        0.5024675130844116,
        0.48642316460609436,
        0.4922402799129486,
        0.5299831628799438,
        0.5971895456314087,
        0.6484798192977905,
        0.6536328792572021,
        0.6448639631271362,
        0.6249350309371948,
        0.5979323387145996,
        0.5715736150741577,
        0.5485010743141174,
        0.5310742855072021,
        0.5217421054840088,
        0.5198485851287842,
        0.5198267102241516,
        0.5211291313171387,
        0.5224206447601318,
        0.5238723754882812,
        0.5266769528388977,
        0.5279844999313354,
        0.5294221639633179,
        0.5309268832206726,
        0.5320589542388916,
        0.5331289172172546,
        0.5343387722969055,
        0.5349751710891724,
        0.5356177687644958,
        0.5364456176757812,
        0.5374462008476257,
        0.5380641222000122,
        0.5381322503089905
    ],
    "train_accuracy": [
        0.40625,
        0.46875,
        0.5,
        0.5625,
        0.46875,
        0.53125,
        0.46875,
        0.375,
        0.5,
        0.53125,
        0.625,
        0.53125,
        0.59375,
        0.46875,
        0.5625,
        0.5625,
        0.53125,
        0.53125,
        0.5,
        0.375,
        0.59375,
        0.53125,
        0.53125,
        0.625,
        0.65625,
        0.53125,
        0.53125,
        0.65625,
        0.53125,
        0.5,
        0.59375,
        0.375,
        0.5625,
        0.53125,
        0.625
    ],
    "val_accuracy": [
        0.5,
        0.75,
        0.875,
        0.75,
        0.75,
        0.875,
        0.875,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.12076210975646973,
        0.1257617473602295,
        0.1164097785949707,
        0.11738395690917969,
        0.11766529083251953,
        0.11691617965698242,
        0.11539244651794434,
        0.11507940292358398,
        0.11562895774841309,
        0.11534547805786133,
        0.11429452896118164,
        0.11587643623352051,
        0.11640071868896484,
        0.1170344352722168,
        0.11359572410583496,
        0.11392354965209961,
        0.11477398872375488,
        0.11659049987792969,
        0.12188220024108887,
        0.11485433578491211,
        0.11519026756286621,
        0.11594581604003906,
        0.11581754684448242,
        0.11393427848815918,
        0.11651444435119629,
        0.11573553085327148,
        0.11528515815734863,
        0.1164388656616211,
        0.11601924896240234,
        0.11510658264160156,
        0.11545372009277344,
        0.11655759811401367,
        0.11622333526611328,
        0.11555075645446777,
        0.1156773567199707
    ]
}