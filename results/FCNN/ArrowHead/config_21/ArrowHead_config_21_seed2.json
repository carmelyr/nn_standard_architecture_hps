{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1161541621413,
        "hidden_units": 16,
        "learning_rate": 0.0141387289096,
        "num_layers": 4,
        "weight_decay": 0.0008062542693
    },
    "dataset_stats": {
        "name": "ArrowHead",
        "train_size": 49,
        "val_size": 12,
        "input_shape": [
            251,
            1
        ],
        "num_classes": 3
    },
    "epochs": 31,
    "train_loss": [
        1.413329005241394,
        1.1301697492599487,
        0.9611842632293701,
        0.8939306139945984,
        0.8369995951652527,
        0.8307520151138306,
        0.7931187152862549,
        0.7903060913085938,
        0.7250193357467651,
        0.709621012210846,
        0.6999024152755737,
        0.6841484904289246,
        0.6126864552497864,
        0.5855080485343933,
        0.5981505513191223,
        0.5101603269577026,
        0.6763512492179871,
        0.5548756122589111,
        0.601883053779602,
        0.5505269765853882,
        0.5643010139465332,
        0.5178138613700867,
        0.6408776044845581,
        0.5660337805747986,
        0.5069878101348877,
        0.5617968440055847,
        0.5437528491020203,
        0.45890021324157715,
        0.6133183836936951,
        0.4327438771724701,
        0.39525705575942993
    ],
    "val_loss": [
        1.1305745840072632,
        1.1145445108413696,
        1.1263912916183472,
        1.1233494281768799,
        1.1260632276535034,
        1.1230500936508179,
        1.1323542594909668,
        1.1893936395645142,
        1.2431985139846802,
        1.287788987159729,
        1.382999062538147,
        1.5258146524429321,
        1.7130554914474487,
        1.9231672286987305,
        2.1652984619140625,
        2.3922817707061768,
        2.6742918491363525,
        2.9360711574554443,
        3.289733648300171,
        3.55561900138855,
        3.793494462966919,
        3.9536428451538086,
        4.101686477661133,
        4.5284576416015625,
        4.588991165161133,
        4.687143325805664,
        4.645716190338135,
        4.768528938293457,
        4.943694114685059,
        5.139286041259766,
        5.286809921264648,
        5.369295120239258
    ],
    "train_accuracy": [
        0.2448979616165161,
        0.36734694242477417,
        0.4693877696990967,
        0.6122449040412903,
        0.6530612111091614,
        0.5714285969734192,
        0.6122449040412903,
        0.6734693646430969,
        0.6122449040412903,
        0.6122449040412903,
        0.6734693646430969,
        0.7142857313156128,
        0.7142857313156128,
        0.6734693646430969,
        0.7551020383834839,
        0.795918345451355,
        0.6734693646430969,
        0.7755101919174194,
        0.7346938848495483,
        0.8163265585899353,
        0.7551020383834839,
        0.8367347121238708,
        0.7551020383834839,
        0.7142857313156128,
        0.7551020383834839,
        0.7142857313156128,
        0.7551020383834839,
        0.8571428656578064,
        0.7142857313156128,
        0.795918345451355,
        0.8367347121238708
    ],
    "val_accuracy": [
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.0833333358168602,
        0.1666666716337204,
        0.25,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.04173588752746582,
        0.028012990951538086,
        0.029018878936767578,
        0.028350830078125,
        0.02776026725769043,
        0.028123140335083008,
        0.027450084686279297,
        0.027926206588745117,
        0.02929401397705078,
        0.027994155883789062,
        0.027690887451171875,
        0.02863478660583496,
        0.02820301055908203,
        0.027278900146484375,
        0.027257919311523438,
        0.02848505973815918,
        0.02829909324645996,
        0.027919292449951172,
        0.0285341739654541,
        0.02728867530822754,
        0.027730226516723633,
        0.027431249618530273,
        0.030544042587280273,
        0.030251026153564453,
        0.03043198585510254,
        0.03520679473876953,
        0.028204917907714844,
        0.027956008911132812,
        0.027687788009643555,
        0.02812790870666504,
        0.027478694915771484
    ]
}