{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1426651722736,
        "ff_dim": 560,
        "hidden_units": 67,
        "learning_rate": 7.79580829e-05,
        "num_heads": 3,
        "num_layers": 5,
        "pooling": "mean",
        "weight_decay": 5.76420282e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        2.274829149246216,
        1.9467933177947998,
        1.5240873098373413,
        1.7693642377853394,
        1.4294589757919312,
        1.8755669593811035,
        1.2175246477127075,
        1.0755971670150757,
        1.0537219047546387,
        1.245348334312439,
        1.2925299406051636,
        1.4138463735580444,
        1.228729009628296,
        1.1576284170150757,
        0.9377448558807373,
        1.2256736755371094,
        1.5621135234832764,
        1.2902990579605103,
        1.0166281461715698,
        1.441056489944458,
        1.3836923837661743,
        1.0519636869430542,
        1.4559180736541748,
        1.1385915279388428,
        1.1339361667633057,
        1.1337686777114868,
        1.1737059354782104,
        1.1996303796768188,
        1.391493320465088,
        1.487027883529663,
        1.4440678358078003,
        1.1270568370819092,
        1.0607329607009888
    ],
    "val_loss": [
        4.153951168060303,
        2.118809223175049,
        1.5547430515289307,
        1.3605998754501343,
        1.4283268451690674,
        1.4959856271743774,
        1.5624107122421265,
        1.4757035970687866,
        1.4504599571228027,
        1.4740495681762695,
        1.4714442491531372,
        1.476405143737793,
        1.4962410926818848,
        1.506836175918579,
        1.5037107467651367,
        1.5255894660949707,
        1.534084677696228,
        1.5209672451019287,
        1.5095072984695435,
        1.4956475496292114,
        1.499334454536438,
        1.4936977624893188,
        1.4930107593536377,
        1.4868879318237305,
        1.4880664348602295,
        1.4941807985305786,
        1.497610330581665,
        1.4975714683532715,
        1.499316692352295,
        1.5013352632522583,
        1.503944993019104,
        1.5106247663497925,
        1.5120065212249756,
        1.5165460109710693
    ],
    "train_accuracy": [
        0.3125,
        0.0625,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.375,
        0.5,
        0.5625,
        0.375,
        0.4375,
        0.4375,
        0.5625,
        0.5,
        0.6875,
        0.375,
        0.25,
        0.375,
        0.625,
        0.3125,
        0.375,
        0.6875,
        0.3125,
        0.4375,
        0.5,
        0.4375,
        0.4375,
        0.6875,
        0.375,
        0.1875,
        0.375,
        0.5,
        0.5
    ],
    "val_accuracy": [
        0.0625,
        0.125,
        0.1875,
        0.1875,
        0.1875,
        0.25,
        0.125,
        0.1875,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.5714468955993652,
        0.5030806064605713,
        0.506096601486206,
        0.5020542144775391,
        0.5021429061889648,
        0.5047147274017334,
        0.5044989585876465,
        0.5079400539398193,
        0.5030288696289062,
        0.5068936347961426,
        0.5047080516815186,
        0.5084381103515625,
        0.5078368186950684,
        0.5036966800689697,
        0.5077016353607178,
        0.5086901187896729,
        0.5055503845214844,
        0.5070381164550781,
        0.5037307739257812,
        0.5074353218078613,
        0.50925612449646,
        0.5066096782684326,
        0.5096259117126465,
        0.5046231746673584,
        0.50443434715271,
        0.5083041191101074,
        0.5051150321960449,
        0.5061118602752686,
        0.5097806453704834,
        0.5077362060546875,
        0.5096702575683594,
        0.5088129043579102,
        0.5073151588439941
    ]
}