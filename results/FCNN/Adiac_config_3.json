{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.3946527684516,
        "hidden_units": 38,
        "learning_rate": 0.0681999832467,
        "num_layers": 1,
        "weight_decay": 0.0065264658318
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 312,
        "val_size": 78,
        "input_shape": [
            176,
            1
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.362513542175293,
        3.029343843460083,
        2.832221269607544,
        2.787897825241089,
        2.5634398460388184,
        3.097856283187866,
        2.4978373050689697,
        3.0449774265289307,
        2.375098705291748,
        2.4277217388153076,
        2.643829345703125,
        2.3585550785064697,
        2.10768723487854,
        2.45133113861084,
        2.4207379817962646
    ],
    "val_loss": [
        3.661166191101074,
        11.448680877685547,
        4.425873279571533,
        9.567957878112793,
        11.159927368164062,
        5.631375789642334,
        10.645811080932617,
        4.830292701721191,
        9.824625015258789,
        23.789794921875,
        6.733763217926025,
        19.049753189086914,
        7.625499248504639,
        13.34439468383789,
        11.80299186706543,
        5.366694450378418
    ],
    "train_accuracy": [
        0.125,
        0.3333333432674408,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.125,
        0.2916666567325592,
        0.25,
        0.375,
        0.2916666567325592,
        0.3333333432674408,
        0.2083333283662796,
        0.2916666567325592,
        0.1666666716337204,
        0.2083333283662796
    ],
    "val_accuracy": [
        0.015625,
        0.012820512987673283,
        0.06410256773233414,
        0.05128205195069313,
        0.025641025975346565,
        0.06410256773233414,
        0.012820512987673283,
        0.11538461595773697,
        0.05128205195069313,
        0.025641025975346565,
        0.05128205195069313,
        0.025641025975346565,
        0.06410256773233414,
        0.012820512987673283,
        0.07692307978868484,
        0.08974359184503555
    ]
}