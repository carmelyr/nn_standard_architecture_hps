{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2078706140663,
        "ff_dim": 417,
        "hidden_units": 309,
        "learning_rate": 0.0001992767244,
        "num_heads": 3,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 3.60552825e-05
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 33,
    "train_loss": [
        0.8286874890327454,
        1.3633553981781006,
        0.9571083784103394,
        0.8168363571166992,
        1.0570859909057617,
        0.7909587621688843,
        0.6711907982826233,
        0.8533932566642761,
        0.9182856678962708,
        0.9817290306091309,
        0.778022050857544,
        0.8180797100067139,
        0.7415362000465393,
        0.6411047577857971,
        0.7029649019241333,
        0.7430290579795837,
        0.8647239804267883,
        0.719182550907135,
        0.6829772591590881,
        0.7875428199768066,
        0.7062023878097534,
        0.7814657092094421,
        0.7850584983825684,
        0.724960446357727,
        0.7079174518585205,
        0.7336758375167847,
        0.7175471186637878,
        0.6778632998466492,
        0.8019555807113647,
        0.7182009816169739,
        0.6977894306182861,
        0.6013169884681702,
        0.6698592901229858
    ],
    "val_loss": [
        0.6693613529205322,
        3.1844823360443115,
        2.16172456741333,
        0.7044541835784912,
        0.7712504863739014,
        0.7136306762695312,
        0.794508159160614,
        1.319908857345581,
        1.435903787612915,
        1.1162137985229492,
        0.8873335123062134,
        0.7365161776542664,
        0.7254986763000488,
        0.7417399287223816,
        0.7383462190628052,
        0.717272937297821,
        0.7160887718200684,
        0.7247008681297302,
        0.7489326000213623,
        0.7734050750732422,
        0.7868752479553223,
        0.799077033996582,
        0.7975205779075623,
        0.7868284583091736,
        0.7721998691558838,
        0.7574944496154785,
        0.7467703223228455,
        0.7412304878234863,
        0.7393673062324524,
        0.7377538084983826,
        0.7362085580825806,
        0.7332339882850647,
        0.7305936813354492,
        0.7276529669761658
    ],
    "train_accuracy": [
        0.53125,
        0.53125,
        0.5625,
        0.5,
        0.4375,
        0.4375,
        0.5625,
        0.5625,
        0.5,
        0.5,
        0.59375,
        0.5625,
        0.5625,
        0.59375,
        0.625,
        0.5625,
        0.40625,
        0.5625,
        0.5625,
        0.375,
        0.53125,
        0.46875,
        0.5,
        0.5625,
        0.5625,
        0.46875,
        0.59375,
        0.53125,
        0.4375,
        0.59375,
        0.59375,
        0.65625,
        0.53125
    ],
    "val_accuracy": [
        0.625,
        0.375,
        0.375,
        0.5,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.5,
        0.625,
        0.5,
        0.5,
        0.625,
        0.625,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.20881938934326172,
        0.11637473106384277,
        0.11559224128723145,
        0.1163330078125,
        0.1151890754699707,
        0.11725831031799316,
        0.11842966079711914,
        0.11820006370544434,
        0.1192171573638916,
        0.11690616607666016,
        0.11706852912902832,
        0.1164999008178711,
        0.11923527717590332,
        0.11675643920898438,
        0.11729741096496582,
        0.11682343482971191,
        0.11598634719848633,
        0.11683034896850586,
        0.1187436580657959,
        0.11666584014892578,
        0.11662054061889648,
        0.11676692962646484,
        0.11724710464477539,
        0.1160576343536377,
        0.11518192291259766,
        0.11784124374389648,
        0.11341166496276855,
        0.11589455604553223,
        0.11797666549682617,
        0.11591410636901855,
        0.11587071418762207,
        0.11768984794616699,
        0.11770129203796387
    ]
}