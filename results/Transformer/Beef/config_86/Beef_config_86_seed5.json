{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.0010936313822,
        "ff_dim": 301,
        "hidden_units": 310,
        "learning_rate": 4.33077252e-05,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 4.9994474e-06
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 32,
    "train_loss": [
        1.6559756994247437,
        1.4200451374053955,
        1.5172408819198608,
        1.4847848415374756,
        1.1739766597747803,
        1.3215010166168213,
        1.5570536851882935,
        1.3173260688781738,
        1.248165249824524,
        0.8529319167137146,
        1.067293405532837,
        1.401985764503479,
        1.0059198141098022,
        1.0105948448181152,
        1.3953205347061157,
        1.008050799369812,
        1.0235404968261719,
        0.9875165224075317,
        1.030778408050537,
        1.1686820983886719,
        1.15545654296875,
        0.8577373027801514,
        1.1141481399536133,
        1.300775408744812,
        0.9581376910209656,
        1.2371506690979004,
        1.0278708934783936,
        0.9249930381774902,
        1.1397944688796997,
        1.0443140268325806,
        0.8719091415405273,
        0.8021013736724854
    ],
    "val_loss": [
        2.209885597229004,
        1.9365267753601074,
        1.5135507583618164,
        1.5179885625839233,
        1.5629652738571167,
        1.6035184860229492,
        1.750307559967041,
        1.6857880353927612,
        1.649221420288086,
        1.6713639497756958,
        1.6475228071212769,
        1.6264681816101074,
        1.6635375022888184,
        1.7191368341445923,
        1.7660046815872192,
        1.7694147825241089,
        1.7473764419555664,
        1.7179194688796997,
        1.6959975957870483,
        1.665877342224121,
        1.6461464166641235,
        1.638318419456482,
        1.6331740617752075,
        1.6282726526260376,
        1.6300358772277832,
        1.6300996541976929,
        1.6328368186950684,
        1.6356124877929688,
        1.637837529182434,
        1.6426082849502563,
        1.645491123199463,
        1.6465457677841187,
        1.6487340927124023
    ],
    "train_accuracy": [
        0.375,
        0.4375,
        0.1875,
        0.4375,
        0.5,
        0.5625,
        0.25,
        0.5,
        0.4375,
        0.625,
        0.6875,
        0.4375,
        0.75,
        0.5,
        0.4375,
        0.8125,
        0.625,
        0.5,
        0.75,
        0.625,
        0.4375,
        0.8125,
        0.625,
        0.4375,
        0.5625,
        0.5625,
        0.5625,
        0.75,
        0.5,
        0.75,
        0.625,
        0.8125
    ],
    "val_accuracy": [
        0.0833333358168602,
        0.1666666716337204,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.3333333432674408,
        0.5,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5833333730697632,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.2016305923461914,
        0.14409470558166504,
        0.14113974571228027,
        0.14425063133239746,
        0.14088726043701172,
        0.13962292671203613,
        0.14009904861450195,
        0.139359712600708,
        0.13791942596435547,
        0.13837504386901855,
        0.14026498794555664,
        0.13897061347961426,
        0.13763093948364258,
        0.14031195640563965,
        0.1403059959411621,
        0.14278912544250488,
        0.14142131805419922,
        0.14443016052246094,
        0.1382129192352295,
        0.13868236541748047,
        0.13904905319213867,
        0.14563870429992676,
        0.13909506797790527,
        0.13793492317199707,
        0.14016342163085938,
        0.14016318321228027,
        0.14050674438476562,
        0.1397397518157959,
        0.13849091529846191,
        0.13929438591003418,
        0.1389482021331787,
        0.14034247398376465
    ]
}