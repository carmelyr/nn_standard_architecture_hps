{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0830843675864,
        "ff_dim": 969,
        "hidden_units": 164,
        "learning_rate": 7.97113417e-05,
        "num_heads": 7,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 7.47559508e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        1.4254357814788818,
        1.4204516410827637,
        1.4512684345245361,
        1.5157769918441772,
        1.1743266582489014,
        1.2961969375610352,
        1.0454719066619873,
        1.3256182670593262,
        1.463067650794983,
        1.0086004734039307,
        1.1783699989318848,
        0.9322263598442078,
        1.0706700086593628,
        0.9066495895385742,
        1.0409884452819824,
        1.124009132385254,
        0.9517102837562561,
        0.9445459246635437,
        0.7668809294700623,
        1.0438753366470337,
        0.7841122150421143,
        0.7582530975341797,
        1.0112415552139282,
        0.8967411518096924,
        1.2296323776245117,
        1.197004795074463,
        0.9807454943656921,
        1.0042232275009155,
        0.8965620398521423,
        0.9972952604293823,
        1.1757277250289917,
        1.1275126934051514,
        0.8689736127853394
    ],
    "val_loss": [
        2.1391396522521973,
        1.614270806312561,
        1.5335512161254883,
        1.3272839784622192,
        1.434970498085022,
        1.4975895881652832,
        1.4301238059997559,
        1.3272066116333008,
        1.435961365699768,
        1.4763619899749756,
        1.4478422403335571,
        1.5287421941757202,
        1.441171646118164,
        1.4667541980743408,
        1.595339059829712,
        1.7123886346817017,
        1.7423416376113892,
        1.7103098630905151,
        1.642496109008789,
        1.6431927680969238,
        1.6467870473861694,
        1.6849578619003296,
        1.6758908033370972,
        1.6973552703857422,
        1.724245309829712,
        1.7583318948745728,
        1.764055848121643,
        1.7564982175827026,
        1.7415363788604736,
        1.7306993007659912,
        1.7220075130462646,
        1.713165044784546,
        1.7239056825637817,
        1.71950364112854
    ],
    "train_accuracy": [
        0.25,
        0.4375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5625,
        0.3125,
        0.3125,
        0.4375,
        0.5,
        0.625,
        0.5,
        0.5625,
        0.5625,
        0.5625,
        0.625,
        0.5625,
        0.75,
        0.5,
        0.6875,
        0.875,
        0.5,
        0.75,
        0.5,
        0.375,
        0.625,
        0.6875,
        0.625,
        0.5,
        0.5625,
        0.4375,
        0.625
    ],
    "val_accuracy": [
        0.3125,
        0.4375,
        0.4375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        1.0940496921539307,
        1.0946474075317383,
        1.0951635837554932,
        1.0961360931396484,
        1.0966911315917969,
        1.101381540298462,
        1.1014015674591064,
        1.1035640239715576,
        1.104245901107788,
        1.1050302982330322,
        1.1030235290527344,
        1.1028125286102295,
        1.105360746383667,
        1.1038033962249756,
        1.1052658557891846,
        1.1059565544128418,
        1.1050105094909668,
        1.1064157485961914,
        1.10563063621521,
        1.1057603359222412,
        1.106426477432251,
        1.1053409576416016,
        1.1046581268310547,
        1.1088793277740479,
        1.111694574356079,
        1.1083741188049316,
        1.1063714027404785,
        1.1067075729370117,
        1.1081740856170654,
        1.1067206859588623,
        1.110732078552246,
        1.1105573177337646,
        1.1053204536437988
    ]
}