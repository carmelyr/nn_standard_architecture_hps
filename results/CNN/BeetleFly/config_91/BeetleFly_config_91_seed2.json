{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2610583810687,
        "kernel_size": 4,
        "learning_rate": 0.0008117377402,
        "num_filters": 217,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 38,
    "train_loss": [
        0.7416627407073975,
        0.480144739151001,
        0.31155598163604736,
        0.23448091745376587,
        0.1320810317993164,
        0.11673350632190704,
        0.07020631432533264,
        0.10652871429920197,
        0.060304176062345505,
        0.03351111710071564,
        0.13187366724014282,
        0.03968237340450287,
        0.014386297203600407,
        0.12423105537891388,
        0.012484713457524776,
        0.004198175389319658,
        0.020843492820858955,
        0.01963726244866848,
        0.010255596600472927,
        0.005973705090582371,
        0.006966347340494394,
        0.01993345282971859,
        0.003672169055789709,
        0.004200267605483532,
        0.11453543603420258,
        0.005343356169760227,
        0.008401423692703247,
        0.0009651621803641319,
        0.004059838596731424,
        0.030108114704489708,
        0.0069888136349618435,
        0.00474023399874568,
        0.0013087003026157618,
        0.009249774739146233,
        0.0006017661653459072,
        0.0002226341748610139,
        0.00020135850354563445,
        0.04554992541670799
    ],
    "val_loss": [
        0.6884033679962158,
        0.6877040863037109,
        0.6830552816390991,
        0.6760505437850952,
        0.6703833341598511,
        0.6638593077659607,
        0.655508816242218,
        0.6479857563972473,
        0.6440091729164124,
        0.6486220955848694,
        0.6648381948471069,
        0.6902512907981873,
        0.7302826046943665,
        0.7762532830238342,
        0.8270441889762878,
        0.9023061990737915,
        1.0022212266921997,
        1.112408995628357,
        1.1961045265197754,
        1.2769991159439087,
        1.3792929649353027,
        1.5225260257720947,
        1.6642943620681763,
        1.8271082639694214,
        1.9722394943237305,
        2.2877328395843506,
        2.626587152481079,
        2.8721015453338623,
        3.08809757232666,
        3.2549233436584473,
        3.2949607372283936,
        3.2943363189697266,
        3.2371058464050293,
        3.1940932273864746,
        3.098918914794922,
        3.190328598022461,
        3.388282060623169,
        3.5464072227478027,
        3.5047447681427
    ],
    "train_accuracy": [
        0.53125,
        0.8125,
        0.84375,
        0.90625,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        0.9375,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.375,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.03816652297973633,
        0.07413101196289062,
        0.022942304611206055,
        0.025602340698242188,
        0.023360013961791992,
        0.025194168090820312,
        0.025036096572875977,
        0.02538609504699707,
        0.02633070945739746,
        0.02582406997680664,
        0.026311397552490234,
        0.026942014694213867,
        0.02682781219482422,
        0.02698516845703125,
        0.026370763778686523,
        0.025348186492919922,
        0.02633833885192871,
        0.026331186294555664,
        0.026032447814941406,
        0.026923656463623047,
        0.02887558937072754,
        0.026018619537353516,
        0.026142358779907227,
        0.024211406707763672,
        0.023889780044555664,
        0.023743629455566406,
        0.02257823944091797,
        0.02217888832092285,
        0.022919178009033203,
        0.022867441177368164,
        0.021765947341918945,
        0.02118968963623047,
        0.021264076232910156,
        0.02265000343322754,
        0.022076129913330078,
        0.0244138240814209,
        0.023842334747314453,
        0.022240638732910156
    ]
}