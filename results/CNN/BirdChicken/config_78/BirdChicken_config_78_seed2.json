{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.4890716569931,
        "kernel_size": 6,
        "learning_rate": 0.0026115694706,
        "num_filters": 191,
        "num_layers": 4,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.8141508102416992,
        0.853358268737793,
        0.67464679479599,
        0.6790059208869934,
        0.40518927574157715,
        0.26947054266929626,
        0.48677146434783936,
        0.27859580516815186,
        0.38832348585128784,
        0.16593144834041595,
        0.5122397541999817,
        0.517151415348053,
        0.40454214811325073,
        0.40588295459747314,
        0.5828394293785095,
        0.14047455787658691,
        0.1683332473039627,
        0.5613595247268677,
        0.32468804717063904,
        0.16611695289611816,
        0.08846770972013474,
        0.12801909446716309,
        0.3338620066642761,
        0.09677469730377197,
        0.1668272614479065,
        0.04647170007228851,
        0.29136571288108826,
        0.06501977890729904,
        0.026769690215587616,
        0.29096242785453796,
        0.056877557188272476,
        0.03172538802027702,
        0.023187056183815002,
        0.05951583757996559
    ],
    "val_loss": [
        0.6958939433097839,
        0.6937247514724731,
        0.6896268725395203,
        0.689900815486908,
        0.6894823312759399,
        0.716816782951355,
        0.7560298442840576,
        0.7998473048210144,
        0.902755856513977,
        1.0794938802719116,
        1.316859245300293,
        1.5454535484313965,
        1.7471749782562256,
        1.9445092678070068,
        2.162961721420288,
        2.3661279678344727,
        2.589186191558838,
        2.7668659687042236,
        2.861689805984497,
        2.9545066356658936,
        3.1739511489868164,
        3.4699227809906006,
        3.800187349319458,
        3.832994222640991,
        3.661367177963257,
        3.4109346866607666,
        3.3214282989501953,
        3.1256940364837646,
        2.9903626441955566,
        2.936152935028076,
        2.8991129398345947,
        2.7984142303466797,
        2.877079486846924,
        3.1138129234313965,
        3.4115748405456543
    ],
    "train_accuracy": [
        0.4375,
        0.5,
        0.75,
        0.65625,
        0.875,
        0.875,
        0.8125,
        0.875,
        0.90625,
        0.9375,
        0.875,
        0.875,
        0.84375,
        0.8125,
        0.90625,
        0.90625,
        0.9375,
        0.84375,
        0.84375,
        0.90625,
        0.96875,
        0.96875,
        0.8125,
        0.9375,
        0.96875,
        1.0,
        0.90625,
        1.0,
        1.0,
        0.9375,
        0.96875,
        0.96875,
        1.0,
        0.96875
    ],
    "val_accuracy": [
        0.375,
        0.5,
        0.5,
        0.625,
        0.75,
        0.625,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.09584665298461914,
        0.16767668724060059,
        0.04065060615539551,
        0.037053585052490234,
        0.03351593017578125,
        0.03153228759765625,
        0.02556777000427246,
        0.02582836151123047,
        0.025899648666381836,
        0.025178909301757812,
        0.025912761688232422,
        0.02496790885925293,
        0.024555206298828125,
        0.025814533233642578,
        0.02801370620727539,
        0.024980545043945312,
        0.02605605125427246,
        0.025696516036987305,
        0.02664947509765625,
        0.028101682662963867,
        0.028028011322021484,
        0.026329517364501953,
        0.025421619415283203,
        0.02677297592163086,
        0.026539087295532227,
        0.022354841232299805,
        0.019031047821044922,
        0.02248549461364746,
        0.027149438858032227,
        0.02606058120727539,
        0.02580404281616211,
        0.026543617248535156,
        0.026169776916503906,
        0.025602340698242188
    ]
}