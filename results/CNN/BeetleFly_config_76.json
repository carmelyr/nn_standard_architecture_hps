{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.1632330199072,
        "kernel_size": 6,
        "learning_rate": 0.0015296552008,
        "num_filters": 208,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8656997084617615,
        0.6430155038833618,
        0.5209452509880066,
        0.24484136700630188,
        0.2164091169834137,
        0.19490931928157806,
        0.14054517447948456,
        0.12342824041843414,
        0.10813243687152863,
        0.10930976271629333,
        0.10391141474246979,
        0.07971756905317307,
        0.07446364313364029,
        0.06574568897485733,
        0.06104160472750664,
        0.05125756934285164,
        0.047242723405361176,
        0.043846260756254196,
        0.04741424322128296,
        0.03861413151025772,
        0.03918832913041115,
        0.026748692616820335,
        0.023928899317979813,
        0.02114633284509182,
        0.02702883444726467,
        0.026326285675168037,
        0.026342084631323814,
        0.018055176362395287,
        0.01614685356616974,
        0.014864813536405563,
        0.012470354326069355,
        0.012138670310378075
    ],
    "val_loss": [
        0.6741995811462402,
        1.011009693145752,
        0.601772129535675,
        0.7211621999740601,
        1.088034987449646,
        1.2101218700408936,
        1.1386370658874512,
        1.0460774898529053,
        1.0136017799377441,
        1.0786269903182983,
        1.238044023513794,
        1.4705764055252075,
        1.661505103111267,
        1.792719841003418,
        1.8832342624664307,
        1.9591926336288452,
        1.968550205230713,
        1.9444881677627563,
        1.8965990543365479,
        1.9155840873718262,
        1.9613529443740845,
        1.9904367923736572,
        2.016880989074707,
        2.0441348552703857,
        2.0726027488708496,
        2.151872158050537,
        2.260251045227051,
        2.4137110710144043,
        2.5377204418182373,
        2.6139867305755615,
        2.6584839820861816,
        2.681349992752075,
        2.6803464889526367
    ],
    "train_accuracy": [
        0.46875,
        0.78125,
        0.78125,
        0.875,
        0.875,
        0.90625,
        0.96875,
        0.9375,
        0.96875,
        0.9375,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.1367475986480713,
        0.04399275779724121,
        0.020343780517578125,
        0.06282687187194824,
        0.02519965171813965,
        0.02090167999267578,
        0.0552370548248291,
        0.027789831161499023,
        0.04646730422973633,
        0.025006532669067383,
        0.023426294326782227,
        0.023540019989013672,
        0.02137446403503418,
        0.05848813056945801,
        0.02109527587890625,
        0.045404672622680664,
        0.023875713348388672,
        0.021155595779418945,
        0.06525778770446777,
        0.020148754119873047,
        0.02052140235900879,
        0.06855630874633789,
        0.02039957046508789,
        0.05020594596862793,
        0.020806312561035156,
        0.022765636444091797,
        0.06308174133300781,
        0.02258610725402832,
        0.04229259490966797,
        0.021453380584716797,
        0.04829001426696777,
        0.07239270210266113
    ]
}