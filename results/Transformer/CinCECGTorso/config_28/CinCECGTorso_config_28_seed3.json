{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        1.9485697746276855,
        1.7359205484390259,
        1.5502153635025024,
        1.7271549701690674,
        1.561361312866211,
        1.3817064762115479,
        1.3276543617248535,
        1.5626121759414673,
        1.5174624919891357,
        1.4157217741012573,
        1.7442878484725952,
        1.6434223651885986,
        1.494328498840332,
        1.4958199262619019,
        1.597400426864624,
        1.3776166439056396,
        1.1923227310180664,
        1.2197887897491455,
        1.3623923063278198,
        1.907508373260498,
        1.764173150062561,
        1.189799189567566,
        1.347463607788086,
        1.5027780532836914,
        1.6621003150939941,
        1.496690034866333,
        1.3795992136001587,
        1.3260385990142822,
        1.4869108200073242,
        1.5434905290603638,
        1.3237305879592896,
        1.1521023511886597,
        1.6852378845214844
    ],
    "val_loss": [
        3.950449228286743,
        2.265857458114624,
        1.3880443572998047,
        1.1892874240875244,
        1.217716097831726,
        1.2642285823822021,
        1.25054931640625,
        1.241446614265442,
        1.2578834295272827,
        1.2751632928848267,
        1.259896993637085,
        1.2530508041381836,
        1.2485392093658447,
        1.2362269163131714,
        1.226192593574524,
        1.2146954536437988,
        1.211171269416809,
        1.2095627784729004,
        1.2086235284805298,
        1.2087846994400024,
        1.2116280794143677,
        1.2150617837905884,
        1.2179557085037231,
        1.219507098197937,
        1.219954013824463,
        1.2218635082244873,
        1.2216497659683228,
        1.220636248588562,
        1.2189750671386719,
        1.2181942462921143,
        1.2179756164550781,
        1.218313455581665,
        1.2185909748077393,
        1.2192463874816895
    ],
    "train_accuracy": [
        0.375,
        0.1875,
        0.3125,
        0.3125,
        0.4375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.4375,
        0.1875,
        0.125,
        0.25,
        0.4375,
        0.25,
        0.5,
        0.5,
        0.375,
        0.3125,
        0.125,
        0.1875,
        0.4375,
        0.375,
        0.25,
        0.125,
        0.3125,
        0.25,
        0.375,
        0.375,
        0.1875,
        0.4375,
        0.625,
        0.25
    ],
    "val_accuracy": [
        0.125,
        0.125,
        0.4375,
        0.5,
        0.5,
        0.4375,
        0.4375,
        0.5,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.5,
        0.5,
        0.5,
        0.5625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.5625
    ],
    "epoch_times": [
        1.6845059394836426,
        1.6798968315124512,
        1.6841368675231934,
        1.6802852153778076,
        1.6882424354553223,
        1.6841576099395752,
        1.6862342357635498,
        1.6833827495574951,
        1.6831300258636475,
        1.682842493057251,
        1.6868345737457275,
        1.6852402687072754,
        1.6835472583770752,
        1.6825957298278809,
        1.6878538131713867,
        1.6841259002685547,
        1.6891369819641113,
        1.6863477230072021,
        1.684453010559082,
        1.6861753463745117,
        1.6842033863067627,
        1.6952500343322754,
        1.6845238208770752,
        1.688279390335083,
        1.6841716766357422,
        1.685943365097046,
        1.6873629093170166,
        1.6827049255371094,
        1.6887092590332031,
        1.6852824687957764,
        1.6868441104888916,
        1.6838831901550293,
        1.6883580684661865
    ]
}