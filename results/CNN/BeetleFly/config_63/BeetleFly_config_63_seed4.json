{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0876662958857,
        "kernel_size": 6,
        "learning_rate": 0.0083678269036,
        "num_filters": 66,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7698301076889038,
        0.635773777961731,
        0.5493577122688293,
        0.29366302490234375,
        0.034385379403829575,
        0.11736830323934555,
        0.06478971242904663,
        0.016881614923477173,
        0.005473978351801634,
        0.005426601506769657,
        0.004097294993698597,
        0.00966251827776432,
        0.005644692573696375,
        0.0029178026597946882,
        0.002203914802521467,
        0.003822345519438386,
        0.0033332621678709984,
        0.0036468731705099344,
        0.0012503793695941567,
        0.0022585128899663687,
        0.0020663735922425985,
        0.001290211221203208,
        0.0006296017090789974,
        0.0008542753057554364,
        0.0008457310032099485,
        0.00046523124910891056,
        0.0001553545444039628,
        0.0009833092335611582,
        0.00017649258370511234,
        0.00016257184324786067,
        8.326525858137757e-05
    ],
    "val_loss": [
        0.6937236189842224,
        0.7317994832992554,
        1.4202611446380615,
        0.9223257899284363,
        3.3669443130493164,
        6.675161361694336,
        9.575096130371094,
        11.436324119567871,
        12.638249397277832,
        13.47177791595459,
        14.028780937194824,
        14.251680374145508,
        14.458578109741211,
        14.262548446655273,
        13.993502616882324,
        13.6827974319458,
        13.407198905944824,
        13.150506973266602,
        12.628955841064453,
        12.336694717407227,
        11.843053817749023,
        11.451096534729004,
        11.014019012451172,
        10.564557075500488,
        10.264458656311035,
        10.025174140930176,
        9.806145668029785,
        9.654764175415039,
        9.4876708984375,
        9.366825103759766,
        9.217389106750488,
        9.092972755432129
    ],
    "train_accuracy": [
        0.5,
        0.8125,
        0.84375,
        0.875,
        1.0,
        0.9375,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.09331822395324707,
        0.025776386260986328,
        0.022788524627685547,
        0.01853466033935547,
        0.018662214279174805,
        0.03092360496520996,
        0.017325401306152344,
        0.019585132598876953,
        0.017500638961791992,
        0.01914525032043457,
        0.020005226135253906,
        0.01754474639892578,
        0.017637252807617188,
        0.017204999923706055,
        0.02435922622680664,
        0.02251458168029785,
        0.01861119270324707,
        0.017000675201416016,
        0.03154110908508301,
        0.0211181640625,
        0.01962733268737793,
        0.018196582794189453,
        0.020478248596191406,
        0.01817464828491211,
        0.01832890510559082,
        0.017755508422851562,
        0.023959875106811523,
        0.017444610595703125,
        0.025671005249023438,
        0.017138004302978516,
        0.017262697219848633
    ]
}