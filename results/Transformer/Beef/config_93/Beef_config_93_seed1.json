{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0830843675864,
        "ff_dim": 969,
        "hidden_units": 164,
        "learning_rate": 7.97113417e-05,
        "num_heads": 7,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 7.47559508e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 36,
    "train_loss": [
        1.9029803276062012,
        1.5322844982147217,
        1.5445786714553833,
        1.5738698244094849,
        1.5201213359832764,
        1.3750536441802979,
        1.4003640413284302,
        1.4487452507019043,
        1.239857792854309,
        1.3390942811965942,
        1.4114432334899902,
        1.3492339849472046,
        0.9822004437446594,
        1.115321397781372,
        1.1601845026016235,
        1.3381145000457764,
        1.082669734954834,
        1.1189109086990356,
        1.1746187210083008,
        1.0710813999176025,
        1.0846954584121704,
        0.9801735877990723,
        0.8277419805526733,
        1.108354091644287,
        0.95798659324646,
        1.2353442907333374,
        0.9612396955490112,
        0.924491286277771,
        0.9754738807678223,
        1.1094516515731812,
        0.8872256278991699,
        1.0507092475891113,
        0.972603976726532,
        1.0309909582138062,
        1.0657237768173218,
        1.1701476573944092
    ],
    "val_loss": [
        1.689212441444397,
        1.5673514604568481,
        1.6979212760925293,
        1.6184369325637817,
        1.5261616706848145,
        1.4691458940505981,
        1.4187263250350952,
        1.425034999847412,
        1.4894862174987793,
        1.514222502708435,
        1.5456271171569824,
        1.5424407720565796,
        1.5291286706924438,
        1.5254231691360474,
        1.5180706977844238,
        1.5062202215194702,
        1.496259331703186,
        1.5005344152450562,
        1.5120092630386353,
        1.5131314992904663,
        1.5048233270645142,
        1.494584083557129,
        1.490338683128357,
        1.4934242963790894,
        1.5072089433670044,
        1.5143681764602661,
        1.528136134147644,
        1.5463234186172485,
        1.5615720748901367,
        1.577653408050537,
        1.5892990827560425,
        1.5913876295089722,
        1.5936638116836548,
        1.5965341329574585,
        1.6000193357467651,
        1.6017460823059082,
        1.602308750152588
    ],
    "train_accuracy": [
        0.0625,
        0.375,
        0.375,
        0.25,
        0.1875,
        0.5,
        0.5625,
        0.3125,
        0.5625,
        0.375,
        0.4375,
        0.4375,
        0.6875,
        0.5625,
        0.5,
        0.5625,
        0.5,
        0.4375,
        0.375,
        0.625,
        0.5625,
        0.5,
        0.6875,
        0.4375,
        0.625,
        0.4375,
        0.6875,
        0.75,
        0.6875,
        0.5625,
        0.8125,
        0.5625,
        0.625,
        0.625,
        0.5625,
        0.4375
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.3333333432674408,
        0.1666666716337204,
        0.25,
        0.5,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.25199055671691895,
        0.13447976112365723,
        0.13407015800476074,
        0.13171601295471191,
        0.13168716430664062,
        0.13100194931030273,
        0.1333904266357422,
        0.13172364234924316,
        0.13224244117736816,
        0.1332871913909912,
        0.1316661834716797,
        0.13327550888061523,
        0.13416218757629395,
        0.13326001167297363,
        0.13222980499267578,
        0.13221335411071777,
        0.1322803497314453,
        0.13230633735656738,
        0.13489699363708496,
        0.1368875503540039,
        0.1313939094543457,
        0.12995409965515137,
        0.12880802154541016,
        0.13279366493225098,
        0.13083982467651367,
        0.13190698623657227,
        0.13168883323669434,
        0.13134980201721191,
        0.13385987281799316,
        0.1320333480834961,
        0.1323843002319336,
        0.1300809383392334,
        0.13032770156860352,
        0.13033771514892578,
        0.12993478775024414,
        0.13057518005371094
    ]
}