{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3161516587151,
        "kernel_size": 6,
        "learning_rate": 0.0012825204594,
        "num_filters": 160,
        "num_layers": 1,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.6281090974807739,
        0.787307620048523,
        0.3258713483810425,
        0.17256590723991394,
        0.12317279726266861,
        0.14790888130664825,
        0.07239606231451035,
        0.06953147798776627,
        0.05545259267091751,
        0.05103759467601776,
        0.057214729487895966,
        0.03762118145823479,
        0.04677502065896988,
        0.04130881279706955,
        0.03357067331671715,
        0.025525076314806938,
        0.022639421746134758,
        0.021115785464644432,
        0.021625449880957603,
        0.015102863311767578,
        0.013696801848709583,
        0.013742449693381786,
        0.011788876727223396,
        0.009852754883468151,
        0.007203714456409216,
        0.009600434452295303,
        0.007205420173704624,
        0.010750922374427319,
        0.009098155423998833,
        0.006567215546965599,
        0.006813547108322382,
        0.004920751787722111,
        0.004928770009428263,
        0.004854919388890266
    ],
    "val_loss": [
        0.6968022584915161,
        0.6457804441452026,
        0.6021324396133423,
        0.5216612815856934,
        0.49653491377830505,
        0.5061948299407959,
        0.5355163812637329,
        0.5732183456420898,
        0.6214242577552795,
        0.6674374341964722,
        0.7109118700027466,
        0.7315912842750549,
        0.739589273929596,
        0.7322711944580078,
        0.7144037485122681,
        0.6921728849411011,
        0.667374849319458,
        0.6413765549659729,
        0.6180852651596069,
        0.5977822542190552,
        0.5799509286880493,
        0.5642159581184387,
        0.5515273809432983,
        0.5403667688369751,
        0.5309691429138184,
        0.5234079360961914,
        0.5171234607696533,
        0.5122354626655579,
        0.5095819234848022,
        0.5081244111061096,
        0.507603645324707,
        0.5081900954246521,
        0.5092291235923767,
        0.5106784105300903,
        0.512426495552063
    ],
    "train_accuracy": [
        0.625,
        0.6875,
        0.84375,
        0.9375,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.75,
        0.75,
        0.75,
        0.625,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.09986019134521484,
        0.30959224700927734,
        0.017344951629638672,
        0.021773099899291992,
        0.024039268493652344,
        0.021215200424194336,
        0.021396875381469727,
        0.021504640579223633,
        0.020020246505737305,
        0.01936483383178711,
        0.021144628524780273,
        0.021170616149902344,
        0.01872849464416504,
        0.021409273147583008,
        0.02100849151611328,
        0.02045154571533203,
        0.01820683479309082,
        0.018680095672607422,
        0.018243074417114258,
        0.0187680721282959,
        0.018887996673583984,
        0.019391775131225586,
        0.017659902572631836,
        0.018349647521972656,
        0.02068924903869629,
        0.01830434799194336,
        0.018370628356933594,
        0.01783275604248047,
        0.01840376853942871,
        0.016976356506347656,
        0.016574382781982422,
        0.016730308532714844,
        0.016240835189819336,
        0.016843080520629883
    ]
}