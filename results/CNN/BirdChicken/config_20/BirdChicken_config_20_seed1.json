{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2155908775802,
        "kernel_size": 3,
        "learning_rate": 0.008326361104,
        "num_filters": 71,
        "num_layers": 4,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.6597251296043396,
        0.8011866211891174,
        0.39125964045524597,
        0.34527522325515747,
        0.3475552797317505,
        0.21679040789604187,
        0.11030837893486023,
        0.203565776348114,
        0.17094090580940247,
        0.11795558780431747,
        0.0893489420413971,
        0.1307588368654251,
        0.16361692547798157,
        0.029091645032167435,
        0.02233695238828659,
        0.04398422688245773,
        0.0662752166390419,
        0.07157002389431,
        0.01580355130136013,
        0.015031451359391212,
        0.02347436361014843,
        0.004927407950162888,
        0.0705944076180458,
        0.07101903855800629,
        0.014399458654224873,
        0.03595671057701111,
        0.0708853155374527,
        0.010388484224677086,
        0.00823312345892191,
        0.005770541727542877,
        0.22151148319244385,
        0.05115070566534996,
        0.024379216134548187,
        0.01163092814385891,
        0.008538495749235153
    ],
    "val_loss": [
        0.7067545652389526,
        0.709134578704834,
        0.7251222133636475,
        0.7240587472915649,
        0.6962370872497559,
        0.6792043447494507,
        0.7014540433883667,
        0.7469292879104614,
        0.7850375175476074,
        0.8194748163223267,
        0.8240660429000854,
        0.8596229553222656,
        0.9063608050346375,
        0.990220844745636,
        1.0807079076766968,
        1.2003521919250488,
        1.3236490488052368,
        1.4752233028411865,
        1.2551032304763794,
        1.3343323469161987,
        1.6754496097564697,
        2.017371416091919,
        2.335566282272339,
        2.386493444442749,
        2.415642261505127,
        2.4342081546783447,
        2.4220519065856934,
        2.3919363021850586,
        2.421112060546875,
        2.4717891216278076,
        2.529409408569336,
        2.5719094276428223,
        2.7001614570617676,
        2.9924988746643066,
        3.1761345863342285,
        3.346148729324341
    ],
    "train_accuracy": [
        0.53125,
        0.5,
        0.875,
        0.84375,
        0.84375,
        0.90625,
        1.0,
        0.90625,
        0.90625,
        0.96875,
        1.0,
        0.9375,
        0.96875,
        1.0,
        1.0,
        0.96875,
        0.9375,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        0.90625,
        0.96875,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.75,
        0.75,
        0.625,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.625,
        0.625,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        2.4581093788146973,
        0.027045726776123047,
        0.025141000747680664,
        0.023946046829223633,
        0.023923158645629883,
        0.024352073669433594,
        0.024096965789794922,
        0.02408313751220703,
        0.02349710464477539,
        0.024750947952270508,
        0.02294015884399414,
        0.024676084518432617,
        0.023929834365844727,
        0.022978782653808594,
        0.02309393882751465,
        0.023729801177978516,
        0.02451610565185547,
        0.022436857223510742,
        0.022902965545654297,
        0.024367809295654297,
        0.02239513397216797,
        0.022891998291015625,
        0.023095130920410156,
        0.022917985916137695,
        0.06591200828552246,
        0.02402806282043457,
        0.02359485626220703,
        0.02278304100036621,
        0.0224151611328125,
        0.024684906005859375,
        0.024198055267333984,
        0.023832082748413086,
        0.023389101028442383,
        0.02267909049987793,
        0.02415919303894043
    ]
}