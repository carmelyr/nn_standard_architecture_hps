{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.3744825168352,
        "kernel_size": 4,
        "learning_rate": 0.0069516560049,
        "num_filters": 198,
        "num_layers": 3,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.8219164609909058,
        2.7992467880249023,
        2.5788629055023193,
        1.6279200315475464,
        1.255420207977295,
        1.549098014831543,
        1.221701979637146,
        1.342587947845459,
        1.4564613103866577,
        1.0824439525604248,
        1.1055123805999756,
        1.2494279146194458,
        0.8882220387458801,
        1.004557728767395,
        1.0742961168289185,
        0.8836448788642883,
        0.9868855476379395,
        0.8397688865661621,
        0.842017650604248,
        0.9992524981498718,
        0.6744462847709656,
        0.6131711602210999,
        0.6611954569816589,
        0.5674425959587097,
        0.6513069272041321,
        0.5410781502723694,
        0.569065272808075,
        0.6443812847137451,
        0.5785588622093201,
        0.6400856375694275,
        0.5221469402313232
    ],
    "val_loss": [
        1.6112254858016968,
        1.6679315567016602,
        3.4946765899658203,
        6.301115036010742,
        6.525693893432617,
        5.170292377471924,
        5.072072505950928,
        4.139662265777588,
        3.537132978439331,
        3.286389112472534,
        3.081754446029663,
        2.663947343826294,
        2.7729883193969727,
        2.843273878097534,
        2.5233981609344482,
        2.610689401626587,
        2.29030179977417,
        2.5695223808288574,
        2.5659339427948,
        2.6639745235443115,
        2.551919937133789,
        2.5162835121154785,
        2.525305986404419,
        2.742626905441284,
        3.111830711364746,
        2.9588048458099365,
        2.555340528488159,
        2.612426519393921,
        3.017108917236328,
        3.4802138805389404,
        3.142991304397583,
        2.9324371814727783
    ],
    "train_accuracy": [
        0.2291666716337204,
        0.3125,
        0.3958333432674408,
        0.4166666567325592,
        0.4583333432674408,
        0.375,
        0.4583333432674408,
        0.4166666567325592,
        0.4375,
        0.5625,
        0.5625,
        0.4375,
        0.625,
        0.5625,
        0.5833333134651184,
        0.6458333134651184,
        0.5833333134651184,
        0.6041666865348816,
        0.5833333134651184,
        0.5416666865348816,
        0.75,
        0.7291666865348816,
        0.7083333134651184,
        0.7291666865348816,
        0.6875,
        0.75,
        0.7708333134651184,
        0.6875,
        0.8333333134651184,
        0.7291666865348816,
        0.7708333134651184
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.25,
        0.25,
        0.25,
        0.4166666567325592,
        0.4166666567325592,
        0.3333333432674408,
        0.25,
        0.25,
        0.5,
        0.5,
        0.3333333432674408,
        0.1666666716337204,
        0.25,
        0.4166666567325592
    ],
    "epoch_times": [
        0.22226810455322266,
        0.08204340934753418,
        0.08346128463745117,
        0.08308053016662598,
        0.08314037322998047,
        0.08111023902893066,
        0.08408212661743164,
        0.08202672004699707,
        0.08628320693969727,
        0.07931184768676758,
        0.07894635200500488,
        0.08313393592834473,
        0.08657407760620117,
        0.0909268856048584,
        0.08445954322814941,
        0.07996773719787598,
        0.08478832244873047,
        0.08223724365234375,
        0.08491921424865723,
        0.08305859565734863,
        0.08460569381713867,
        0.08283209800720215,
        0.08034157752990723,
        0.08098006248474121,
        0.08227300643920898,
        0.07479500770568848,
        0.03360128402709961,
        0.059017181396484375,
        0.08240509033203125,
        0.08326530456542969,
        0.0820155143737793
    ]
}