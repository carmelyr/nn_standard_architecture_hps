{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1448636024401,
        "ff_dim": 331,
        "hidden_units": 347,
        "learning_rate": 1.84210549e-05,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 6.33151081e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        1.1313211917877197,
        0.9408289194107056,
        0.788418173789978,
        0.7228391766548157,
        0.8315407037734985,
        0.765845537185669,
        0.5922446250915527,
        0.848957359790802,
        0.6247474551200867,
        0.5482395887374878,
        0.6688162088394165,
        0.7938787341117859,
        0.7175279855728149,
        0.8490678071975708,
        0.7337801456451416,
        0.6936916708946228,
        0.7353413701057434,
        0.7777064442634583,
        0.7199684977531433,
        0.6860581636428833,
        0.7689704298973083,
        0.7096378207206726,
        0.665432870388031,
        0.6921929717063904,
        0.7375947833061218,
        0.599740207195282,
        0.7043315768241882,
        0.6834318041801453,
        0.6697917580604553,
        0.6408212184906006,
        0.6295789480209351,
        0.5387259721755981
    ],
    "val_loss": [
        1.3570020198822021,
        1.1791199445724487,
        1.1444956064224243,
        1.2060247659683228,
        1.3275045156478882,
        1.4631978273391724,
        1.5704206228256226,
        1.675592303276062,
        1.7483408451080322,
        1.7748764753341675,
        1.793534278869629,
        1.804673433303833,
        1.8124885559082031,
        1.8213722705841064,
        1.8274694681167603,
        1.8343582153320312,
        1.8400347232818604,
        1.8477461338043213,
        1.8575458526611328,
        1.8678971529006958,
        1.8789671659469604,
        1.8856781721115112,
        1.8924105167388916,
        1.898989200592041,
        1.905282974243164,
        1.9117882251739502,
        1.9174867868423462,
        1.9200530052185059,
        1.9226772785186768,
        1.9250502586364746,
        1.927558183670044,
        1.9300771951675415,
        1.9327975511550903
    ],
    "train_accuracy": [
        0.5,
        0.53125,
        0.53125,
        0.59375,
        0.5625,
        0.5,
        0.59375,
        0.53125,
        0.75,
        0.75,
        0.59375,
        0.59375,
        0.5625,
        0.53125,
        0.5,
        0.59375,
        0.5625,
        0.46875,
        0.625,
        0.5625,
        0.53125,
        0.59375,
        0.5625,
        0.5625,
        0.59375,
        0.6875,
        0.625,
        0.71875,
        0.59375,
        0.65625,
        0.625,
        0.71875
    ],
    "val_accuracy": [
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.13933730125427246,
        0.13321161270141602,
        0.13201642036437988,
        0.13397955894470215,
        0.13236784934997559,
        0.13309192657470703,
        0.13377904891967773,
        0.13181352615356445,
        0.1321425437927246,
        0.13277840614318848,
        0.13285160064697266,
        0.13585877418518066,
        0.13259029388427734,
        0.13362836837768555,
        0.13283467292785645,
        0.13365411758422852,
        0.13307857513427734,
        0.13372039794921875,
        0.13486480712890625,
        0.13205552101135254,
        0.13176941871643066,
        0.132066011428833,
        0.13768720626831055,
        0.1333627700805664,
        0.13103151321411133,
        0.13256216049194336,
        0.1314716339111328,
        0.1349644660949707,
        0.13227415084838867,
        0.13320612907409668,
        0.13356399536132812,
        0.1325221061706543
    ]
}