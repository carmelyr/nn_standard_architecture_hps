{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0876662958857,
        "kernel_size": 6,
        "learning_rate": 0.0083678269036,
        "num_filters": 66,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.8010821342468262,
        0.628174364566803,
        0.8530055284500122,
        0.18144448101520538,
        0.21888943016529083,
        0.10147375613451004,
        0.07608813047409058,
        0.07710649818181992,
        0.05124662071466446,
        0.02565647102892399,
        0.03050229139626026,
        0.009116258472204208,
        0.0063104210421442986,
        0.0033947320189327,
        0.002341557526960969,
        0.0019329085480421782,
        0.0014603433664888144,
        0.0027907895855605602,
        0.000533713900949806,
        0.0005988076445646584,
        0.0007598389056511223,
        0.0004914035671390593,
        0.00026014496688731015,
        0.00032998621463775635,
        0.00026660162257030606,
        0.00025075129815377295,
        0.00014647271018475294,
        0.00017681509780231863,
        0.0005304835503920913,
        0.005459409207105637,
        0.00020613186643458903,
        0.00012607192911673337,
        6.613449659198523e-05,
        0.00027543120086193085
    ],
    "val_loss": [
        0.686928391456604,
        0.6803097724914551,
        0.8666746020317078,
        0.7897230982780457,
        0.6766411662101746,
        0.7234529256820679,
        0.9597480893135071,
        1.4099678993225098,
        1.8908220529556274,
        2.225322723388672,
        2.389035701751709,
        2.6639249324798584,
        2.955751419067383,
        3.228022336959839,
        3.436816453933716,
        3.627265214920044,
        3.808675765991211,
        3.933952569961548,
        4.043696880340576,
        4.110611438751221,
        4.12520170211792,
        4.109395980834961,
        4.095734119415283,
        4.095610618591309,
        4.007853031158447,
        3.977030038833618,
        3.968093156814575,
        3.8859798908233643,
        3.8050975799560547,
        3.712001085281372,
        3.6999337673187256,
        3.664936065673828,
        3.6525964736938477,
        3.614966630935669,
        3.616598606109619
    ],
    "train_accuracy": [
        0.5,
        0.6875,
        0.6875,
        0.9375,
        0.9375,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.5,
        0.625,
        0.625,
        0.5,
        0.625,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.08478951454162598,
        0.17038774490356445,
        0.0273129940032959,
        0.02587127685546875,
        0.025893449783325195,
        0.10962319374084473,
        0.025990724563598633,
        0.02532172203063965,
        0.025205135345458984,
        0.025124788284301758,
        0.024953603744506836,
        0.02553391456604004,
        0.025941848754882812,
        0.02516317367553711,
        0.02504897117614746,
        0.02541804313659668,
        0.02492213249206543,
        0.024959087371826172,
        0.025391340255737305,
        0.025575876235961914,
        0.0252227783203125,
        0.02546072006225586,
        0.025171995162963867,
        0.02534937858581543,
        0.025147199630737305,
        0.02521800994873047,
        0.02504897117614746,
        0.025339841842651367,
        0.025159835815429688,
        0.02601027488708496,
        0.025336027145385742,
        0.02533864974975586,
        0.025160789489746094,
        0.024805068969726562
    ]
}