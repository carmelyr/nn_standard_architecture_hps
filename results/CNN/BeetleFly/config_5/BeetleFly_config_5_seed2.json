{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1418779037326,
        "kernel_size": 7,
        "learning_rate": 0.0019347410864,
        "num_filters": 158,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8983688354492188,
        0.301582396030426,
        0.18630169332027435,
        0.1464734971523285,
        0.10166971385478973,
        0.08159023523330688,
        0.04329701513051987,
        0.033156346529722214,
        0.0235531534999609,
        0.01987467147409916,
        0.012463127262890339,
        0.011572475545108318,
        0.008689501322805882,
        0.00957865547388792,
        0.007273952942341566,
        0.006609324365854263,
        0.00523863872513175,
        0.0028096844907850027,
        0.002856497187167406,
        0.0021319296211004257,
        0.0027016205713152885,
        0.0014757838798686862,
        0.0019056197488680482,
        0.0033267547842115164,
        0.0023939702659845352,
        0.00484319357201457,
        0.0012601710623130202,
        0.0008400806691497564,
        0.0011458199005573988,
        0.0009698783396743238,
        0.0022777365520596504,
        0.0011068128515034914
    ],
    "val_loss": [
        0.6901071071624756,
        0.6846193075180054,
        0.6832919716835022,
        0.68470299243927,
        0.6930075287818909,
        0.7049572467803955,
        0.7214413285255432,
        0.7417424321174622,
        0.7593288421630859,
        0.78519606590271,
        0.8213368654251099,
        0.862648069858551,
        0.9085248708724976,
        0.9563845992088318,
        1.0088613033294678,
        1.0615582466125488,
        1.1193690299987793,
        1.182698130607605,
        1.24774968624115,
        1.3141791820526123,
        1.3819981813430786,
        1.448491096496582,
        1.5157945156097412,
        1.5836559534072876,
        1.6447170972824097,
        1.7039836645126343,
        1.7527947425842285,
        1.7957489490509033,
        1.8361879587173462,
        1.8756985664367676,
        1.9111626148223877,
        1.9496917724609375,
        1.9899672269821167
    ],
    "train_accuracy": [
        0.46875,
        0.90625,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.1157846450805664,
        0.07433629035949707,
        0.06384563446044922,
        0.02020573616027832,
        0.04610180854797363,
        0.020312786102294922,
        0.050359249114990234,
        0.01993107795715332,
        0.0477137565612793,
        0.07517218589782715,
        0.022257566452026367,
        0.051969051361083984,
        0.06885194778442383,
        0.021863937377929688,
        0.04307222366333008,
        0.020824670791625977,
        0.018467426300048828,
        0.056357622146606445,
        0.020358562469482422,
        0.05212998390197754,
        0.020534515380859375,
        0.04971170425415039,
        0.020415306091308594,
        0.054383039474487305,
        0.020010948181152344,
        0.043365478515625,
        0.07022809982299805,
        0.021123886108398438,
        0.04185009002685547,
        0.022051572799682617,
        0.05016016960144043,
        0.06500840187072754
    ]
}