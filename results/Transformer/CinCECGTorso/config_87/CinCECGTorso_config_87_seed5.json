{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0345486166769,
        "ff_dim": 269,
        "hidden_units": 212,
        "learning_rate": 0.0008103677994,
        "num_heads": 6,
        "num_layers": 3,
        "pooling": "max",
        "weight_decay": 2.71456542e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 38,
    "train_loss": [
        1.9168269634246826,
        1.6694040298461914,
        1.6453980207443237,
        1.5897026062011719,
        1.2462952136993408,
        1.2250232696533203,
        1.2163327932357788,
        1.4559106826782227,
        1.148457407951355,
        0.8761234879493713,
        1.0571402311325073,
        0.800929069519043,
        0.5635777711868286,
        0.5779274702072144,
        0.28650200366973877,
        0.45840200781822205,
        0.42160138487815857,
        0.24077968299388885,
        0.1396944224834442,
        0.11012107878923416,
        0.09185555577278137,
        0.13521318137645721,
        0.061962999403476715,
        0.06495822966098785,
        0.13259842991828918,
        0.03227481245994568,
        0.023165252059698105,
        0.009248265065252781,
        0.0401376336812973,
        0.005653351545333862,
        0.011267164722084999,
        0.011052524670958519,
        0.00876433402299881,
        0.0036587377544492483,
        0.0038010862190276384,
        0.025651901960372925,
        0.006732662674039602,
        0.006203365046530962
    ],
    "val_loss": [
        2.7989213466644287,
        1.406744122505188,
        1.2477823495864868,
        1.6223946809768677,
        1.3435847759246826,
        1.3566280603408813,
        1.3517924547195435,
        1.3685811758041382,
        1.1974687576293945,
        1.5332095623016357,
        1.3600187301635742,
        1.497450351715088,
        1.8885879516601562,
        2.2832953929901123,
        1.6919785737991333,
        2.2264604568481445,
        1.9345942735671997,
        2.4156711101531982,
        2.27508544921875,
        2.8324129581451416,
        2.7980194091796875,
        2.928999185562134,
        3.406076431274414,
        2.839226007461548,
        3.0062928199768066,
        3.6650006771087646,
        3.1542136669158936,
        3.3221688270568848,
        3.635464668273926,
        3.2363102436065674,
        3.1744537353515625,
        3.5184967517852783,
        3.4763877391815186,
        3.3757665157318115,
        3.38628888130188,
        3.405282735824585,
        3.436636447906494,
        3.425537586212158,
        3.35656476020813
    ],
    "train_accuracy": [
        0.3125,
        0.25,
        0.1875,
        0.25,
        0.5,
        0.375,
        0.4375,
        0.4375,
        0.5,
        0.5,
        0.4375,
        0.625,
        0.75,
        0.875,
        1.0,
        0.8125,
        0.8125,
        0.9375,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.9375,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.3125,
        0.375,
        0.625,
        0.1875,
        0.4375,
        0.3125,
        0.25,
        0.3125,
        0.5625,
        0.3125,
        0.375,
        0.4375,
        0.375,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.5,
        0.375,
        0.4375,
        0.4375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375
    ],
    "epoch_times": [
        0.5297744274139404,
        0.5137848854064941,
        0.5134544372558594,
        0.5113565921783447,
        0.5128445625305176,
        0.5127935409545898,
        0.5134198665618896,
        0.5135622024536133,
        0.5139765739440918,
        0.515042781829834,
        0.5213809013366699,
        0.5126569271087646,
        0.5102336406707764,
        0.5128421783447266,
        0.5105500221252441,
        0.5136487483978271,
        0.513495922088623,
        0.5124006271362305,
        0.5141294002532959,
        0.5168652534484863,
        0.5124032497406006,
        0.5115921497344971,
        0.5173149108886719,
        0.5132980346679688,
        0.5131289958953857,
        0.5138497352600098,
        0.5120534896850586,
        0.5116751194000244,
        0.5122778415679932,
        0.5109918117523193,
        0.5111379623413086,
        0.511371374130249,
        0.5127427577972412,
        0.5101852416992188,
        0.5108492374420166,
        0.5106291770935059,
        0.5096194744110107,
        0.5092334747314453
    ]
}