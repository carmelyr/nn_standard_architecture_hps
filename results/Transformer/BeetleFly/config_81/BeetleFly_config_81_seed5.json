{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.068110276744,
        "ff_dim": 279,
        "hidden_units": 444,
        "learning_rate": 1.63705046e-05,
        "num_heads": 8,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 2.56177413e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.767026960849762,
        0.7615092992782593,
        0.7327430844306946,
        0.6886043548583984,
        0.6376864314079285,
        0.7202382683753967,
        0.6658126711845398,
        0.619426965713501,
        0.6864967942237854,
        0.6292645931243896,
        0.7351707816123962,
        0.7078080177307129,
        0.6116616725921631,
        0.6072856783866882,
        0.623633861541748,
        0.6415661573410034,
        0.7050753831863403,
        0.6533035039901733,
        0.6799337267875671,
        0.6127925515174866,
        0.5491619110107422,
        0.5333962440490723,
        0.6317352652549744,
        0.7088606953620911,
        0.6541862487792969,
        0.6387302279472351,
        0.6247299909591675,
        0.5525742769241333,
        0.6255819797515869,
        0.6529372334480286,
        0.5715577602386475,
        0.6510422229766846,
        0.6405994296073914,
        0.5759954452514648
    ],
    "val_loss": [
        1.0778471231460571,
        1.2982163429260254,
        1.0866292715072632,
        0.8094316124916077,
        0.7880334258079529,
        0.8340678215026855,
        0.8428712487220764,
        0.9253086447715759,
        0.9275588989257812,
        0.8567856550216675,
        0.8141787648200989,
        0.819758951663971,
        0.8360245823860168,
        0.8607189655303955,
        0.9055705666542053,
        0.9714288711547852,
        1.0191832780838013,
        1.0232592821121216,
        1.010046124458313,
        0.9882667660713196,
        0.9596230387687683,
        0.9494717121124268,
        0.9468383193016052,
        0.9484800100326538,
        0.9515170454978943,
        0.9556004405021667,
        0.9613973498344421,
        0.9696266055107117,
        0.9744899272918701,
        0.977283239364624,
        0.9770939946174622,
        0.9764062762260437,
        0.9744593501091003,
        0.9710944294929504,
        0.9685857892036438
    ],
    "train_accuracy": [
        0.53125,
        0.625,
        0.53125,
        0.53125,
        0.75,
        0.5625,
        0.625,
        0.71875,
        0.625,
        0.625,
        0.59375,
        0.46875,
        0.65625,
        0.65625,
        0.5625,
        0.625,
        0.625,
        0.65625,
        0.46875,
        0.59375,
        0.75,
        0.75,
        0.5625,
        0.625,
        0.53125,
        0.625,
        0.59375,
        0.71875,
        0.59375,
        0.59375,
        0.6875,
        0.65625,
        0.65625,
        0.78125
    ],
    "val_accuracy": [
        0.5,
        0.25,
        0.25,
        0.25,
        0.375,
        0.125,
        0.25,
        0.25,
        0.25,
        0.0,
        0.5,
        0.5,
        0.5,
        0.5,
        0.25,
        0.125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.125,
        0.125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.0
    ],
    "epoch_times": [
        0.20844173431396484,
        0.15342020988464355,
        0.14809393882751465,
        0.14737772941589355,
        0.14687061309814453,
        0.14563417434692383,
        0.14843988418579102,
        0.14972162246704102,
        0.14811229705810547,
        0.14784812927246094,
        0.1491098403930664,
        0.14797687530517578,
        0.1465470790863037,
        0.14806461334228516,
        0.14843249320983887,
        0.14896726608276367,
        0.1524360179901123,
        0.14679408073425293,
        0.14652562141418457,
        0.14753150939941406,
        0.14745497703552246,
        0.14855337142944336,
        0.1519327163696289,
        0.14930057525634766,
        0.14834809303283691,
        0.1485142707824707,
        0.1486964225769043,
        0.14915847778320312,
        0.14847254753112793,
        0.15110445022583008,
        0.1489570140838623,
        0.149336576461792,
        0.1497509479522705,
        0.1475391387939453
    ]
}