{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1418779037326,
        "kernel_size": 7,
        "learning_rate": 0.0019347410864,
        "num_filters": 158,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.594783306121826,
        3.384381055831909,
        3.283237934112549,
        3.176844596862793,
        3.1347789764404297,
        3.0402610301971436,
        2.9630212783813477,
        2.8740267753601074,
        2.858566999435425,
        2.7702043056488037,
        2.6991209983825684,
        2.6386194229125977,
        2.6236791610717773,
        2.5469577312469482,
        2.4591424465179443
    ],
    "val_loss": [
        3.5585803985595703,
        3.5032966136932373,
        3.380566358566284,
        3.314546823501587,
        3.3214128017425537,
        3.246868371963501,
        3.2150723934173584,
        3.1778318881988525,
        3.164367198944092,
        3.1711626052856445,
        3.109790802001953,
        3.0836455821990967,
        3.018019676208496,
        2.9634616374969482,
        2.928030490875244,
        2.9870643615722656
    ],
    "train_accuracy": [
        0.05181623995304108,
        0.08012820780277252,
        0.10844016820192337,
        0.1260683834552765,
        0.13141025602817535,
        0.15491452813148499,
        0.17521367967128754,
        0.19284188747406006,
        0.19284188747406006,
        0.2142094075679779,
        0.2270299196243286,
        0.24519230425357819,
        0.24091880023479462,
        0.2649572789669037,
        0.2868589758872986
    ],
    "val_accuracy": [
        0.03125,
        0.0555555559694767,
        0.07051282376050949,
        0.08547008782625198,
        0.10470085591077805,
        0.10683760792016983,
        0.10470085591077805,
        0.10256410390138626,
        0.12393162399530411,
        0.10256410390138626,
        0.1111111119389534,
        0.12393162399530411,
        0.12393162399530411,
        0.14743590354919434,
        0.16880342364311218,
        0.1645299196243286
    ]
}