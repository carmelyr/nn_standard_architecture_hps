{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.0437363810925,
        "kernel_size": 4,
        "learning_rate": 0.0003864861313,
        "num_filters": 66,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        0.7697067260742188,
        0.47680291533470154,
        0.36963126063346863,
        0.2785342335700989,
        0.18479973077774048,
        0.1371898055076599,
        0.09695329517126083,
        0.06960878521203995,
        0.06415994465351105,
        0.04236859828233719,
        0.026954321190714836,
        0.022384753450751305,
        0.0199139267206192,
        0.01865122653543949,
        0.013083107769489288,
        0.010006830096244812,
        0.007394938264042139,
        0.010554091073572636,
        0.0064930967055261135,
        0.00799540150910616,
        0.003361274255439639,
        0.004362279083579779,
        0.00475538894534111,
        0.003584476187825203,
        0.003080960363149643,
        0.004273183178156614,
        0.0016594183398410678,
        0.001884221681393683,
        0.00159306894056499,
        0.0015278920764103532,
        0.001588052837178111,
        0.001334606553427875,
        0.001479864353314042,
        0.0016490640118718147,
        0.0011950707994401455,
        0.0014111128402873874
    ],
    "val_loss": [
        0.6938551068305969,
        0.6859230995178223,
        0.6759461760520935,
        0.6689072251319885,
        0.6638256907463074,
        0.6600328683853149,
        0.6571253538131714,
        0.6576626896858215,
        0.6642739772796631,
        0.6771371364593506,
        0.697865903377533,
        0.7268759608268738,
        0.7686716318130493,
        0.8239471316337585,
        0.8987946510314941,
        0.9909019470214844,
        1.0974156856536865,
        1.214354395866394,
        1.3348811864852905,
        1.458876132965088,
        1.5804568529129028,
        1.7014050483703613,
        1.8209011554718018,
        1.9419363737106323,
        2.056406021118164,
        2.1675686836242676,
        2.2776708602905273,
        2.3831286430358887,
        2.484570264816284,
        2.5835461616516113,
        2.6770265102386475,
        2.7648661136627197,
        2.8502397537231445,
        2.9346094131469727,
        3.0074267387390137,
        3.078446865081787,
        3.151182174682617
    ],
    "train_accuracy": [
        0.5,
        0.71875,
        0.875,
        0.875,
        0.96875,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.188629150390625,
        0.06949186325073242,
        0.019591569900512695,
        0.017405986785888672,
        0.01736927032470703,
        0.017510414123535156,
        0.02022409439086914,
        0.020938634872436523,
        0.021687030792236328,
        0.022133827209472656,
        0.02202582359313965,
        0.02127861976623535,
        0.02173328399658203,
        0.02156543731689453,
        0.022307395935058594,
        0.022464513778686523,
        0.022509336471557617,
        0.02225470542907715,
        0.021642446517944336,
        0.02195286750793457,
        0.021456241607666016,
        0.020531415939331055,
        0.0199127197265625,
        0.01972222328186035,
        0.020131587982177734,
        0.021294116973876953,
        0.020816326141357422,
        0.020882844924926758,
        0.020839929580688477,
        0.022414445877075195,
        0.02243518829345703,
        0.021746397018432617,
        0.022157907485961914,
        0.021741628646850586,
        0.022282123565673828,
        0.02232074737548828
    ]
}