{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0668866210245,
        "kernel_size": 7,
        "learning_rate": 0.0048811259055,
        "num_filters": 136,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7436463832855225,
        0.42580729722976685,
        0.1684005707502365,
        0.07107673585414886,
        0.07228808850049973,
        0.035660360008478165,
        0.0195918045938015,
        0.01299873273819685,
        0.014859091490507126,
        0.009948516264557838,
        0.007665693759918213,
        0.004739310126751661,
        0.003752878401428461,
        0.0034077195450663567,
        0.0047858296893537045,
        0.0016385094495490193,
        0.0020723312627524137,
        0.001648434204980731,
        0.001220191828906536,
        0.0008430681191384792,
        0.0012440824648365378,
        0.0008994220988824964,
        0.0010823934571817517,
        0.0008828293066471815,
        0.0010951628210023046,
        0.0004808973171748221,
        0.0014321074122563004,
        0.0005241887411102653,
        0.00045195830170996487,
        0.0005859936936758459,
        0.0006771197658963501
    ],
    "val_loss": [
        0.701830267906189,
        0.7103756070137024,
        0.748079240322113,
        0.7969508171081543,
        0.8606610894203186,
        0.9696436524391174,
        1.0985212326049805,
        1.2483869791030884,
        1.4043099880218506,
        1.5561789274215698,
        1.7038426399230957,
        1.8444182872772217,
        1.9835186004638672,
        2.109417200088501,
        2.2353506088256836,
        2.341963768005371,
        2.4471936225891113,
        2.543846845626831,
        2.6333248615264893,
        2.7225241661071777,
        2.7994384765625,
        2.868635654449463,
        2.9400980472564697,
        2.995323657989502,
        3.0457732677459717,
        3.09175181388855,
        3.1299965381622314,
        3.14900541305542,
        3.1722636222839355,
        3.1965274810791016,
        3.208303451538086,
        3.2306618690490723
    ],
    "train_accuracy": [
        0.5625,
        0.75,
        0.9375,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.11797809600830078,
        0.03190350532531738,
        0.050669193267822266,
        0.015395164489746094,
        0.0254209041595459,
        0.017580270767211914,
        0.014478206634521484,
        0.015013694763183594,
        0.016710758209228516,
        0.013531208038330078,
        0.015145063400268555,
        0.013950347900390625,
        0.013676166534423828,
        0.013553619384765625,
        0.017361164093017578,
        0.014809608459472656,
        0.015561580657958984,
        0.014442682266235352,
        0.01473855972290039,
        0.013864278793334961,
        0.014970064163208008,
        0.01706838607788086,
        0.014715433120727539,
        0.0147705078125,
        0.013570785522460938,
        0.013562917709350586,
        0.013927459716796875,
        0.026952266693115234,
        0.013946056365966797,
        0.014159202575683594,
        0.014072895050048828
    ]
}