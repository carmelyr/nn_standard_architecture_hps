{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 32,
    "train_loss": [
        1.6982275247573853,
        1.8406777381896973,
        1.6865761280059814,
        1.30523681640625,
        1.4313743114471436,
        1.278045415878296,
        1.740309238433838,
        1.6094579696655273,
        1.3887989521026611,
        1.1260989904403687,
        1.3341591358184814,
        1.4738881587982178,
        1.2896043062210083,
        1.284470558166504,
        1.545353651046753,
        1.5745370388031006,
        1.316396951675415,
        1.6517990827560425,
        1.2458723783493042,
        1.4998185634613037,
        1.2282605171203613,
        1.23234224319458,
        1.6474257707595825,
        1.4769511222839355,
        1.1208075284957886,
        1.6033562421798706,
        1.6726661920547485,
        1.2014650106430054,
        1.398694634437561,
        1.6394050121307373,
        1.4549667835235596,
        1.538424015045166
    ],
    "val_loss": [
        1.6147323846817017,
        1.3877798318862915,
        1.340175986289978,
        1.345041036605835,
        1.3729274272918701,
        1.3968106508255005,
        1.4215351343154907,
        1.4256876707077026,
        1.4242780208587646,
        1.4194403886795044,
        1.415908932685852,
        1.420630931854248,
        1.4274935722351074,
        1.439202070236206,
        1.4450278282165527,
        1.4470082521438599,
        1.4375238418579102,
        1.431677222251892,
        1.4167267084121704,
        1.4111803770065308,
        1.411867618560791,
        1.4154847860336304,
        1.41508150100708,
        1.416072130203247,
        1.4147605895996094,
        1.416286826133728,
        1.416179895401001,
        1.415648341178894,
        1.415124535560608,
        1.414719581604004,
        1.4131313562393188,
        1.4125268459320068,
        1.4134935140609741
    ],
    "train_accuracy": [
        0.3125,
        0.125,
        0.3125,
        0.4375,
        0.25,
        0.5,
        0.1875,
        0.125,
        0.5,
        0.5625,
        0.375,
        0.25,
        0.4375,
        0.5625,
        0.125,
        0.3125,
        0.5,
        0.1875,
        0.375,
        0.375,
        0.5625,
        0.4375,
        0.25,
        0.4375,
        0.5,
        0.4375,
        0.3125,
        0.5,
        0.375,
        0.3125,
        0.375,
        0.125
    ],
    "val_accuracy": [
        0.1875,
        0.4375,
        0.5625,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.3125,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        1.7099909782409668,
        1.6858539581298828,
        1.690981149673462,
        1.6906516551971436,
        1.687997579574585,
        1.6943109035491943,
        1.69771409034729,
        1.6918737888336182,
        1.6913833618164062,
        1.6941914558410645,
        1.6940455436706543,
        1.6933763027191162,
        1.694098949432373,
        1.6952292919158936,
        1.6948626041412354,
        1.6997220516204834,
        1.6952235698699951,
        1.694415807723999,
        1.6932156085968018,
        1.6961603164672852,
        1.693495512008667,
        1.694870948791504,
        1.6961257457733154,
        1.7004480361938477,
        1.6970126628875732,
        1.702364444732666,
        1.7004616260528564,
        1.6967096328735352,
        1.6981801986694336,
        1.6983635425567627,
        1.6947903633117676,
        1.701143503189087
    ]
}