{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0740313187916,
        "ff_dim": 391,
        "hidden_units": 325,
        "learning_rate": 0.0001399254532,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 3.79775821e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 34,
    "train_loss": [
        1.8831638097763062,
        1.7316299676895142,
        1.43952476978302,
        1.2219158411026,
        1.41685950756073,
        1.39735746383667,
        1.25727379322052,
        1.1979565620422363,
        1.0692427158355713,
        0.9892233610153198,
        1.2122341394424438,
        1.0188779830932617,
        0.9779030084609985,
        1.1868774890899658,
        1.1279664039611816,
        0.9963608980178833,
        1.080386996269226,
        0.9540749192237854,
        0.8281412124633789,
        0.9605240821838379,
        0.6377499103546143,
        0.8694252967834473,
        0.9879199862480164,
        0.7252032160758972,
        0.8454279899597168,
        0.7771814465522766,
        0.6824557781219482,
        0.9989153146743774,
        0.6865261793136597,
        0.6503027677536011,
        0.7651769518852234,
        0.8541538119316101,
        0.9712501168251038,
        0.8234278559684753
    ],
    "val_loss": [
        2.2108545303344727,
        2.301011323928833,
        1.9438530206680298,
        1.427891731262207,
        1.3561410903930664,
        1.5840858221054077,
        1.6581705808639526,
        1.6659544706344604,
        1.58722984790802,
        1.6192735433578491,
        1.6228901147842407,
        1.658821702003479,
        1.69058358669281,
        1.754982829093933,
        1.91757333278656,
        1.9173779487609863,
        1.8255630731582642,
        1.7433754205703735,
        1.6773978471755981,
        1.6733088493347168,
        1.6958636045455933,
        1.7357314825057983,
        1.8014384508132935,
        1.8208924531936646,
        1.821701169013977,
        1.8532620668411255,
        1.864898681640625,
        1.867426872253418,
        1.8868390321731567,
        1.8893502950668335,
        1.881977915763855,
        1.8806082010269165,
        1.8854103088378906,
        1.893977165222168,
        1.902267575263977
    ],
    "train_accuracy": [
        0.25,
        0.375,
        0.3125,
        0.5625,
        0.4375,
        0.3125,
        0.375,
        0.5625,
        0.625,
        0.625,
        0.6875,
        0.5625,
        0.625,
        0.4375,
        0.5,
        0.5625,
        0.625,
        0.5625,
        0.625,
        0.625,
        0.75,
        0.6875,
        0.625,
        0.75,
        0.6875,
        0.8125,
        0.75,
        0.6875,
        0.75,
        0.875,
        0.8125,
        0.75,
        0.625,
        0.8125
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.5,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.3356165885925293,
        0.19975662231445312,
        0.19936084747314453,
        0.1991405487060547,
        0.1983809471130371,
        0.20138216018676758,
        0.20165157318115234,
        0.20038938522338867,
        0.19929194450378418,
        0.19924163818359375,
        0.19951987266540527,
        0.19897127151489258,
        0.1994633674621582,
        0.20153427124023438,
        0.20012283325195312,
        0.20254182815551758,
        0.2007911205291748,
        0.19968461990356445,
        0.2008810043334961,
        0.19958281517028809,
        0.19927430152893066,
        0.20104098320007324,
        0.20096182823181152,
        0.20142436027526855,
        0.20064878463745117,
        0.2013874053955078,
        0.20325064659118652,
        0.20163846015930176,
        0.20028209686279297,
        0.2004990577697754,
        0.1998906135559082,
        0.19946980476379395,
        0.20137262344360352,
        0.20114779472351074
    ]
}