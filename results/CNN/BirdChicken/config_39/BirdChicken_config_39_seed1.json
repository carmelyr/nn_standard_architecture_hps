{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3172593581459,
        "kernel_size": 3,
        "learning_rate": 0.00016592867,
        "num_filters": 164,
        "num_layers": 4,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.6072916984558105,
        0.5629472136497498,
        0.5446943640708923,
        0.5397250652313232,
        0.5844534635543823,
        0.5854834914207458,
        0.5307644009590149,
        0.5210621356964111,
        0.42607128620147705,
        0.4105513393878937,
        0.4177205562591553,
        0.37292787432670593,
        0.5341376066207886,
        0.3664587438106537,
        0.4119645357131958,
        0.47892627120018005,
        0.3288271427154541,
        0.3009036183357239,
        0.3347274661064148,
        0.3633911907672882,
        0.4244596064090729,
        0.266920268535614,
        0.24463431537151337,
        0.2872244417667389,
        0.19459417462348938,
        0.28120699524879456,
        0.24149155616760254,
        0.2520662248134613,
        0.2886851727962494,
        0.20252692699432373,
        0.19202256202697754
    ],
    "val_loss": [
        0.6889110207557678,
        0.6890916228294373,
        0.6895241737365723,
        0.6899139285087585,
        0.6903127431869507,
        0.6909617185592651,
        0.6915522217750549,
        0.6915732026100159,
        0.6917757391929626,
        0.692048192024231,
        0.6924437284469604,
        0.6934314966201782,
        0.6949493885040283,
        0.6957533955574036,
        0.6964031457901001,
        0.6978642344474792,
        0.698959469795227,
        0.7000046968460083,
        0.7008568644523621,
        0.7026630640029907,
        0.7039430737495422,
        0.7064334154129028,
        0.7090352773666382,
        0.7115398049354553,
        0.7142488956451416,
        0.718094527721405,
        0.7228930592536926,
        0.7275575399398804,
        0.7331527471542358,
        0.7415863275527954,
        0.7492795586585999,
        0.7561162114143372
    ],
    "train_accuracy": [
        0.625,
        0.71875,
        0.78125,
        0.65625,
        0.625,
        0.6875,
        0.75,
        0.75,
        0.875,
        0.78125,
        0.75,
        0.8125,
        0.6875,
        0.84375,
        0.8125,
        0.8125,
        0.84375,
        0.90625,
        0.90625,
        0.8125,
        0.75,
        0.9375,
        0.9375,
        0.875,
        0.96875,
        0.9375,
        0.9375,
        0.90625,
        0.875,
        0.90625,
        0.9375
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.5,
        0.5,
        0.25
    ],
    "epoch_times": [
        0.20425677299499512,
        0.13989520072937012,
        0.03309369087219238,
        0.029799461364746094,
        0.026900768280029297,
        0.02639007568359375,
        0.02547144889831543,
        0.024202346801757812,
        0.02398514747619629,
        0.023929834365844727,
        0.023555755615234375,
        0.02353954315185547,
        0.023945331573486328,
        0.023792743682861328,
        0.024039268493652344,
        0.02383279800415039,
        0.023364782333374023,
        0.023225784301757812,
        0.023653507232666016,
        0.023695707321166992,
        0.025762557983398438,
        0.023189306259155273,
        0.023114919662475586,
        0.023815393447875977,
        0.023800373077392578,
        0.02281332015991211,
        0.022425174713134766,
        0.021926164627075195,
        0.022576570510864258,
        0.022336721420288086,
        0.0222318172454834
    ]
}