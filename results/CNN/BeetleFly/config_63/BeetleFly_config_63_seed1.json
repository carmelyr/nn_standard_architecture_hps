{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0876662958857,
        "kernel_size": 6,
        "learning_rate": 0.0083678269036,
        "num_filters": 66,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7706645727157593,
        0.5835864543914795,
        0.6582025289535522,
        0.21652936935424805,
        0.20867519080638885,
        0.09851342439651489,
        0.08458156883716583,
        0.08251848071813583,
        0.032439909875392914,
        0.03539847582578659,
        0.053904592990875244,
        0.006936110556125641,
        0.04540976136922836,
        0.006392954848706722,
        0.0028467560186982155,
        0.00811725202947855,
        0.001505718333646655,
        0.002631259383633733,
        0.001139258616603911,
        0.004836265929043293,
        0.002866963855922222,
        0.052889227867126465,
        0.0066965664736926556,
        0.006915958132594824,
        0.020272551104426384,
        0.0005444990820251405,
        0.0006793838692829013,
        0.003174849785864353,
        0.0006863016751594841,
        0.09282906353473663,
        0.00022412178805097938
    ],
    "val_loss": [
        0.7001984119415283,
        0.689781904220581,
        0.7526165246963501,
        0.8269342184066772,
        0.8599070310592651,
        0.7791958451271057,
        1.0394402742385864,
        1.4175159931182861,
        1.9018032550811768,
        2.3899893760681152,
        2.5925841331481934,
        2.9614386558532715,
        3.3436481952667236,
        3.5477170944213867,
        3.6842708587646484,
        3.8402655124664307,
        4.012206077575684,
        4.192102432250977,
        4.346438407897949,
        4.483497619628906,
        4.578943252563477,
        4.63057279586792,
        4.433084487915039,
        4.315962791442871,
        4.240182876586914,
        4.306451320648193,
        4.388891220092773,
        4.502213954925537,
        4.600138187408447,
        4.671010971069336,
        4.7468791007995605,
        4.81170654296875
    ],
    "train_accuracy": [
        0.625,
        0.71875,
        0.84375,
        0.9375,
        0.90625,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875
    ],
    "epoch_times": [
        3.732112169265747,
        0.05261802673339844,
        0.024644851684570312,
        0.026354312896728516,
        0.02455592155456543,
        0.024096965789794922,
        0.024343013763427734,
        0.0241849422454834,
        0.02348804473876953,
        0.024096012115478516,
        0.025621891021728516,
        0.023599863052368164,
        0.023038864135742188,
        0.023746013641357422,
        0.02348017692565918,
        0.023794889450073242,
        0.023461103439331055,
        0.02242302894592285,
        0.0229489803314209,
        0.025236129760742188,
        0.023952245712280273,
        0.02266979217529297,
        0.023350954055786133,
        0.021965980529785156,
        0.022148847579956055,
        0.023545026779174805,
        0.023000001907348633,
        0.024627208709716797,
        0.02345871925354004,
        0.02314901351928711,
        0.023134231567382812
    ]
}