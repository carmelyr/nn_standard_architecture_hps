{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.4535545276102,
        "kernel_size": 7,
        "learning_rate": 0.0017894055959,
        "num_filters": 124,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.7800501585006714,
        0.3369778096675873,
        0.2328035533428192,
        0.23074497282505035,
        0.1350172460079193,
        0.18498782813549042,
        0.11175920069217682,
        0.14280273020267487,
        0.11635341495275497,
        0.08534806221723557,
        0.08006472140550613,
        0.1112738773226738,
        0.07528644800186157,
        0.08283070474863052,
        0.05516890436410904,
        0.05257386714220047,
        0.0761883556842804,
        0.04537001624703407,
        0.04007058963179588,
        0.03992071375250816,
        0.038538530468940735,
        0.028939535841345787,
        0.024382146075367928,
        0.042127665132284164,
        0.041252363473176956,
        0.05788218975067139,
        0.02388661913573742,
        0.0227082259953022,
        0.02297228015959263,
        0.026134924963116646,
        0.02751253917813301,
        0.01860080659389496,
        0.016099272295832634,
        0.016463929787278175
    ],
    "val_loss": [
        0.6817733645439148,
        0.6850789785385132,
        0.6653099656105042,
        0.6504697203636169,
        0.6456577777862549,
        0.6545436382293701,
        0.6706761717796326,
        0.6926553249359131,
        0.7212363481521606,
        0.7510143518447876,
        0.7849181294441223,
        0.8343114256858826,
        0.8900471925735474,
        0.9473292231559753,
        1.007384181022644,
        1.0724356174468994,
        1.1414926052093506,
        1.2209991216659546,
        1.294021725654602,
        1.3601633310317993,
        1.4260900020599365,
        1.4859939813613892,
        1.5400419235229492,
        1.5916553735733032,
        1.6408400535583496,
        1.6910301446914673,
        1.7382653951644897,
        1.7824372053146362,
        1.827040433883667,
        1.8670315742492676,
        1.8981001377105713,
        1.9261125326156616,
        1.9589382410049438,
        1.9862422943115234,
        2.0185139179229736
    ],
    "train_accuracy": [
        0.5,
        0.90625,
        0.96875,
        0.90625,
        1.0,
        0.96875,
        1.0,
        0.96875,
        0.96875,
        1.0,
        1.0,
        0.9375,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.09906840324401855,
        0.02792191505432129,
        0.017972230911254883,
        0.018126249313354492,
        0.012186765670776367,
        0.012394905090332031,
        0.020920753479003906,
        0.015857934951782227,
        0.016992807388305664,
        0.015294551849365234,
        0.014139175415039062,
        0.017460107803344727,
        0.01586127281188965,
        0.015092611312866211,
        0.013955116271972656,
        0.013806581497192383,
        0.013616561889648438,
        0.014043807983398438,
        0.014818429946899414,
        0.012476682662963867,
        0.01255941390991211,
        0.012747049331665039,
        0.012661457061767578,
        0.012284278869628906,
        0.012509584426879883,
        0.012116193771362305,
        0.016962528228759766,
        0.012854576110839844,
        0.012818098068237305,
        0.013741731643676758,
        0.013316869735717773,
        0.012674331665039062,
        0.012500524520874023,
        0.012695074081420898
    ]
}