{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3663849266307,
        "kernel_size": 3,
        "learning_rate": 0.0043888822554,
        "num_filters": 229,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.8480234146118164,
        0.7300110459327698,
        0.4406261742115021,
        0.2982415556907654,
        0.20705267786979675,
        0.19498375058174133,
        0.20538438856601715,
        0.16316135227680206,
        0.1739944964647293,
        0.13040269911289215,
        0.11994033306837082,
        0.08335024863481522,
        0.06943338364362717,
        0.09345534443855286,
        0.08293792605400085,
        0.08577140420675278,
        0.06007411330938339,
        0.05868121236562729,
        0.029649846255779266,
        0.052350666373968124,
        0.02737421728670597,
        0.04492472484707832,
        0.020846929401159286,
        0.028093889355659485,
        0.01968553103506565,
        0.01767531968653202,
        0.01224065013229847,
        0.009687569923698902,
        0.013406515121459961,
        0.011566903442144394,
        0.007481212727725506
    ],
    "val_loss": [
        0.6995500326156616,
        0.548323929309845,
        0.7480210065841675,
        0.8789987564086914,
        0.9603080749511719,
        1.0313384532928467,
        1.1006288528442383,
        1.136284589767456,
        1.1423008441925049,
        1.1151429414749146,
        1.1075612306594849,
        1.1248458623886108,
        1.1670862436294556,
        1.2206230163574219,
        1.2803276777267456,
        1.3431533575057983,
        1.4094855785369873,
        1.4792039394378662,
        1.5536754131317139,
        1.62969172000885,
        1.7028037309646606,
        1.778180480003357,
        1.8452327251434326,
        1.9091295003890991,
        1.968279480934143,
        2.0269877910614014,
        2.0820090770721436,
        2.1345582008361816,
        2.188777446746826,
        2.243157148361206,
        2.298222541809082,
        2.3534321784973145
    ],
    "train_accuracy": [
        0.40625,
        0.65625,
        0.90625,
        0.90625,
        0.9375,
        0.9375,
        0.9375,
        0.96875,
        0.9375,
        0.96875,
        0.9375,
        1.0,
        1.0,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.5,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.75,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.08764958381652832,
        0.1449112892150879,
        0.013560771942138672,
        0.012761116027832031,
        0.011910200119018555,
        0.011027812957763672,
        0.012963533401489258,
        0.010773897171020508,
        0.011394500732421875,
        0.011492252349853516,
        0.011399507522583008,
        0.01095890998840332,
        0.01072382926940918,
        0.015992403030395508,
        0.012611627578735352,
        0.010860919952392578,
        0.011229515075683594,
        0.011226892471313477,
        0.01445317268371582,
        0.014500856399536133,
        0.014829397201538086,
        0.014649391174316406,
        0.016748905181884766,
        0.014299631118774414,
        0.01605534553527832,
        0.013456106185913086,
        0.014054536819458008,
        0.015154361724853516,
        0.01354217529296875,
        0.014624357223510742,
        0.013997316360473633
    ]
}