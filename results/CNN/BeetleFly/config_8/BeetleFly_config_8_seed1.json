{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.4828634018447,
        "kernel_size": 7,
        "learning_rate": 0.004118329187,
        "num_filters": 191,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.855912446975708,
        1.0152114629745483,
        0.5617883801460266,
        0.2690194249153137,
        0.4698406159877777,
        0.16945940256118774,
        0.1542501151561737,
        0.053648095577955246,
        0.09989853948354721,
        0.1821153461933136,
        0.10839498043060303,
        0.11661454290151596,
        0.11525032669305801,
        0.1919904202222824,
        0.16502845287322998,
        0.04638471081852913,
        0.05725788325071335,
        0.10757171362638474,
        0.04389241710305214,
        0.09898047894239426,
        0.06961505860090256,
        0.038553427904844284,
        0.037533607333898544,
        0.021482491865754128,
        0.012192909605801105,
        0.034469783306121826,
        0.026047462597489357,
        0.05283401906490326,
        0.03232601284980774,
        0.00845455750823021,
        0.02060425654053688
    ],
    "val_loss": [
        0.6898243427276611,
        0.6883916854858398,
        0.6908453106880188,
        0.6989952325820923,
        0.7202184796333313,
        0.7531912922859192,
        0.8086807727813721,
        0.8917264342308044,
        1.0180692672729492,
        1.1732583045959473,
        1.3639940023422241,
        1.5670689344406128,
        1.7706786394119263,
        1.986337661743164,
        2.2599871158599854,
        2.5459864139556885,
        2.841088056564331,
        3.1433026790618896,
        3.4869415760040283,
        3.8536646366119385,
        4.227816104888916,
        4.565374374389648,
        4.955427646636963,
        5.281078338623047,
        5.594916820526123,
        5.8571977615356445,
        6.12295389175415,
        6.308979034423828,
        6.537021636962891,
        6.59246826171875,
        6.666837215423584,
        6.92702579498291
    ],
    "train_accuracy": [
        0.5,
        0.53125,
        0.625,
        0.9375,
        0.78125,
        0.9375,
        0.875,
        1.0,
        0.9375,
        0.9375,
        0.96875,
        0.9375,
        0.90625,
        0.96875,
        0.9375,
        0.96875,
        0.96875,
        0.9375,
        1.0,
        0.9375,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.375,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.4025728702545166,
        0.019700050354003906,
        0.020264148712158203,
        0.02039313316345215,
        0.020890235900878906,
        0.021364688873291016,
        0.0214998722076416,
        0.0221097469329834,
        0.021846294403076172,
        0.022312641143798828,
        0.021692752838134766,
        0.02269268035888672,
        0.02232193946838379,
        0.02134561538696289,
        0.022062063217163086,
        0.021545886993408203,
        0.021362781524658203,
        0.02185201644897461,
        0.021635770797729492,
        0.021269798278808594,
        0.020240068435668945,
        0.0203244686126709,
        0.020383834838867188,
        0.019529342651367188,
        0.02173638343811035,
        0.01749897003173828,
        0.0181882381439209,
        0.016987323760986328,
        0.017660140991210938,
        0.015719890594482422,
        0.016991376876831055
    ]
}