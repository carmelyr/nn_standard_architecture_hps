{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1617706587673,
        "kernel_size": 6,
        "learning_rate": 0.0005297303088,
        "num_filters": 228,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 2,
        "residual": false
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.583922863006592,
        3.3351871967315674,
        3.2099311351776123,
        3.1321914196014404,
        3.051180362701416,
        2.9814887046813965,
        2.9083051681518555,
        2.8258309364318848,
        2.7748968601226807,
        2.694504976272583,
        2.6355364322662354,
        2.5801634788513184,
        2.556269884109497,
        2.5012571811676025,
        2.4106481075286865
    ],
    "val_loss": [
        3.547769069671631,
        3.4417784214019775,
        3.386662244796753,
        3.3163580894470215,
        3.2914981842041016,
        3.332547426223755,
        3.250487804412842,
        3.202410936355591,
        3.2062952518463135,
        3.184262990951538,
        3.1386444568634033,
        3.1305172443389893,
        3.1692090034484863,
        3.0976736545562744,
        3.048337936401367,
        3.0522468090057373
    ],
    "train_accuracy": [
        0.05288461595773697,
        0.09775640815496445,
        0.11858974397182465,
        0.14262820780277252,
        0.16613247990608215,
        0.17040598392486572,
        0.1933760643005371,
        0.21901708841323853,
        0.2350427359342575,
        0.2590811848640442,
        0.27724358439445496,
        0.2889957129955292,
        0.3007478713989258,
        0.30021366477012634,
        0.33066239953041077
    ],
    "val_accuracy": [
        0.0,
        0.05128205195069313,
        0.07051282376050949,
        0.09615384787321091,
        0.11965811997652054,
        0.09829059988260269,
        0.14316239953041077,
        0.13034188747406006,
        0.14316239953041077,
        0.15811966359615326,
        0.1645299196243286,
        0.18589743971824646,
        0.15598291158676147,
        0.15811966359615326,
        0.18376068770885468,
        0.17307692766189575
    ]
}