{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2823050495344,
        "kernel_size": 6,
        "learning_rate": 0.0026153421423,
        "num_filters": 75,
        "num_layers": 4,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.6412711143493652,
        1.6998282670974731,
        1.4125758409500122,
        1.4256528615951538,
        1.5054339170455933,
        1.028894305229187,
        1.0694997310638428,
        0.9522214531898499,
        1.0024640560150146,
        0.8218141198158264,
        0.7888829112052917,
        0.7823768258094788,
        0.8277035355567932,
        0.8139641880989075,
        0.7930078506469727,
        0.6621465086936951,
        0.7263843417167664,
        0.5660406947135925,
        0.7397677302360535,
        0.5866875052452087,
        0.5988962650299072,
        0.5043801665306091,
        0.5048167705535889,
        0.43451058864593506,
        0.6046955585479736,
        0.3673671782016754,
        0.33757707476615906,
        0.39379680156707764,
        0.34164324402809143,
        0.3667657673358917,
        0.34995731711387634
    ],
    "val_loss": [
        1.6104931831359863,
        1.6173847913742065,
        1.6282835006713867,
        1.6246824264526367,
        1.6252354383468628,
        1.6443675756454468,
        1.6867055892944336,
        1.7474675178527832,
        1.717213749885559,
        1.718633770942688,
        1.8184747695922852,
        1.951161503791809,
        2.1494269371032715,
        2.114293336868286,
        2.0467886924743652,
        2.1651928424835205,
        2.245650053024292,
        2.362614870071411,
        2.372502565383911,
        2.0028069019317627,
        1.794705867767334,
        1.9032282829284668,
        2.1929433345794678,
        2.5085275173187256,
        2.6628432273864746,
        2.40596079826355,
        2.3259615898132324,
        2.3815362453460693,
        2.4576189517974854,
        2.616859197616577,
        2.4288885593414307,
        2.1595776081085205
    ],
    "train_accuracy": [
        0.3125,
        0.2916666567325592,
        0.4583333432674408,
        0.3958333432674408,
        0.375,
        0.5625,
        0.5208333134651184,
        0.6666666865348816,
        0.5833333134651184,
        0.6458333134651184,
        0.6458333134651184,
        0.625,
        0.7083333134651184,
        0.7083333134651184,
        0.6875,
        0.6458333134651184,
        0.7291666865348816,
        0.7916666865348816,
        0.7083333134651184,
        0.6875,
        0.7916666865348816,
        0.7916666865348816,
        0.8125,
        0.8125,
        0.7291666865348816,
        0.8333333134651184,
        0.8125,
        0.8125,
        0.875,
        0.8958333134651184,
        0.8541666865348816
    ],
    "val_accuracy": [
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.1666666716337204,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592
    ],
    "epoch_times": [
        0.1993417739868164,
        0.09722208976745605,
        0.04254460334777832,
        0.04553651809692383,
        0.04482603073120117,
        0.04242992401123047,
        0.040868282318115234,
        0.0426945686340332,
        0.04102373123168945,
        0.03985404968261719,
        0.036322593688964844,
        0.04003119468688965,
        0.03942990303039551,
        0.03946399688720703,
        0.04494452476501465,
        0.04702448844909668,
        0.035590410232543945,
        0.045540571212768555,
        0.04174375534057617,
        0.040705204010009766,
        0.038700103759765625,
        0.04187893867492676,
        0.04464411735534668,
        0.0454256534576416,
        0.04245901107788086,
        0.04196429252624512,
        0.042794227600097656,
        0.04387521743774414,
        0.04535675048828125,
        0.04362082481384277,
        0.041100502014160156
    ]
}