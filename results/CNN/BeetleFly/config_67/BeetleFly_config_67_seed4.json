{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0078882678643,
        "kernel_size": 5,
        "learning_rate": 0.0045123278898,
        "num_filters": 195,
        "num_layers": 3,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8077672123908997,
        0.3517528176307678,
        0.8352121710777283,
        0.14024846255779266,
        0.1280776560306549,
        0.09039516746997833,
        0.05525429546833038,
        0.04470430314540863,
        0.03858786076307297,
        0.03151925280690193,
        0.02315630204975605,
        0.01700039580464363,
        0.01311616413295269,
        0.009344900958240032,
        0.007824353873729706,
        0.0053365956991910934,
        0.003652472048997879,
        0.0030781670939177275,
        0.0027000545524060726,
        0.0020686567295342684,
        0.0017515805084258318,
        0.001476106233894825,
        0.0011074437061324716,
        0.0010371707612648606,
        0.0009138227324001491,
        0.0007756650447845459,
        0.0006531346007250249,
        0.0005862879334017634,
        0.00060272152768448,
        0.0005259208846837282,
        0.0004926788387820125,
        0.0005428290460258722
    ],
    "val_loss": [
        0.702541172504425,
        0.7137035131454468,
        0.6343643665313721,
        0.7317327857017517,
        0.8699970841407776,
        1.00364351272583,
        1.1215770244598389,
        1.2518236637115479,
        1.4167453050613403,
        1.6333554983139038,
        1.8727493286132812,
        2.108567953109741,
        2.3171496391296387,
        2.487301826477051,
        2.612067937850952,
        2.7089524269104004,
        2.772050619125366,
        2.8100767135620117,
        2.8169875144958496,
        2.8054678440093994,
        2.7766921520233154,
        2.7421772480010986,
        2.698859453201294,
        2.650829315185547,
        2.6019043922424316,
        2.5490610599517822,
        2.4981770515441895,
        2.4457638263702393,
        2.400566339492798,
        2.356156349182129,
        2.317211151123047,
        2.282501459121704,
        2.260396718978882
    ],
    "train_accuracy": [
        0.5,
        0.8125,
        0.71875,
        0.9375,
        0.9375,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.75,
        0.375,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.08988595008850098,
        0.03972792625427246,
        0.047577857971191406,
        0.013495922088623047,
        0.013493776321411133,
        0.013454198837280273,
        0.013031482696533203,
        0.013755083084106445,
        0.014627456665039062,
        0.013953685760498047,
        0.019690990447998047,
        0.014102697372436523,
        0.014020204544067383,
        0.013418912887573242,
        0.013252735137939453,
        0.01814103126525879,
        0.014799833297729492,
        0.014620304107666016,
        0.014096260070800781,
        0.02185654640197754,
        0.013871431350708008,
        0.022421836853027344,
        0.014495611190795898,
        0.015200376510620117,
        0.013987302780151367,
        0.018444299697875977,
        0.015847444534301758,
        0.026030302047729492,
        0.014859676361083984,
        0.014821767807006836,
        0.014983654022216797,
        0.01500844955444336
    ]
}