{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0811492992512,
        "kernel_size": 5,
        "learning_rate": 0.000747299215,
        "num_filters": 71,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 2,
        "residual": false
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.6023313999176025,
        3.4180996417999268,
        3.3155384063720703,
        3.2791032791137695,
        3.2152647972106934,
        3.1438984870910645,
        3.0936152935028076,
        3.0692312717437744,
        2.9980852603912354,
        2.9320261478424072,
        2.9314754009246826,
        2.906261920928955,
        2.8725383281707764,
        2.8340368270874023,
        2.775932788848877
    ],
    "val_loss": [
        3.5572452545166016,
        3.527082681655884,
        3.4623141288757324,
        3.428283214569092,
        3.351731538772583,
        3.343151330947876,
        3.3803658485412598,
        3.3682641983032227,
        3.296022415161133,
        3.2995047569274902,
        3.2484469413757324,
        3.237581968307495,
        3.222794771194458,
        3.2220511436462402,
        3.191905975341797,
        3.2213597297668457
    ],
    "train_accuracy": [
        0.036858975887298584,
        0.07959401607513428,
        0.10256410390138626,
        0.10309828817844391,
        0.12393162399530411,
        0.13621795177459717,
        0.14423076808452606,
        0.1458333283662796,
        0.17521367967128754,
        0.1816239356994629,
        0.18803419172763824,
        0.1864316165447235,
        0.2024572640657425,
        0.21153846383094788,
        0.2072649598121643
    ],
    "val_accuracy": [
        0.0,
        0.061965811997652054,
        0.07051282376050949,
        0.0555555559694767,
        0.09615384787321091,
        0.09188034385442734,
        0.0833333358168602,
        0.09188034385442734,
        0.08547008782625198,
        0.07051282376050949,
        0.10897435992956161,
        0.13034188747406006,
        0.11324786394834518,
        0.10470085591077805,
        0.11752136796712875,
        0.10683760792016983
    ]
}