{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.4604736078126,
        "kernel_size": 6,
        "learning_rate": 0.0001308354078,
        "num_filters": 153,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.8627487421035767,
        0.7330585718154907,
        0.5241801142692566,
        0.6609008312225342,
        0.43341901898384094,
        0.5687963366508484,
        0.42607802152633667,
        0.5056743621826172,
        0.44150325655937195,
        0.5056359171867371,
        0.4190235137939453,
        0.33349892497062683,
        0.39376404881477356,
        0.24446788430213928,
        0.3377438187599182,
        0.24500399827957153,
        0.30171483755111694,
        0.1958792805671692,
        0.2391211986541748,
        0.1885066032409668,
        0.19782575964927673,
        0.11132168769836426,
        0.16182982921600342,
        0.1518605798482895,
        0.14647363126277924,
        0.07574258744716644,
        0.08997344225645065,
        0.11729742586612701,
        0.10132356733083725,
        0.09312622249126434,
        0.06725705415010452
    ],
    "val_loss": [
        0.6958886384963989,
        0.6963910460472107,
        0.699191153049469,
        0.7019149661064148,
        0.7046830058097839,
        0.7078136205673218,
        0.710902988910675,
        0.712494969367981,
        0.7147994637489319,
        0.7194592356681824,
        0.7262389659881592,
        0.7327905893325806,
        0.7415212392807007,
        0.7490467429161072,
        0.7604263424873352,
        0.7732317447662354,
        0.7874476313591003,
        0.8046990633010864,
        0.8193418383598328,
        0.8394447565078735,
        0.8587777018547058,
        0.8770702481269836,
        0.8915759325027466,
        0.9085451364517212,
        0.9234926104545593,
        0.949221134185791,
        0.9817904829978943,
        1.0153775215148926,
        1.0613667964935303,
        1.1195858716964722,
        1.1807866096496582,
        1.2457259893417358
    ],
    "train_accuracy": [
        0.5625,
        0.53125,
        0.6875,
        0.59375,
        0.75,
        0.65625,
        0.875,
        0.71875,
        0.71875,
        0.8125,
        0.84375,
        0.78125,
        0.875,
        0.9375,
        0.84375,
        0.9375,
        0.875,
        0.9375,
        0.90625,
        0.90625,
        0.9375,
        1.0,
        0.96875,
        1.0,
        0.9375,
        1.0,
        1.0,
        0.96875,
        0.96875,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.11086678504943848,
        0.22706198692321777,
        0.0220184326171875,
        0.021729230880737305,
        0.02243781089782715,
        0.022686243057250977,
        0.022192001342773438,
        0.022012710571289062,
        0.02257227897644043,
        0.022168397903442383,
        0.021268606185913086,
        0.021327495574951172,
        0.020890235900878906,
        0.021872997283935547,
        0.021433591842651367,
        0.021510839462280273,
        0.02183222770690918,
        0.020293712615966797,
        0.02128767967224121,
        0.02114248275756836,
        0.02112555503845215,
        0.020721435546875,
        0.020104169845581055,
        0.020751476287841797,
        0.020273447036743164,
        0.019961118698120117,
        0.020496368408203125,
        0.020444154739379883,
        0.020342588424682617,
        0.022597074508666992,
        0.021510839462280273
    ]
}