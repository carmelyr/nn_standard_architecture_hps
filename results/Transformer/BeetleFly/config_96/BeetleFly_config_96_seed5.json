{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0085693488774,
        "ff_dim": 366,
        "hidden_units": 252,
        "learning_rate": 0.000296152136,
        "num_heads": 8,
        "num_layers": 5,
        "pooling": "mean",
        "weight_decay": 3.90141137e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 33,
    "train_loss": [
        1.0717055797576904,
        4.106957912445068,
        2.152712106704712,
        0.7098424434661865,
        1.3107985258102417,
        1.131613850593567,
        0.7118956446647644,
        1.1386455297470093,
        1.2265044450759888,
        0.9687367677688599,
        0.7717434763908386,
        0.7023086547851562,
        0.7208420038223267,
        0.7843832969665527,
        0.7471786141395569,
        0.7314285039901733,
        0.6945477724075317,
        0.6812387704849243,
        0.6775146722793579,
        0.6878193020820618,
        0.698344349861145,
        0.7090834975242615,
        0.730354368686676,
        0.686079204082489,
        0.6609922051429749,
        0.6729552149772644,
        0.6748732924461365,
        0.6580460071563721,
        0.6545768976211548,
        0.6817116737365723,
        0.6632392406463623,
        0.6788302063941956,
        0.6495213508605957
    ],
    "val_loss": [
        1.4700485467910767,
        2.3361730575561523,
        1.2186815738677979,
        0.5341323018074036,
        1.6561018228530884,
        1.5285507440567017,
        0.901653528213501,
        0.915629506111145,
        0.8804077506065369,
        0.6416443586349487,
        0.5578815937042236,
        0.5706014037132263,
        0.7194669842720032,
        0.827612578868866,
        0.8406590819358826,
        0.7771700024604797,
        0.7258450984954834,
        0.6729841828346252,
        0.6338219046592712,
        0.6216102838516235,
        0.6171785593032837,
        0.6141843795776367,
        0.613976240158081,
        0.616233229637146,
        0.6230095624923706,
        0.6362019777297974,
        0.6525675058364868,
        0.6641403436660767,
        0.6659677028656006,
        0.6646056175231934,
        0.6596692800521851,
        0.6535099744796753,
        0.6461569666862488,
        0.6386938691139221
    ],
    "train_accuracy": [
        0.53125,
        0.46875,
        0.46875,
        0.5,
        0.53125,
        0.53125,
        0.5625,
        0.46875,
        0.46875,
        0.46875,
        0.5,
        0.46875,
        0.53125,
        0.53125,
        0.53125,
        0.53125,
        0.53125,
        0.5,
        0.53125,
        0.53125,
        0.5,
        0.4375,
        0.5,
        0.5625,
        0.625,
        0.5625,
        0.59375,
        0.625,
        0.5625,
        0.53125,
        0.59375,
        0.5625,
        0.625
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        1.0,
        0.375,
        0.375,
        0.25,
        0.625,
        0.625,
        0.625,
        0.625,
        1.0,
        0.5,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.13792657852172852,
        0.08707571029663086,
        0.08413004875183105,
        0.08388757705688477,
        0.08410906791687012,
        0.08357715606689453,
        0.08186197280883789,
        0.0827481746673584,
        0.08281326293945312,
        0.08547163009643555,
        0.0843343734741211,
        0.0825650691986084,
        0.08183145523071289,
        0.08314347267150879,
        0.082000732421875,
        0.08141279220581055,
        0.08235955238342285,
        0.0901339054107666,
        0.08142828941345215,
        0.08067631721496582,
        0.08096480369567871,
        0.5611329078674316,
        0.08331918716430664,
        0.08134818077087402,
        0.0829932689666748,
        0.0821688175201416,
        0.07984375953674316,
        0.08142948150634766,
        0.07966232299804688,
        0.07934451103210449,
        0.0821542739868164,
        0.08149147033691406,
        0.08225488662719727
    ]
}