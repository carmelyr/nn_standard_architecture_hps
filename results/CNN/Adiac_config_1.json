{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2101839010437,
        "kernel_size": 5,
        "learning_rate": 0.0009933958471,
        "num_filters": 112,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 2,
        "residual": true
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.6271729469299316,
        3.4190173149108887,
        3.3356704711914062,
        3.2530901432037354,
        3.20062255859375,
        3.1470651626586914,
        3.0951461791992188,
        3.0497260093688965,
        3.0033645629882812,
        2.9958691596984863,
        2.936004400253296,
        2.88631272315979,
        2.875389575958252,
        2.807598829269409,
        2.781765937805176
    ],
    "val_loss": [
        3.5559194087982178,
        3.452192544937134,
        3.3929316997528076,
        3.3510546684265137,
        3.309898614883423,
        3.271780014038086,
        3.2213046550750732,
        3.1781485080718994,
        3.1876378059387207,
        3.1363606452941895,
        3.115083932876587,
        3.0792245864868164,
        3.0651626586914062,
        3.077214241027832,
        3.015763998031616,
        3.0198819637298584
    ],
    "train_accuracy": [
        0.04754273593425751,
        0.0822649598121643,
        0.10042735189199448,
        0.10630341619253159,
        0.11538461595773697,
        0.13354700803756714,
        0.13514956831932068,
        0.16239316761493683,
        0.17147435247898102,
        0.16826923191547394,
        0.18482905626296997,
        0.19177350401878357,
        0.19391025602817535,
        0.21100427210330963,
        0.2072649598121643
    ],
    "val_accuracy": [
        0.0,
        0.07478632777929306,
        0.0683760717511177,
        0.09829059988260269,
        0.10256410390138626,
        0.10256410390138626,
        0.10470085591077805,
        0.15598291158676147,
        0.13034188747406006,
        0.1517094075679779,
        0.1367521435022354,
        0.13034188747406006,
        0.14529915153980255,
        0.16025641560554504,
        0.16239316761493683,
        0.15598291158676147
    ]
}