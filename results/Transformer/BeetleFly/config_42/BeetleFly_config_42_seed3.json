{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.0403092744102,
        "ff_dim": 422,
        "hidden_units": 132,
        "learning_rate": 0.0007862395322,
        "num_heads": 8,
        "num_layers": 1,
        "pooling": "max",
        "weight_decay": 4.12806002e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.8700084686279297,
        1.4083049297332764,
        1.0594695806503296,
        0.6420664191246033,
        0.7854452133178711,
        0.8449464440345764,
        0.7561857104301453,
        0.6782275438308716,
        0.7244528532028198,
        0.6735535264015198,
        0.6975287795066833,
        0.6262620687484741,
        0.5961132645606995,
        0.6290307641029358,
        0.5241534113883972,
        0.580862820148468,
        0.6810919046401978,
        0.6020816564559937,
        0.6198108792304993,
        0.5599111914634705,
        0.634759783744812,
        0.5789998769760132,
        0.5558083653450012,
        0.5404366850852966,
        0.5678418874740601,
        0.5537933111190796,
        0.5504874587059021,
        0.585919976234436,
        0.5632455348968506,
        0.5517923831939697,
        0.5582822561264038,
        0.5782026648521423,
        0.4892725348472595,
        0.5494648218154907
    ],
    "val_loss": [
        0.8146106600761414,
        2.173262596130371,
        1.7743619680404663,
        1.0180425643920898,
        1.0095770359039307,
        1.076887845993042,
        1.13660728931427,
        1.3688981533050537,
        1.4644311666488647,
        1.397437334060669,
        1.2811963558197021,
        1.2717604637145996,
        1.2907347679138184,
        1.33237886428833,
        1.4029940366744995,
        1.4812778234481812,
        1.522301197052002,
        1.5233927965164185,
        1.5058256387710571,
        1.4805678129196167,
        1.4598755836486816,
        1.4438260793685913,
        1.4434174299240112,
        1.449309229850769,
        1.4604911804199219,
        1.47760009765625,
        1.4989145994186401,
        1.5219826698303223,
        1.5504831075668335,
        1.5643856525421143,
        1.5748909711837769,
        1.5817804336547852,
        1.585029125213623,
        1.5854567289352417,
        1.5833901166915894
    ],
    "train_accuracy": [
        0.46875,
        0.53125,
        0.53125,
        0.625,
        0.46875,
        0.5,
        0.34375,
        0.59375,
        0.625,
        0.5625,
        0.5625,
        0.5625,
        0.71875,
        0.6875,
        0.78125,
        0.71875,
        0.625,
        0.65625,
        0.71875,
        0.6875,
        0.625,
        0.71875,
        0.71875,
        0.78125,
        0.6875,
        0.71875,
        0.6875,
        0.65625,
        0.6875,
        0.75,
        0.71875,
        0.78125,
        0.78125,
        0.71875
    ],
    "val_accuracy": [
        0.625,
        0.25,
        0.25,
        0.25,
        0.625,
        0.625,
        0.5,
        0.125,
        0.125,
        0.125,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.25,
        0.25,
        0.25,
        0.25,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.04505205154418945,
        0.028305530548095703,
        0.027820825576782227,
        0.028831958770751953,
        0.02753758430480957,
        0.029018640518188477,
        0.028110742568969727,
        0.029641151428222656,
        0.02951335906982422,
        0.029894113540649414,
        0.029436349868774414,
        0.032949209213256836,
        0.030455589294433594,
        0.028993606567382812,
        0.0292971134185791,
        0.028577566146850586,
        0.028383731842041016,
        0.028925418853759766,
        0.02880859375,
        0.0283968448638916,
        0.029604434967041016,
        0.02803802490234375,
        0.02790236473083496,
        0.02807760238647461,
        0.02798748016357422,
        0.02895665168762207,
        0.028948307037353516,
        0.028676748275756836,
        0.029387235641479492,
        0.02938079833984375,
        0.02854466438293457,
        0.028458833694458008,
        0.028769493103027344,
        0.028135299682617188
    ]
}