{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1946683822245,
        "hidden_units": 50,
        "learning_rate": 0.0063916696635,
        "num_layers": 4,
        "weight_decay": 0.0011710711659
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 36,
        "val_size": 9,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7529670596122742,
        0.827183187007904,
        0.6112635135650635,
        0.6418983936309814,
        0.5179200768470764,
        0.5325058698654175,
        0.5189539790153503,
        0.4419631361961365,
        0.49057525396347046,
        0.4668754041194916,
        0.5066342353820801,
        0.3412575423717499,
        0.37434709072113037,
        0.3816412687301636,
        0.25604933500289917,
        0.3157186508178711,
        0.4175465703010559,
        0.23048537969589233,
        0.30292826890945435,
        0.2637407183647156,
        0.26878079771995544,
        0.34187859296798706,
        0.2344730943441391,
        0.2395581156015396,
        0.24828127026557922,
        0.24003887176513672,
        0.24612662196159363,
        0.23290954530239105,
        0.3027437925338745,
        0.24009758234024048,
        0.23044994473457336
    ],
    "val_loss": [
        0.6976041793823242,
        0.6792278289794922,
        0.6990604400634766,
        0.7394192218780518,
        0.7462913990020752,
        0.8599063754081726,
        0.8849064707756042,
        0.9997829794883728,
        0.9851586818695068,
        0.8578645586967468,
        0.9353165030479431,
        0.9102408289909363,
        1.0588328838348389,
        1.0361311435699463,
        0.894368588924408,
        0.9228278398513794,
        0.9204420447349548,
        1.0184242725372314,
        1.1246528625488281,
        1.0636558532714844,
        1.0653877258300781,
        1.0035456418991089,
        1.169114589691162,
        1.179442286491394,
        1.223243236541748,
        1.1934443712234497,
        0.8536521792411804,
        0.9056404829025269,
        1.2463849782943726,
        1.5098919868469238,
        1.629427194595337,
        1.7137192487716675
    ],
    "train_accuracy": [
        0.5,
        0.5277777910232544,
        0.6388888955116272,
        0.6388888955116272,
        0.7222222089767456,
        0.6666666865348816,
        0.7222222089767456,
        0.8333333134651184,
        0.6666666865348816,
        0.75,
        0.7777777910232544,
        0.9166666865348816,
        0.8611111044883728,
        0.8888888955116272,
        0.9444444179534912,
        0.8888888955116272,
        0.7777777910232544,
        0.9444444179534912,
        0.8888888955116272,
        0.9444444179534912,
        0.9166666865348816,
        0.8333333134651184,
        0.8888888955116272,
        0.9166666865348816,
        0.9166666865348816,
        0.8888888955116272,
        0.8611111044883728,
        0.9166666865348816,
        0.8333333134651184,
        0.8611111044883728,
        0.8888888955116272
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.6666666865348816,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.4444444477558136,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088,
        0.5555555820465088
    ],
    "epoch_times": [
        0.034475088119506836,
        0.029122114181518555,
        0.028234004974365234,
        0.0281369686126709,
        0.02845287322998047,
        0.029729127883911133,
        0.02803802490234375,
        0.028542041778564453,
        0.028261184692382812,
        0.02862405776977539,
        0.0285031795501709,
        0.028469085693359375,
        0.02813410758972168,
        0.028272151947021484,
        0.027927875518798828,
        0.0281369686126709,
        0.028153181076049805,
        0.02860093116760254,
        0.02820110321044922,
        0.028174161911010742,
        0.028248071670532227,
        0.02817511558532715,
        0.03055882453918457,
        0.028695106506347656,
        0.028243064880371094,
        0.028009891510009766,
        0.027986764907836914,
        0.027904987335205078,
        0.027881860733032227,
        0.02797412872314453,
        0.027704238891601562
    ]
}