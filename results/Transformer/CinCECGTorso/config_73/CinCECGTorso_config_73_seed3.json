{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2343066462444,
        "ff_dim": 693,
        "hidden_units": 382,
        "learning_rate": 9.45319945e-05,
        "num_heads": 2,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 5.13722523e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        3.9305155277252197,
        1.4734582901000977,
        1.1173323392868042,
        1.449975609779358,
        1.3409276008605957,
        1.382440209388733,
        1.1987190246582031,
        1.2791606187820435,
        2.0455162525177,
        1.1139235496520996,
        1.197172999382019,
        1.2585550546646118,
        1.048185110092163,
        1.453676462173462,
        1.1737723350524902,
        1.1393661499023438,
        0.8395656943321228,
        0.9971707463264465,
        1.09165620803833,
        1.075544834136963,
        0.8387690782546997,
        1.0903915166854858,
        1.1085190773010254,
        0.7788308262825012,
        0.9102457761764526,
        1.1563373804092407,
        0.9783982038497925,
        0.9721969962120056,
        0.8620553016662598,
        0.738858163356781,
        0.9023991227149963,
        1.0718653202056885,
        0.974481463432312,
        0.6327081918716431,
        1.079856038093567
    ],
    "val_loss": [
        1.5782486200332642,
        2.4385430812835693,
        1.5599957704544067,
        1.7748520374298096,
        1.7226158380508423,
        1.463789701461792,
        1.6854658126831055,
        2.005751132965088,
        1.737972617149353,
        1.5517356395721436,
        1.9109400510787964,
        1.9585809707641602,
        1.707342505455017,
        1.7367998361587524,
        1.8252228498458862,
        1.7985787391662598,
        1.842637300491333,
        1.820589542388916,
        1.8626176118850708,
        2.0657732486724854,
        2.1916799545288086,
        2.155923366546631,
        2.1740753650665283,
        2.295952320098877,
        2.3586981296539307,
        2.4814372062683105,
        2.512955904006958,
        2.452836036682129,
        2.4285366535186768,
        2.4641873836517334,
        2.4840099811553955,
        2.5001113414764404,
        2.5169970989227295,
        2.5134756565093994,
        2.4968667030334473,
        2.475233793258667
    ],
    "train_accuracy": [
        0.1875,
        0.25,
        0.5625,
        0.375,
        0.4375,
        0.3125,
        0.625,
        0.375,
        0.3125,
        0.5,
        0.5,
        0.5,
        0.625,
        0.3125,
        0.5625,
        0.5625,
        0.625,
        0.5625,
        0.375,
        0.4375,
        0.6875,
        0.5,
        0.4375,
        0.75,
        0.4375,
        0.4375,
        0.5625,
        0.625,
        0.6875,
        0.625,
        0.5625,
        0.4375,
        0.5,
        0.75,
        0.5625
    ],
    "val_accuracy": [
        0.3125,
        0.25,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.125,
        0.1875,
        0.375,
        0.375,
        0.25,
        0.125,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.4375,
        0.25,
        0.1875,
        0.25,
        0.1875,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125
    ],
    "epoch_times": [
        1.2077348232269287,
        1.2065281867980957,
        1.208028793334961,
        1.208587408065796,
        1.2130322456359863,
        1.210204839706421,
        1.211075782775879,
        1.2111506462097168,
        1.2124392986297607,
        1.211836338043213,
        1.2126619815826416,
        1.2098388671875,
        1.209836721420288,
        1.2106373310089111,
        1.211566686630249,
        1.2136282920837402,
        1.2127583026885986,
        1.2130177021026611,
        1.2102196216583252,
        1.2113804817199707,
        1.213796854019165,
        1.212752103805542,
        1.212824821472168,
        1.2146766185760498,
        1.2144248485565186,
        1.212418794631958,
        1.212522029876709,
        1.2142672538757324,
        1.213287591934204,
        1.214674949645996,
        1.2146642208099365,
        1.2142586708068848,
        1.213782787322998,
        1.2128474712371826,
        1.2114980220794678
    ]
}