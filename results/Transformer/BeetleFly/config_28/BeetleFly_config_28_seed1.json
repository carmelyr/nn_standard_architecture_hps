{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.164840434563,
        "ff_dim": 390,
        "hidden_units": 391,
        "learning_rate": 1.42123626e-05,
        "num_heads": 4,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 2.90315205e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        1.5933908224105835,
        1.4747557640075684,
        1.2288398742675781,
        1.1811274290084839,
        0.9715617895126343,
        0.9052948355674744,
        0.8838986158370972,
        0.8638112545013428,
        0.8270548582077026,
        0.6591131687164307,
        0.793022632598877,
        0.6896709203720093,
        0.9614434838294983,
        0.711098849773407,
        0.7483184933662415,
        1.094558596611023,
        0.9124026298522949,
        0.8039975762367249,
        0.7266897559165955,
        0.8424085378646851,
        0.8206408023834229,
        0.7483471632003784,
        0.6983265280723572,
        0.7800721526145935,
        0.7931052446365356,
        0.7066333293914795,
        0.7932683229446411,
        0.8746863007545471,
        0.9252592325210571,
        0.6911444664001465,
        0.9168540239334106,
        0.7961447834968567,
        0.7622196674346924,
        0.7759301066398621
    ],
    "val_loss": [
        1.3850398063659668,
        1.1289845705032349,
        0.9075236320495605,
        0.7432174682617188,
        0.6624119281768799,
        0.6876604557037354,
        0.8219583630561829,
        1.0201882123947144,
        1.2444965839385986,
        1.443860650062561,
        1.5834276676177979,
        1.633538007736206,
        1.6541311740875244,
        1.661280870437622,
        1.649226427078247,
        1.6174472570419312,
        1.5728414058685303,
        1.5454745292663574,
        1.5149399042129517,
        1.480140209197998,
        1.4444187879562378,
        1.4139552116394043,
        1.384348750114441,
        1.3725512027740479,
        1.3595359325408936,
        1.346587061882019,
        1.3349189758300781,
        1.3223540782928467,
        1.3097777366638184,
        1.3036439418792725,
        1.298231840133667,
        1.292136549949646,
        1.2856495380401611,
        1.2794991731643677,
        1.273913860321045
    ],
    "train_accuracy": [
        0.46875,
        0.46875,
        0.46875,
        0.5,
        0.46875,
        0.5625,
        0.375,
        0.46875,
        0.5625,
        0.71875,
        0.5,
        0.59375,
        0.5,
        0.5625,
        0.59375,
        0.40625,
        0.4375,
        0.46875,
        0.6875,
        0.59375,
        0.4375,
        0.5,
        0.5,
        0.53125,
        0.53125,
        0.59375,
        0.5,
        0.40625,
        0.5,
        0.625,
        0.4375,
        0.53125,
        0.59375,
        0.5625
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.3029308319091797,
        0.15169191360473633,
        0.1505889892578125,
        0.15099811553955078,
        0.150834321975708,
        0.15027427673339844,
        0.15150856971740723,
        0.1512300968170166,
        0.15317463874816895,
        0.15082979202270508,
        0.15201878547668457,
        0.151292085647583,
        0.15183377265930176,
        0.152191162109375,
        0.15100622177124023,
        0.15292000770568848,
        0.15160083770751953,
        0.1552293300628662,
        0.1523897647857666,
        0.1529223918914795,
        0.1514444351196289,
        0.15191888809204102,
        0.15286779403686523,
        0.15318036079406738,
        0.1528034210205078,
        0.15438270568847656,
        0.1539762020111084,
        0.15282392501831055,
        0.15259408950805664,
        0.1529524326324463,
        0.15197396278381348,
        0.1526954174041748,
        0.15085053443908691,
        0.1532881259918213
    ]
}