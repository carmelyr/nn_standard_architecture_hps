{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2830115084066,
        "ff_dim": 880,
        "hidden_units": 148,
        "learning_rate": 4.31873011e-05,
        "num_heads": 4,
        "num_layers": 3,
        "pooling": "mean",
        "weight_decay": 9.47975004e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 36,
    "train_loss": [
        1.8679139614105225,
        1.6570024490356445,
        1.9368584156036377,
        1.3198678493499756,
        1.7007864713668823,
        1.5611937046051025,
        1.6424520015716553,
        1.565990924835205,
        1.9590686559677124,
        1.3103933334350586,
        1.1949042081832886,
        1.5269676446914673,
        1.301689624786377,
        1.35861337184906,
        1.2687513828277588,
        1.3821715116500854,
        1.505074381828308,
        1.2403078079223633,
        1.3887485265731812,
        1.4905422925949097,
        1.3927760124206543,
        1.5825005769729614,
        1.5716681480407715,
        1.465408205986023,
        1.0863182544708252,
        1.4297369718551636,
        1.4695802927017212,
        1.0562821626663208,
        1.2505959272384644,
        1.486921787261963,
        1.5054038763046265,
        1.420198678970337,
        1.4778985977172852,
        1.0719554424285889,
        1.3529844284057617,
        1.3350406885147095
    ],
    "val_loss": [
        1.7970685958862305,
        1.4973468780517578,
        1.4848179817199707,
        1.4928501844406128,
        1.5247366428375244,
        1.4687553644180298,
        1.418508768081665,
        1.4540215730667114,
        1.5722559690475464,
        1.579757571220398,
        1.5564621686935425,
        1.557136058807373,
        1.5283405780792236,
        1.5102050304412842,
        1.533682942390442,
        1.549527645111084,
        1.5487771034240723,
        1.5534350872039795,
        1.5570918321609497,
        1.5560585260391235,
        1.5348247289657593,
        1.517343521118164,
        1.5174894332885742,
        1.5131083726882935,
        1.5178476572036743,
        1.5142372846603394,
        1.5132603645324707,
        1.5188188552856445,
        1.5234031677246094,
        1.5330681800842285,
        1.5485618114471436,
        1.550629734992981,
        1.551356315612793,
        1.5479964017868042,
        1.5428069829940796,
        1.5393542051315308,
        1.5373867750167847
    ],
    "train_accuracy": [
        0.25,
        0.25,
        0.0,
        0.4375,
        0.25,
        0.375,
        0.25,
        0.25,
        0.125,
        0.4375,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.4375,
        0.25,
        0.375,
        0.4375,
        0.4375,
        0.3125,
        0.4375,
        0.3125,
        0.3125,
        0.375,
        0.4375,
        0.1875,
        0.3125,
        0.5,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.25,
        0.375,
        0.4375,
        0.375
    ],
    "val_accuracy": [
        0.3125,
        0.3125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.3125,
        0.375,
        0.1875,
        0.1875,
        0.125,
        0.125,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        0.6068680286407471,
        0.5688002109527588,
        0.5658578872680664,
        0.5691609382629395,
        0.564241886138916,
        0.5667667388916016,
        0.5664088726043701,
        0.5672614574432373,
        0.5662548542022705,
        0.5636861324310303,
        0.5700924396514893,
        0.567396879196167,
        0.5677804946899414,
        0.567624568939209,
        0.564171552658081,
        0.5660784244537354,
        0.567645788192749,
        0.5669753551483154,
        0.5646257400512695,
        0.5669658184051514,
        0.5666558742523193,
        0.5664453506469727,
        0.5659534931182861,
        0.5661172866821289,
        0.5652692317962646,
        0.5658338069915771,
        0.5671143531799316,
        0.5661468505859375,
        0.5669963359832764,
        0.5661835670471191,
        0.568535566329956,
        0.5664167404174805,
        0.56703782081604,
        0.567021369934082,
        0.5672304630279541,
        0.5663406848907471
    ]
}