{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1683732048574,
        "ff_dim": 350,
        "hidden_units": 261,
        "learning_rate": 0.0001622411327,
        "num_heads": 2,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 6.63173062e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 35,
    "train_loss": [
        2.172781467437744,
        1.8071576356887817,
        1.8780186176300049,
        1.5118178129196167,
        1.4419662952423096,
        1.5796804428100586,
        1.8615696430206299,
        1.5283682346343994,
        1.6076399087905884,
        1.3391611576080322,
        1.317746877670288,
        1.4671329259872437,
        0.9868746399879456,
        1.4488500356674194,
        1.6129220724105835,
        1.4266672134399414,
        1.2397390604019165,
        1.6317670345306396,
        1.3862427473068237,
        1.0632704496383667,
        1.2207005023956299,
        1.308231234550476,
        1.2382421493530273,
        1.3336448669433594,
        0.860319972038269,
        1.488590955734253,
        1.3378362655639648,
        1.3382995128631592,
        1.7671915292739868,
        1.1638814210891724,
        1.1876747608184814,
        1.5563037395477295,
        1.362990140914917,
        1.2892377376556396,
        1.280531883239746
    ],
    "val_loss": [
        1.7337950468063354,
        2.3748059272766113,
        3.1452629566192627,
        2.704495668411255,
        1.7780593633651733,
        1.491083025932312,
        1.5852516889572144,
        1.698581337928772,
        1.8185337781906128,
        1.8214677572250366,
        1.710373878479004,
        1.8130136728286743,
        1.8167115449905396,
        1.7541955709457397,
        1.725685477256775,
        1.6952515840530396,
        1.6530064344406128,
        1.650086522102356,
        1.6335139274597168,
        1.6372960805892944,
        1.6435842514038086,
        1.6563905477523804,
        1.6437989473342896,
        1.638657569885254,
        1.6295055150985718,
        1.6216317415237427,
        1.6222673654556274,
        1.6287493705749512,
        1.6290106773376465,
        1.6328219175338745,
        1.6343398094177246,
        1.6348587274551392,
        1.6351432800292969,
        1.6315189599990845,
        1.6255110502243042,
        1.6199263334274292
    ],
    "train_accuracy": [
        0.25,
        0.3125,
        0.3125,
        0.25,
        0.25,
        0.4375,
        0.375,
        0.4375,
        0.3125,
        0.5,
        0.4375,
        0.375,
        0.5625,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.3125,
        0.5,
        0.5625,
        0.625,
        0.625,
        0.375,
        0.5625,
        0.75,
        0.4375,
        0.5,
        0.5,
        0.1875,
        0.5625,
        0.625,
        0.1875,
        0.375,
        0.5,
        0.375
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.25,
        0.25,
        0.4166666567325592,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592
    ],
    "epoch_times": [
        0.21203160285949707,
        0.16974449157714844,
        0.16723155975341797,
        0.16783928871154785,
        0.16787314414978027,
        0.16773009300231934,
        0.17009997367858887,
        0.16787314414978027,
        0.1678314208984375,
        0.1687939167022705,
        0.16795825958251953,
        0.16845989227294922,
        0.16846489906311035,
        0.16823792457580566,
        0.16853117942810059,
        0.16834640502929688,
        0.1680293083190918,
        0.16881370544433594,
        0.16883325576782227,
        0.17026710510253906,
        0.16936779022216797,
        0.16837716102600098,
        0.16875457763671875,
        0.16852140426635742,
        0.1681075096130371,
        0.1690230369567871,
        0.16859912872314453,
        0.16835355758666992,
        0.16898083686828613,
        0.16818618774414062,
        0.17033624649047852,
        0.16887569427490234,
        0.16814541816711426,
        0.16865229606628418,
        0.16832804679870605
    ]
}