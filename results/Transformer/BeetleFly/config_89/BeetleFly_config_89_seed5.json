{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0589211467474,
        "ff_dim": 485,
        "hidden_units": 425,
        "learning_rate": 0.0004939244837,
        "num_heads": 8,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 4.39730861e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.8595008254051208,
        5.865301132202148,
        2.742016077041626,
        1.0667681694030762,
        0.6413687467575073,
        1.3729522228240967,
        1.2511334419250488,
        0.625058650970459,
        0.725229799747467,
        0.5983970761299133,
        0.6231474876403809,
        0.6320446729660034,
        0.5995736122131348,
        0.6002310514450073,
        0.6448912620544434,
        0.6102680563926697,
        0.5801447629928589,
        0.5485520362854004,
        0.6330942511558533,
        0.6223835945129395,
        0.5278917551040649,
        0.5198107361793518,
        0.5486083030700684,
        0.4977443218231201,
        0.4828360378742218,
        0.5211989283561707,
        0.5614266991615295,
        0.47597283124923706,
        0.5019018650054932,
        0.4840821921825409,
        0.5124308466911316,
        0.46900588274002075,
        0.5104582905769348,
        0.48015278577804565
    ],
    "val_loss": [
        0.7196226716041565,
        9.173770904541016,
        4.051313877105713,
        1.3234987258911133,
        0.7730140686035156,
        2.263662338256836,
        1.7749245166778564,
        0.8028507828712463,
        0.8408119678497314,
        0.9089040756225586,
        0.901751697063446,
        0.9710468053817749,
        0.9731228351593018,
        1.052196979522705,
        1.0573126077651978,
        1.1507433652877808,
        1.1458059549331665,
        1.1688296794891357,
        1.1978378295898438,
        1.1784430742263794,
        1.1329100131988525,
        1.1271723508834839,
        1.1702090501785278,
        1.184064507484436,
        1.1650962829589844,
        1.1501253843307495,
        1.1454875469207764,
        1.1583890914916992,
        1.1767364740371704,
        1.1961824893951416,
        1.2067294120788574,
        1.2164244651794434,
        1.230934977531433,
        1.2364362478256226,
        1.235681414604187
    ],
    "train_accuracy": [
        0.40625,
        0.53125,
        0.53125,
        0.46875,
        0.65625,
        0.53125,
        0.53125,
        0.625,
        0.53125,
        0.59375,
        0.625,
        0.65625,
        0.625,
        0.6875,
        0.625,
        0.5625,
        0.65625,
        0.75,
        0.59375,
        0.65625,
        0.75,
        0.75,
        0.71875,
        0.71875,
        0.78125,
        0.8125,
        0.75,
        0.8125,
        0.71875,
        0.78125,
        0.78125,
        0.78125,
        0.71875,
        0.75
    ],
    "val_accuracy": [
        0.5,
        0.375,
        0.375,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.16668367385864258,
        0.11893272399902344,
        0.11670589447021484,
        0.1171562671661377,
        0.11630606651306152,
        0.11735129356384277,
        0.11745119094848633,
        0.1178903579711914,
        0.11712813377380371,
        0.11706900596618652,
        0.11847257614135742,
        0.11823368072509766,
        0.11702299118041992,
        0.11870241165161133,
        0.11855435371398926,
        0.11711597442626953,
        0.11832523345947266,
        0.1177518367767334,
        0.11847782135009766,
        0.11727142333984375,
        0.11673355102539062,
        0.11740803718566895,
        0.11796975135803223,
        0.11799883842468262,
        0.11844635009765625,
        0.11902093887329102,
        0.11821579933166504,
        0.11798763275146484,
        0.11642622947692871,
        0.11659121513366699,
        0.11690115928649902,
        0.11804652214050293,
        0.11659646034240723,
        0.1162407398223877
    ]
}