{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0658205096112,
        "ff_dim": 762,
        "hidden_units": 425,
        "learning_rate": 2.34082976e-05,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 8.25118913e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.9570645093917847,
        1.2898645401000977,
        1.2702425718307495,
        0.7503998279571533,
        0.822311282157898,
        0.9176099896430969,
        0.7734621167182922,
        0.6624851226806641,
        0.7392207384109497,
        0.681201696395874,
        0.7028326988220215,
        0.6294798851013184,
        0.6119517683982849,
        0.5994007587432861,
        0.7079846262931824,
        0.6014478802680969,
        0.5924350619316101,
        0.7450973987579346,
        0.6586740016937256,
        0.6405926942825317,
        0.6537837982177734,
        0.691158652305603,
        0.6097193360328674,
        0.7043237090110779,
        0.5468323230743408,
        0.5508776903152466,
        0.6624557375907898,
        0.5863462686538696,
        0.5863869786262512,
        0.5659984946250916,
        0.5885997414588928
    ],
    "val_loss": [
        1.0277577638626099,
        0.3548368811607361,
        0.564174234867096,
        0.8017177581787109,
        1.4050941467285156,
        1.607276439666748,
        1.4773352146148682,
        1.2784308195114136,
        1.1909369230270386,
        1.1391278505325317,
        1.1052361726760864,
        1.0843183994293213,
        1.086051106452942,
        1.0822632312774658,
        1.0835893154144287,
        1.0832188129425049,
        1.0877357721328735,
        1.1067183017730713,
        1.1363859176635742,
        1.168594241142273,
        1.1863354444503784,
        1.2053539752960205,
        1.222152829170227,
        1.2393044233322144,
        1.2569448947906494,
        1.2762571573257446,
        1.2860815525054932,
        1.2968980073928833,
        1.3060847520828247,
        1.313604712486267,
        1.3211501836776733,
        1.326029658317566
    ],
    "train_accuracy": [
        0.53125,
        0.40625,
        0.40625,
        0.5,
        0.625,
        0.59375,
        0.59375,
        0.625,
        0.46875,
        0.46875,
        0.53125,
        0.71875,
        0.65625,
        0.6875,
        0.59375,
        0.6875,
        0.65625,
        0.53125,
        0.5625,
        0.59375,
        0.5,
        0.5,
        0.75,
        0.65625,
        0.8125,
        0.71875,
        0.5,
        0.65625,
        0.71875,
        0.6875,
        0.71875
    ],
    "val_accuracy": [
        0.375,
        0.75,
        0.75,
        0.5,
        0.125,
        0.125,
        0.0,
        0.25,
        0.375,
        0.5,
        0.5,
        0.5,
        0.25,
        0.125,
        0.25,
        0.25,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.22031569480895996,
        0.21723723411560059,
        0.21381878852844238,
        0.21527576446533203,
        0.21533727645874023,
        0.2156229019165039,
        0.21564745903015137,
        0.21587681770324707,
        0.21665573120117188,
        0.21573662757873535,
        0.21649980545043945,
        0.2163848876953125,
        0.2158653736114502,
        0.2160038948059082,
        0.21675419807434082,
        0.2171192169189453,
        0.21782708168029785,
        0.21660852432250977,
        0.21655631065368652,
        0.21607375144958496,
        0.2154853343963623,
        0.2152237892150879,
        0.2160961627960205,
        0.21597909927368164,
        0.21647238731384277,
        0.21677231788635254,
        0.21568584442138672,
        0.2161571979522705,
        0.21624255180358887,
        0.21500682830810547,
        0.21636056900024414
    ]
}