{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2945044166213,
        "ff_dim": 361,
        "hidden_units": 447,
        "learning_rate": 0.0007998317165,
        "num_heads": 7,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 5.48204651e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.8450092673301697,
        4.993619918823242,
        2.2765848636627197,
        1.2417705059051514,
        0.7668101787567139,
        1.1565731763839722,
        0.9934825897216797,
        0.9224243760108948,
        0.8495886325836182,
        0.846890389919281,
        0.7472396492958069,
        0.6994145512580872,
        0.6306329965591431,
        0.809285044670105,
        0.6709747314453125,
        0.5868728756904602,
        0.7013596296310425,
        0.678254246711731,
        0.6616803407669067,
        0.6776323318481445,
        0.7836753129959106,
        0.6618635654449463,
        0.6057611703872681,
        0.6486946940422058,
        0.764999270439148,
        0.612450361251831,
        0.6629312634468079,
        0.7104147672653198,
        0.5873271226882935,
        0.7083674073219299,
        0.5947642922401428,
        0.6207605004310608,
        0.7500057816505432,
        0.6243728399276733,
        0.6682284474372864
    ],
    "val_loss": [
        0.7158011794090271,
        5.045684814453125,
        1.0652669668197632,
        4.360259532928467,
        2.94128680229187,
        0.7100619077682495,
        0.7120746970176697,
        1.781512975692749,
        1.8908491134643555,
        1.184381127357483,
        1.095196008682251,
        1.0695672035217285,
        1.2378796339035034,
        1.4548192024230957,
        1.4074928760528564,
        1.215255856513977,
        1.2786396741867065,
        1.2732126712799072,
        1.194484829902649,
        1.1340073347091675,
        1.1259756088256836,
        1.1599109172821045,
        1.1688051223754883,
        1.2209522724151611,
        1.2161147594451904,
        1.1915497779846191,
        1.2029370069503784,
        1.2080742120742798,
        1.2021143436431885,
        1.2237735986709595,
        1.2441052198410034,
        1.2755348682403564,
        1.2933733463287354,
        1.2942490577697754,
        1.2782971858978271,
        1.2583084106445312
    ],
    "train_accuracy": [
        0.5625,
        0.46875,
        0.46875,
        0.5625,
        0.5,
        0.40625,
        0.53125,
        0.46875,
        0.5,
        0.46875,
        0.5,
        0.59375,
        0.59375,
        0.4375,
        0.65625,
        0.65625,
        0.53125,
        0.53125,
        0.59375,
        0.59375,
        0.5625,
        0.625,
        0.65625,
        0.65625,
        0.46875,
        0.59375,
        0.59375,
        0.59375,
        0.625,
        0.53125,
        0.65625,
        0.71875,
        0.53125,
        0.65625,
        0.53125
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.375,
        0.375,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.16803932189941406,
        0.16587495803833008,
        0.16451525688171387,
        0.16752171516418457,
        0.16499924659729004,
        0.16495227813720703,
        0.16856908798217773,
        0.16603469848632812,
        0.1656193733215332,
        0.1689620018005371,
        0.1658916473388672,
        0.16460800170898438,
        0.16536235809326172,
        0.16576719284057617,
        0.1667799949645996,
        0.16640949249267578,
        0.16530370712280273,
        0.16552090644836426,
        0.16630887985229492,
        0.16615796089172363,
        0.1657106876373291,
        0.165069580078125,
        0.16556334495544434,
        0.16585612297058105,
        0.16607189178466797,
        0.1656324863433838,
        0.16489744186401367,
        0.16549134254455566,
        0.1653766632080078,
        0.1654222011566162,
        0.16600418090820312,
        0.1650547981262207,
        0.16528534889221191,
        0.16614699363708496,
        0.16556453704833984
    ]
}