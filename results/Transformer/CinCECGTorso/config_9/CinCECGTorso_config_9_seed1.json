{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0137457461769,
        "ff_dim": 839,
        "hidden_units": 476,
        "learning_rate": 2.32106058e-05,
        "num_heads": 2,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 2.58271673e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        1.275829792022705,
        1.3419313430786133,
        1.0872962474822998,
        1.1863313913345337,
        1.1111756563186646,
        1.0465502738952637,
        1.13754141330719,
        0.9170619249343872,
        0.9472622871398926,
        0.9844260215759277,
        0.7519464492797852,
        0.697439432144165,
        0.7068386673927307,
        0.7670693397521973,
        0.5346344709396362,
        0.7458897233009338,
        0.5112425088882446,
        0.7249518632888794,
        0.5432514548301697,
        0.6213818788528442,
        0.6261681318283081,
        0.6112514734268188,
        0.5933550596237183,
        0.5729778409004211,
        0.5310912728309631,
        0.40565016865730286,
        0.46049821376800537,
        0.5813348293304443,
        0.5773741602897644,
        0.5307194590568542,
        0.4978258013725281,
        0.4985730051994324,
        0.42768263816833496,
        0.3862529397010803,
        0.5701313018798828
    ],
    "val_loss": [
        1.481596827507019,
        1.5577099323272705,
        1.213867425918579,
        1.3156110048294067,
        1.341642141342163,
        1.1899833679199219,
        1.3019137382507324,
        1.4317749738693237,
        1.2683091163635254,
        1.2351962327957153,
        1.3073309659957886,
        1.348211407661438,
        1.358667254447937,
        1.3880006074905396,
        1.3284912109375,
        1.372896432876587,
        1.4167240858078003,
        1.4668315649032593,
        1.4412908554077148,
        1.4086222648620605,
        1.4274163246154785,
        1.3924274444580078,
        1.4412648677825928,
        1.4755687713623047,
        1.4771143198013306,
        1.4829280376434326,
        1.488306999206543,
        1.4533494710922241,
        1.4508435726165771,
        1.4591546058654785,
        1.4689757823944092,
        1.4797247648239136,
        1.493604063987732,
        1.5043320655822754,
        1.501605749130249,
        1.4979393482208252
    ],
    "train_accuracy": [
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.6875,
        0.4375,
        0.625,
        0.5,
        0.625,
        0.75,
        0.8125,
        0.75,
        0.75,
        0.875,
        0.6875,
        0.875,
        0.8125,
        0.9375,
        0.8125,
        0.875,
        0.75,
        0.8125,
        0.9375,
        0.875,
        0.875,
        0.9375,
        0.875,
        0.8125,
        0.875,
        0.875,
        0.9375,
        1.0,
        1.0,
        0.8125
    ],
    "val_accuracy": [
        0.3125,
        0.3125,
        0.5625,
        0.375,
        0.25,
        0.5,
        0.375,
        0.1875,
        0.5,
        0.3125,
        0.375,
        0.4375,
        0.25,
        0.3125,
        0.5,
        0.4375,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        2.4552125930786133,
        2.4580140113830566,
        2.463628053665161,
        2.4615190029144287,
        2.464188575744629,
        2.463503122329712,
        2.463871479034424,
        2.4654855728149414,
        2.464909791946411,
        2.4624409675598145,
        2.4604969024658203,
        2.461033821105957,
        2.460282802581787,
        2.4606354236602783,
        2.4589433670043945,
        2.460768938064575,
        2.4612770080566406,
        2.461245059967041,
        2.46311616897583,
        2.460221767425537,
        2.4606781005859375,
        2.460609197616577,
        2.458064556121826,
        2.4609458446502686,
        2.461988925933838,
        2.4596598148345947,
        2.4593658447265625,
        2.4599416255950928,
        2.4611129760742188,
        2.4584481716156006,
        2.4581806659698486,
        2.460139274597168,
        2.459690570831299,
        2.4609501361846924,
        2.460134744644165
    ]
}