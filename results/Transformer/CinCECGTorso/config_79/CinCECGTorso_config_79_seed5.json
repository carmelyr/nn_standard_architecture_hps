{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1642170252408,
        "ff_dim": 576,
        "hidden_units": 164,
        "learning_rate": 8.31797856e-05,
        "num_heads": 4,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 1.81819156e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        2.0571959018707275,
        1.6454087495803833,
        1.3227542638778687,
        1.5144436359405518,
        1.673890233039856,
        1.492300271987915,
        1.4969083070755005,
        1.329822301864624,
        1.3121299743652344,
        1.3044015169143677,
        1.513965368270874,
        1.373626947402954,
        1.5126073360443115,
        1.3236193656921387,
        1.2781848907470703,
        1.434515357017517,
        1.2148449420928955,
        1.333503246307373,
        1.1568717956542969,
        1.4154934883117676,
        1.3710579872131348,
        1.6545202732086182,
        1.6349455118179321,
        1.3213446140289307,
        1.233312726020813,
        1.227012038230896,
        1.419486403465271,
        1.3147344589233398,
        0.990379810333252,
        1.3445191383361816,
        1.3470381498336792,
        1.396125078201294,
        1.2737877368927002
    ],
    "val_loss": [
        3.191394805908203,
        2.000957489013672,
        1.5481261014938354,
        1.5316106081008911,
        1.5581302642822266,
        1.575899600982666,
        1.6107909679412842,
        1.6628316640853882,
        1.6397801637649536,
        1.6193325519561768,
        1.6067030429840088,
        1.6019505262374878,
        1.6111661195755005,
        1.6087311506271362,
        1.5827661752700806,
        1.5558247566223145,
        1.5560938119888306,
        1.5563287734985352,
        1.5573530197143555,
        1.5576889514923096,
        1.565474271774292,
        1.5708171129226685,
        1.5737491846084595,
        1.576648473739624,
        1.5706876516342163,
        1.5716737508773804,
        1.5695440769195557,
        1.5687172412872314,
        1.5663542747497559,
        1.5629985332489014,
        1.5612618923187256,
        1.558618187904358,
        1.5582618713378906,
        1.5583655834197998
    ],
    "train_accuracy": [
        0.1875,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.4375,
        0.5,
        0.5,
        0.3125,
        0.3125,
        0.3125,
        0.5,
        0.375,
        0.125,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.25,
        0.3125,
        0.375,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.625,
        0.3125,
        0.4375,
        0.3125,
        0.5
    ],
    "val_accuracy": [
        0.125,
        0.125,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.3125,
        0.375,
        0.25,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375
    ],
    "epoch_times": [
        0.41998958587646484,
        0.32834839820861816,
        0.3286600112915039,
        0.32881641387939453,
        0.32723569869995117,
        0.3289012908935547,
        0.3305673599243164,
        0.3285536766052246,
        0.3285374641418457,
        0.3277699947357178,
        0.32677602767944336,
        0.32808899879455566,
        0.3269963264465332,
        0.32736635208129883,
        0.32756996154785156,
        0.32647132873535156,
        0.3278231620788574,
        0.3280766010284424,
        0.3267371654510498,
        0.32622647285461426,
        0.3263261318206787,
        0.32659482955932617,
        0.3289790153503418,
        0.3303389549255371,
        0.32656121253967285,
        0.3256058692932129,
        0.3271651268005371,
        0.3271064758300781,
        0.3252432346343994,
        0.32828283309936523,
        0.32687926292419434,
        0.32840871810913086,
        0.3264141082763672
    ]
}