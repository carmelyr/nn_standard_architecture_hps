{
    "hyperparameters": {
        "activation": "tanh",
        "dropout_rate": 0.43870914072,
        "hidden_units": 39,
        "learning_rate": 0.01492945994,
        "num_layers": 1,
        "weight_decay": 0.007663351325
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 36,
        "val_size": 9,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.8061244487762451,
        0.4038736820220947,
        0.34575796127319336,
        0.27567899227142334,
        0.2534422278404236,
        0.17190614342689514,
        0.13706153631210327,
        0.11492690443992615,
        0.10772845894098282,
        0.05022789537906647,
        0.06868939101696014,
        0.04902574419975281,
        0.09790264070034027,
        0.0478019081056118,
        0.07104646414518356,
        0.04471559077501297,
        0.04137246683239937,
        0.0459897518157959,
        0.06009283289313316,
        0.016997702419757843,
        0.03502834588289261,
        0.05532579869031906,
        0.01227127481251955,
        0.056924208998680115,
        0.02370222471654415,
        0.027085309848189354,
        0.18414756655693054,
        0.03571854531764984,
        0.034744925796985626,
        0.10156987607479095,
        0.08214043825864792
    ],
    "val_loss": [
        0.8734071254730225,
        0.3420327603816986,
        0.4569893479347229,
        0.5509436130523682,
        0.5495314002037048,
        0.5507590770721436,
        0.5424286127090454,
        0.54868483543396,
        0.5346925258636475,
        0.5526196360588074,
        0.579230546951294,
        0.6222431063652039,
        0.6816543936729431,
        0.7035343050956726,
        0.7250055074691772,
        0.757150411605835,
        0.79312664270401,
        0.8363012075424194,
        0.8712282776832581,
        0.8760746717453003,
        0.8917731046676636,
        0.9372042417526245,
        0.9712855815887451,
        0.9705648422241211,
        0.9432039260864258,
        0.9378352761268616,
        0.9097729921340942,
        0.9450827836990356,
        0.9026411771774292,
        0.8782622814178467,
        0.8423736095428467,
        0.865370512008667
    ],
    "train_accuracy": [
        0.5555555820465088,
        0.8611111044883728,
        0.8333333134651184,
        0.8888888955116272,
        0.9166666865348816,
        0.9444444179534912,
        0.9722222089767456,
        0.9722222089767456,
        0.9444444179534912,
        1.0,
        1.0,
        1.0,
        0.9444444179534912,
        1.0,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        1.0,
        1.0,
        1.0,
        0.9722222089767456,
        1.0,
        0.9722222089767456,
        1.0,
        1.0,
        0.9166666865348816,
        1.0,
        1.0,
        0.9444444179534912,
        0.9722222089767456
    ],
    "val_accuracy": [
        0.1111111119389534,
        0.8888888955116272,
        0.8888888955116272,
        0.7777777910232544,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272,
        0.8888888955116272
    ],
    "epoch_times": [
        0.012242794036865234,
        0.01166081428527832,
        0.011672735214233398,
        0.01166224479675293,
        0.011697769165039062,
        0.011706352233886719,
        0.011631488800048828,
        0.011711359024047852,
        0.01169276237487793,
        0.011660099029541016,
        0.011656999588012695,
        0.011587381362915039,
        0.01164865493774414,
        0.011809825897216797,
        0.011715173721313477,
        0.011686086654663086,
        0.011566400527954102,
        0.01163172721862793,
        0.012237787246704102,
        0.011670112609863281,
        0.01188349723815918,
        0.012146472930908203,
        0.011717081069946289,
        0.011827468872070312,
        0.01192927360534668,
        0.012374162673950195,
        0.012156486511230469,
        0.01206827163696289,
        0.011610984802246094,
        0.011618614196777344,
        0.011634349822998047
    ]
}