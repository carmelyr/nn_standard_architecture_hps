{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.3605328622166,
        "kernel_size": 5,
        "learning_rate": 0.0059486585564,
        "num_filters": 168,
        "num_layers": 4,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        0.7039118409156799,
        0.7571650147438049,
        0.42587050795555115,
        0.5149960517883301,
        0.2293235957622528,
        0.17780464887619019,
        0.08722207695245743,
        0.08561259508132935,
        0.06466731429100037,
        0.07140541076660156,
        0.053902436047792435,
        0.04056786373257637,
        0.044242892414331436,
        0.038343645632267,
        0.007084060925990343,
        0.015464697033166885,
        0.019495029002428055,
        0.07709556818008423,
        0.008206350728869438,
        0.02100430056452751,
        0.005961095914244652,
        0.010127823799848557,
        0.010663463734090328,
        0.024174358695745468,
        0.023891659453511238,
        0.02537182904779911,
        0.0013044551014900208,
        0.030869100242853165,
        0.0050282832235097885,
        0.007932807318866253,
        0.0008400100632570684,
        0.05273953452706337,
        0.004915566183626652,
        0.017959585413336754,
        0.007023368962109089,
        0.009032739326357841
    ],
    "val_loss": [
        0.682564377784729,
        0.6842220425605774,
        0.686334490776062,
        0.6922593116760254,
        0.6789771318435669,
        0.663081169128418,
        0.6549457311630249,
        0.6941176056861877,
        0.7983683347702026,
        0.9067507982254028,
        0.9956691265106201,
        1.0661263465881348,
        1.1209063529968262,
        1.159426212310791,
        1.214597463607788,
        1.2450077533721924,
        1.291545033454895,
        1.3826137781143188,
        1.4854464530944824,
        1.595046877861023,
        1.681916356086731,
        1.7743204832077026,
        1.8705710172653198,
        1.941666841506958,
        2.0140938758850098,
        2.1393866539001465,
        2.2089200019836426,
        2.2821497917175293,
        2.374577522277832,
        2.5047709941864014,
        2.609127998352051,
        2.7359070777893066,
        2.550661325454712,
        2.434410572052002,
        2.3793764114379883,
        2.3726415634155273,
        2.358292579650879
    ],
    "train_accuracy": [
        0.59375,
        0.5625,
        0.84375,
        0.75,
        0.90625,
        0.90625,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.75,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.5,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        59.29008889198303,
        0.08376622200012207,
        0.02464890480041504,
        0.02541804313659668,
        0.025231122970581055,
        0.02314305305480957,
        0.023874759674072266,
        0.023929119110107422,
        0.023913145065307617,
        0.024051904678344727,
        0.024653196334838867,
        0.02517414093017578,
        0.07513880729675293,
        0.02447795867919922,
        0.02308511734008789,
        0.02369999885559082,
        0.023508787155151367,
        0.02622532844543457,
        0.023836851119995117,
        0.02363300323486328,
        0.02308487892150879,
        0.02276134490966797,
        0.024934053421020508,
        0.023914813995361328,
        0.0236208438873291,
        0.023422956466674805,
        0.023396015167236328,
        0.022706031799316406,
        0.023221969604492188,
        0.022762060165405273,
        0.02404308319091797,
        0.023413419723510742,
        0.023326873779296875,
        0.023725032806396484,
        0.023707151412963867,
        0.02356123924255371
    ]
}