{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0589211467474,
        "ff_dim": 485,
        "hidden_units": 425,
        "learning_rate": 0.0004939244837,
        "num_heads": 8,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 4.39730861e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        1.257400631904602,
        6.236636638641357,
        3.326704740524292,
        0.7658054232597351,
        0.7320948243141174,
        1.0362766981124878,
        0.8037052154541016,
        1.0385292768478394,
        0.9468506574630737,
        0.708471417427063,
        0.6380422711372375,
        0.6491016745567322,
        0.6734200716018677,
        0.6684999465942383,
        0.6767829656600952,
        0.6011708974838257,
        0.7319852709770203,
        0.5845499634742737,
        0.6530173420906067,
        0.6312919855117798,
        0.5801690220832825,
        0.5789803862571716,
        0.6328338980674744,
        0.6352269053459167,
        0.483638197183609,
        0.5772213935852051,
        0.5055670738220215,
        0.5496134161949158,
        0.5479516386985779,
        0.4970828592777252,
        0.48868462443351746,
        0.4783287048339844,
        0.5262179374694824,
        0.4607941508293152,
        0.496563196182251,
        0.4229881763458252
    ],
    "val_loss": [
        1.6806257963180542,
        5.102023124694824,
        2.4028356075286865,
        1.0277695655822754,
        1.3449821472167969,
        0.7280923128128052,
        0.6557883620262146,
        1.638443112373352,
        1.5257527828216553,
        0.75886070728302,
        0.6753777265548706,
        0.9010816216468811,
        0.7729182243347168,
        0.6750896573066711,
        0.6827746629714966,
        0.765495777130127,
        0.9161205291748047,
        0.8917398452758789,
        0.7458169460296631,
        0.738054096698761,
        0.7698899507522583,
        0.8338226675987244,
        0.8942214250564575,
        0.8772342801094055,
        0.8071133494377136,
        0.7931779623031616,
        0.7998198866844177,
        0.8197722434997559,
        0.8588048815727234,
        0.885597288608551,
        0.9046775102615356,
        0.8944048285484314,
        0.8786330223083496,
        0.8804794549942017,
        0.8920337557792664,
        0.9109668135643005,
        0.930456280708313
    ],
    "train_accuracy": [
        0.53125,
        0.46875,
        0.46875,
        0.46875,
        0.625,
        0.5,
        0.5,
        0.53125,
        0.53125,
        0.53125,
        0.53125,
        0.5,
        0.625,
        0.5625,
        0.5625,
        0.75,
        0.5,
        0.75,
        0.46875,
        0.65625,
        0.71875,
        0.71875,
        0.5625,
        0.65625,
        0.8125,
        0.59375,
        0.8125,
        0.71875,
        0.71875,
        0.84375,
        0.78125,
        0.8125,
        0.8125,
        0.9375,
        0.75,
        0.84375
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.375,
        0.375,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.75,
        0.375,
        0.375,
        0.75,
        0.75,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.125,
        0.125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.49674153327941895,
        0.5398128032684326,
        0.14149975776672363,
        0.14252376556396484,
        0.1441783905029297,
        0.14287424087524414,
        0.14256834983825684,
        0.14174485206604004,
        0.1422266960144043,
        0.14192986488342285,
        0.14409303665161133,
        0.14228439331054688,
        0.14192628860473633,
        0.1420130729675293,
        0.14272427558898926,
        0.1419506072998047,
        0.1420907974243164,
        0.14188456535339355,
        0.14322590827941895,
        0.14258170127868652,
        0.14273524284362793,
        0.1415119171142578,
        0.1412191390991211,
        0.14241862297058105,
        0.14152932167053223,
        0.14217710494995117,
        0.142805814743042,
        0.14187955856323242,
        0.14178037643432617,
        0.14318490028381348,
        0.14321565628051758,
        0.1394789218902588,
        0.1394343376159668,
        0.1414351463317871,
        0.1409916877746582,
        0.1405482292175293
    ]
}