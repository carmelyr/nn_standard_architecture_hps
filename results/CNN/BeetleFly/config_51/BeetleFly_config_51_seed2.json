{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.4920915744963,
        "kernel_size": 4,
        "learning_rate": 0.0037816397364,
        "num_filters": 180,
        "num_layers": 2,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.8598669767379761,
        0.42512401938438416,
        0.23693862557411194,
        0.09334171563386917,
        0.23676246404647827,
        0.24291306734085083,
        0.2427239567041397,
        0.09831336885690689,
        0.16688957810401917,
        0.07076190412044525,
        0.04050692543387413,
        0.02019396796822548,
        0.08817517757415771,
        0.02252883091568947,
        0.011444155126810074,
        0.007637251168489456,
        0.05294756963849068,
        0.012068447656929493,
        0.06869208812713623,
        0.02700796164572239,
        0.0709596574306488,
        0.07025089859962463,
        0.004440800752490759,
        0.04961462691426277,
        0.05538898706436157,
        0.05080043151974678,
        0.002258489839732647,
        0.10702141374349594,
        0.000543880567420274,
        0.006675866898149252,
        0.03065292164683342
    ],
    "val_loss": [
        0.7121994495391846,
        0.715375542640686,
        0.716072678565979,
        0.8952767252922058,
        1.1441302299499512,
        0.9113895893096924,
        1.3699853420257568,
        2.347229480743408,
        2.5995492935180664,
        2.3307087421417236,
        1.9740501642227173,
        1.7869081497192383,
        1.7261587381362915,
        1.8952596187591553,
        2.0933103561401367,
        2.273441791534424,
        2.4850099086761475,
        2.637031078338623,
        2.7627031803131104,
        2.623317003250122,
        2.3662500381469727,
        2.2528090476989746,
        2.2559287548065186,
        2.269956111907959,
        2.2947351932525635,
        2.2415378093719482,
        2.1543638706207275,
        2.154813766479492,
        2.278203248977661,
        2.4150350093841553,
        2.511213541030884,
        2.5277161598205566
    ],
    "train_accuracy": [
        0.34375,
        0.78125,
        0.875,
        1.0,
        0.90625,
        0.9375,
        0.96875,
        0.9375,
        0.9375,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        0.96875,
        1.0,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        0.96875
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.19562673568725586,
        0.047034263610839844,
        0.0732574462890625,
        0.024334430694580078,
        0.025752782821655273,
        0.06852579116821289,
        0.07570385932922363,
        0.02170395851135254,
        0.0556483268737793,
        0.05694293975830078,
        0.021570205688476562,
        0.0606691837310791,
        0.025238752365112305,
        0.048569440841674805,
        0.022893667221069336,
        0.022351980209350586,
        0.021779537200927734,
        0.02362227439880371,
        0.06600666046142578,
        0.021323680877685547,
        0.04477190971374512,
        0.020923376083374023,
        0.04695725440979004,
        0.021474123001098633,
        0.024053096771240234,
        0.06028103828430176,
        0.022006511688232422,
        0.02638864517211914,
        0.061631202697753906,
        0.06929898262023926,
        0.024483919143676758
    ]
}