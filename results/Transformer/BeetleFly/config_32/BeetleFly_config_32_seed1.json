{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0658205096112,
        "ff_dim": 762,
        "hidden_units": 425,
        "learning_rate": 2.34082976e-05,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 8.25118913e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.7268326282501221,
        1.0618237257003784,
        0.7803856730461121,
        0.7410757541656494,
        0.7331051826477051,
        0.6580424308776855,
        0.6618235111236572,
        0.6460552215576172,
        0.6284649968147278,
        0.5975249409675598,
        0.6510457992553711,
        0.587029755115509,
        0.6079865097999573,
        0.5712552666664124,
        0.5983112454414368,
        0.5648090839385986,
        0.5788938403129578,
        0.604503870010376,
        0.5556535720825195,
        0.6183856129646301,
        0.6273287534713745,
        0.5959135890007019,
        0.5473279356956482,
        0.5912831425666809,
        0.5086990594863892,
        0.5870409607887268,
        0.543646514415741,
        0.5837401151657104,
        0.5485163331031799,
        0.5509645938873291,
        0.5470684170722961,
        0.5358841419219971,
        0.5067037343978882,
        0.5711302757263184,
        0.5207716226577759
    ],
    "val_loss": [
        0.9162017107009888,
        0.8461913466453552,
        0.7241222262382507,
        0.7180456519126892,
        0.7286968231201172,
        0.6796957850456238,
        0.700867235660553,
        0.7606221437454224,
        0.8290404081344604,
        0.8500387072563171,
        0.746806800365448,
        0.6938552856445312,
        0.6878398656845093,
        0.688568115234375,
        0.6995594501495361,
        0.7019470930099487,
        0.6942239999771118,
        0.6949338912963867,
        0.6963018178939819,
        0.699131190776825,
        0.7030771970748901,
        0.7101505994796753,
        0.7180433869361877,
        0.7296490669250488,
        0.7340759634971619,
        0.7347211837768555,
        0.7299585342407227,
        0.7234336137771606,
        0.7183815836906433,
        0.7153398990631104,
        0.7148634791374207,
        0.7147087454795837,
        0.7147710919380188,
        0.7150142192840576,
        0.715441882610321,
        0.7163344025611877
    ],
    "train_accuracy": [
        0.5,
        0.5,
        0.59375,
        0.5625,
        0.5,
        0.59375,
        0.5625,
        0.71875,
        0.59375,
        0.625,
        0.59375,
        0.625,
        0.65625,
        0.65625,
        0.65625,
        0.71875,
        0.6875,
        0.71875,
        0.75,
        0.59375,
        0.6875,
        0.53125,
        0.625,
        0.625,
        0.75,
        0.625,
        0.71875,
        0.625,
        0.65625,
        0.625,
        0.75,
        0.65625,
        0.75,
        0.65625,
        0.78125
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.375,
        0.25,
        0.625,
        0.5,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.3335278034210205,
        0.21619272232055664,
        0.21738910675048828,
        0.21811532974243164,
        0.21744537353515625,
        0.21660256385803223,
        0.21732139587402344,
        0.21741747856140137,
        0.21680998802185059,
        0.21677708625793457,
        0.21793913841247559,
        0.21684050559997559,
        0.21917057037353516,
        0.21539616584777832,
        0.2152855396270752,
        0.22403931617736816,
        0.2170732021331787,
        0.2171790599822998,
        0.21600675582885742,
        0.2157750129699707,
        0.21727943420410156,
        0.2174215316772461,
        0.21562814712524414,
        0.21549081802368164,
        0.21486926078796387,
        0.22683405876159668,
        0.22709250450134277,
        0.2139449119567871,
        0.21564388275146484,
        0.2166910171508789,
        0.21718668937683105,
        0.217271089553833,
        0.21618103981018066,
        0.21727728843688965,
        0.21659255027770996
    ]
}