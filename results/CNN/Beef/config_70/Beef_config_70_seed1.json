{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3663849266307,
        "kernel_size": 3,
        "learning_rate": 0.0043888822554,
        "num_filters": 229,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 33,
    "train_loss": [
        1.8859463930130005,
        1.1100420951843262,
        0.921389102935791,
        0.8782033920288086,
        0.8340117335319519,
        0.8506727814674377,
        0.7171815037727356,
        0.7025039792060852,
        0.719153642654419,
        0.6711094379425049,
        0.6016192436218262,
        0.5282451510429382,
        0.5514456629753113,
        0.5138532519340515,
        0.4470338821411133,
        0.47978711128234863,
        0.5180472135543823,
        0.4879957437515259,
        0.5060357451438904,
        0.39760008454322815,
        0.38912081718444824,
        0.3880203068256378,
        0.43686795234680176,
        0.3063575029373169,
        0.40345486998558044,
        0.30948367714881897,
        0.274376779794693,
        0.26224976778030396,
        0.2923416197299957,
        0.2852669656276703,
        0.34678784012794495,
        0.26745662093162537,
        0.28479084372520447
    ],
    "val_loss": [
        1.6048564910888672,
        2.002187967300415,
        2.0431506633758545,
        1.8559269905090332,
        1.8569945096969604,
        1.9852358102798462,
        2.0729644298553467,
        2.209210157394409,
        2.315664291381836,
        2.155651807785034,
        1.9802590608596802,
        1.893536925315857,
        1.8890091180801392,
        1.9221683740615845,
        1.9746965169906616,
        2.0040972232818604,
        2.051365852355957,
        2.076169013977051,
        2.357692003250122,
        2.445582151412964,
        2.586784601211548,
        2.447307586669922,
        2.347663164138794,
        2.248732089996338,
        2.147095203399658,
        2.1041369438171387,
        2.192537307739258,
        2.432530164718628,
        2.590454339981079,
        2.637284994125366,
        2.5509700775146484,
        2.4787757396698,
        2.4362432956695557,
        2.462769031524658
    ],
    "train_accuracy": [
        0.2291666716337204,
        0.6041666865348816,
        0.6875,
        0.7291666865348816,
        0.7708333134651184,
        0.7083333134651184,
        0.6875,
        0.75,
        0.7083333134651184,
        0.75,
        0.7708333134651184,
        0.8541666865348816,
        0.8333333134651184,
        0.7916666865348816,
        0.8541666865348816,
        0.8541666865348816,
        0.7708333134651184,
        0.8125,
        0.8125,
        0.8958333134651184,
        0.875,
        0.8333333134651184,
        0.8541666865348816,
        0.9375,
        0.875,
        0.9375,
        0.9583333134651184,
        0.8958333134651184,
        0.875,
        0.9375,
        0.8541666865348816,
        0.9375,
        0.9166666865348816
    ],
    "val_accuracy": [
        0.25,
        0.25,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.25,
        0.3333333432674408,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408
    ],
    "epoch_times": [
        0.0928945541381836,
        0.055356502532958984,
        0.02676224708557129,
        0.024172306060791016,
        0.024709701538085938,
        0.024420976638793945,
        0.024029016494750977,
        0.02338266372680664,
        0.02368021011352539,
        0.022691965103149414,
        0.02330613136291504,
        0.022467851638793945,
        0.022632598876953125,
        0.024324893951416016,
        0.024222612380981445,
        0.025829792022705078,
        0.02434372901916504,
        0.023295879364013672,
        0.02579331398010254,
        0.024724960327148438,
        0.023822784423828125,
        0.024486064910888672,
        0.02474689483642578,
        0.025138378143310547,
        0.02417778968811035,
        0.028431177139282227,
        0.025809049606323242,
        0.027392864227294922,
        0.026568174362182617,
        0.027205944061279297,
        0.02651810646057129,
        0.026131868362426758,
        0.026485443115234375
    ]
}