{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1799906420434,
        "ff_dim": 840,
        "hidden_units": 273,
        "learning_rate": 1.09356413e-05,
        "num_heads": 6,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 2.88015742e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 36,
    "train_loss": [
        1.6374698877334595,
        1.487031102180481,
        1.1617377996444702,
        1.2407994270324707,
        1.7057139873504639,
        1.4397833347320557,
        1.563572883605957,
        1.2510008811950684,
        1.2464704513549805,
        1.6424310207366943,
        1.2599420547485352,
        1.4332813024520874,
        1.0456516742706299,
        1.3958390951156616,
        1.452873945236206,
        1.7072064876556396,
        1.3139617443084717,
        1.3564598560333252,
        1.505277395248413,
        1.5059828758239746,
        1.5610398054122925,
        1.6162526607513428,
        1.2291853427886963,
        1.4489562511444092,
        1.0533944368362427,
        1.3540607690811157,
        1.5829274654388428,
        1.3690404891967773,
        1.307613730430603,
        1.1544995307922363,
        1.5707759857177734,
        1.3622509241104126,
        1.3134924173355103,
        1.1915266513824463,
        1.510408878326416,
        1.2423992156982422
    ],
    "val_loss": [
        2.0929548740386963,
        1.5642297267913818,
        1.6166658401489258,
        1.7589141130447388,
        1.5856648683547974,
        1.4221127033233643,
        1.355903148651123,
        1.4188312292099,
        1.4516617059707642,
        1.497470736503601,
        1.455127477645874,
        1.4773021936416626,
        1.4858851432800293,
        1.447853922843933,
        1.4336590766906738,
        1.4144916534423828,
        1.3893632888793945,
        1.3763937950134277,
        1.3872380256652832,
        1.4022730588912964,
        1.4230339527130127,
        1.4251271486282349,
        1.4177414178848267,
        1.4148647785186768,
        1.4083369970321655,
        1.4135648012161255,
        1.418680191040039,
        1.4250235557556152,
        1.4270507097244263,
        1.427828311920166,
        1.433040738105774,
        1.43508780002594,
        1.4318828582763672,
        1.4327155351638794,
        1.4311444759368896,
        1.4290024042129517,
        1.4324133396148682
    ],
    "train_accuracy": [
        0.3125,
        0.375,
        0.4375,
        0.375,
        0.125,
        0.3125,
        0.25,
        0.5625,
        0.5,
        0.3125,
        0.4375,
        0.375,
        0.375,
        0.25,
        0.3125,
        0.25,
        0.3125,
        0.375,
        0.375,
        0.3125,
        0.25,
        0.125,
        0.4375,
        0.25,
        0.625,
        0.3125,
        0.375,
        0.5625,
        0.3125,
        0.5,
        0.25,
        0.3125,
        0.3125,
        0.5625,
        0.4375,
        0.375
    ],
    "val_accuracy": [
        0.125,
        0.4375,
        0.1875,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        1.2079572677612305,
        1.2075278759002686,
        1.206176996231079,
        1.2137818336486816,
        1.2100396156311035,
        1.2105786800384521,
        1.2088055610656738,
        1.209914207458496,
        1.2091095447540283,
        1.210012674331665,
        1.2099952697753906,
        1.2114362716674805,
        1.2120490074157715,
        1.2097909450531006,
        1.209432601928711,
        1.2146296501159668,
        1.2122278213500977,
        1.2141647338867188,
        1.208946943283081,
        1.2127914428710938,
        1.2143378257751465,
        1.2158112525939941,
        1.2147345542907715,
        1.2163138389587402,
        1.2146828174591064,
        1.2148370742797852,
        1.2133171558380127,
        1.2139701843261719,
        1.2160730361938477,
        1.2151639461517334,
        1.2183074951171875,
        1.2129664421081543,
        1.216848611831665,
        1.2163164615631104,
        1.2152225971221924,
        1.2161533832550049
    ]
}