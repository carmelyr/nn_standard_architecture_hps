{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.218584331441,
        "ff_dim": 683,
        "hidden_units": 202,
        "learning_rate": 0.0002079150577,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "mean",
        "weight_decay": 9.99230179e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 34,
    "train_loss": [
        3.062647581100464,
        1.6649243831634521,
        1.7836841344833374,
        1.338578224182129,
        1.7994384765625,
        1.2655266523361206,
        1.4163302183151245,
        1.2479304075241089,
        1.4446337223052979,
        1.5400736331939697,
        1.5872113704681396,
        0.9892265200614929,
        1.4862817525863647,
        1.4134095907211304,
        1.5167500972747803,
        1.3627495765686035,
        1.4694452285766602,
        1.4955427646636963,
        1.3106226921081543,
        1.1327674388885498,
        1.3934074640274048,
        1.1629798412322998,
        1.2724897861480713,
        1.184578776359558,
        0.9695184230804443,
        1.1629750728607178,
        1.375900149345398,
        1.1022155284881592,
        1.3761111497879028,
        0.8934874534606934,
        1.3305829763412476,
        1.1013025045394897,
        0.9511846899986267,
        1.3021414279937744
    ],
    "val_loss": [
        1.8813656568527222,
        2.5093886852264404,
        1.5201307535171509,
        1.7873448133468628,
        1.481080174446106,
        1.6405706405639648,
        1.6833086013793945,
        1.5943020582199097,
        1.5712517499923706,
        1.5895823240280151,
        1.6330915689468384,
        1.5648359060287476,
        1.5756778717041016,
        1.6320937871932983,
        1.6637688875198364,
        1.6882206201553345,
        1.7052868604660034,
        1.6710023880004883,
        1.642372727394104,
        1.6196942329406738,
        1.6162687540054321,
        1.6136366128921509,
        1.6007037162780762,
        1.5963611602783203,
        1.5940848588943481,
        1.6017736196517944,
        1.6238404512405396,
        1.6472450494766235,
        1.661810040473938,
        1.6733664274215698,
        1.6781545877456665,
        1.6807818412780762,
        1.6789644956588745,
        1.6725444793701172,
        1.6718425750732422
    ],
    "train_accuracy": [
        0.1875,
        0.3125,
        0.1875,
        0.5,
        0.25,
        0.5625,
        0.375,
        0.4375,
        0.375,
        0.25,
        0.3125,
        0.5,
        0.25,
        0.5625,
        0.25,
        0.375,
        0.4375,
        0.25,
        0.25,
        0.5625,
        0.375,
        0.5625,
        0.4375,
        0.5,
        0.5625,
        0.5625,
        0.25,
        0.375,
        0.375,
        0.5625,
        0.375,
        0.5625,
        0.625,
        0.4375
    ],
    "val_accuracy": [
        0.4166666567325592,
        0.3333333432674408,
        0.5,
        0.25,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592
    ],
    "epoch_times": [
        0.15143370628356934,
        0.1310725212097168,
        0.13208341598510742,
        0.13199234008789062,
        0.13407373428344727,
        0.1329212188720703,
        0.13231635093688965,
        0.13331055641174316,
        0.13198161125183105,
        0.13385868072509766,
        0.1335592269897461,
        0.13274550437927246,
        0.1332845687866211,
        0.13225293159484863,
        0.13385462760925293,
        0.1331934928894043,
        0.1320044994354248,
        0.13312077522277832,
        0.13214397430419922,
        0.13344597816467285,
        0.1339423656463623,
        0.13292670249938965,
        0.13267827033996582,
        0.13193559646606445,
        0.1331641674041748,
        0.13280248641967773,
        0.13238024711608887,
        0.1328449249267578,
        0.13231229782104492,
        0.13428902626037598,
        0.13353180885314941,
        0.13374948501586914,
        0.13323378562927246,
        0.1325695514678955
    ]
}