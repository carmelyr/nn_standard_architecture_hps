{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2730251423111,
        "ff_dim": 278,
        "hidden_units": 242,
        "learning_rate": 0.0007346151138,
        "num_heads": 5,
        "num_layers": 1,
        "pooling": "max",
        "weight_decay": 5.2611351e-06
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        2.0689549446105957,
        1.4911984205245972,
        1.4723660945892334,
        2.157240152359009,
        1.57400643825531,
        1.734909176826477,
        1.575452446937561,
        1.6575194597244263,
        1.1396715641021729,
        1.2369791269302368,
        1.141977071762085,
        1.2044973373413086,
        1.4540510177612305,
        1.2481558322906494,
        1.3210946321487427,
        1.143802285194397,
        1.0355561971664429,
        1.3675813674926758,
        1.0253392457962036,
        1.121781826019287,
        1.0085279941558838,
        1.3030589818954468,
        1.2176731824874878,
        1.174917459487915,
        0.9580602645874023,
        1.2290939092636108,
        1.218598484992981,
        0.9155972003936768,
        0.9941184520721436,
        1.108532428741455,
        1.093860149383545,
        1.2006666660308838,
        0.9730218052864075
    ],
    "val_loss": [
        1.9320563077926636,
        1.9058282375335693,
        1.8489563465118408,
        1.361963152885437,
        1.4543148279190063,
        1.758992314338684,
        1.6101112365722656,
        1.4082279205322266,
        1.651202917098999,
        1.6181870698928833,
        1.486225962638855,
        1.3876047134399414,
        1.4585046768188477,
        1.653370976448059,
        1.458241581916809,
        1.4432748556137085,
        1.538293719291687,
        1.6267588138580322,
        1.5872342586517334,
        1.3956390619277954,
        1.3714592456817627,
        1.5455361604690552,
        1.6093733310699463,
        1.5602504014968872,
        1.491470456123352,
        1.5015928745269775,
        1.6154121160507202,
        1.6502231359481812,
        1.6279436349868774,
        1.5844162702560425,
        1.544689655303955,
        1.5391639471054077,
        1.5541784763336182,
        1.5974946022033691
    ],
    "train_accuracy": [
        0.1875,
        0.25,
        0.4375,
        0.25,
        0.25,
        0.25,
        0.1875,
        0.375,
        0.5625,
        0.4375,
        0.5,
        0.625,
        0.3125,
        0.5,
        0.5,
        0.5,
        0.5625,
        0.25,
        0.4375,
        0.4375,
        0.5625,
        0.375,
        0.5,
        0.5625,
        0.625,
        0.4375,
        0.5,
        0.625,
        0.625,
        0.5625,
        0.375,
        0.5625,
        0.75
    ],
    "val_accuracy": [
        0.375,
        0.3125,
        0.1875,
        0.375,
        0.3125,
        0.125,
        0.375,
        0.375,
        0.125,
        0.3125,
        0.4375,
        0.375,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        0.24796557426452637,
        0.22156763076782227,
        0.21778559684753418,
        0.2169349193572998,
        0.21680188179016113,
        0.22251200675964355,
        0.21787762641906738,
        0.21543335914611816,
        0.21506071090698242,
        0.2150881290435791,
        0.21716856956481934,
        0.21619176864624023,
        0.21663618087768555,
        0.215590238571167,
        0.22231841087341309,
        0.21698212623596191,
        0.22707724571228027,
        0.21480917930603027,
        0.2166154384613037,
        0.22128796577453613,
        0.21564054489135742,
        0.21603083610534668,
        0.21395254135131836,
        0.2144925594329834,
        0.21454763412475586,
        0.2217717170715332,
        0.2194056510925293,
        0.21483683586120605,
        0.21511268615722656,
        0.21488380432128906,
        0.21430253982543945,
        0.2146925926208496,
        0.21348118782043457
    ]
}