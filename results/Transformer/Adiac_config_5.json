{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.490114750642,
        "ff_dim": 371,
        "hidden_units": 45,
        "learning_rate": 0.001685441794,
        "num_heads": 1,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 0.0002779539026
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 312,
        "val_size": 78,
        "input_shape": [
            176,
            1
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.7930524349212646,
        3.6620452404022217,
        3.574536085128784,
        3.6944148540496826,
        3.6556503772735596,
        3.590820550918579,
        3.6176512241363525,
        3.6313211917877197,
        3.7624988555908203,
        3.6598336696624756,
        3.6872730255126953,
        3.618281126022339,
        3.800930976867676,
        3.5940659046173096,
        3.597501039505005
    ],
    "val_loss": [
        3.6861913204193115,
        3.8389618396759033,
        3.817146062850952,
        3.83345103263855,
        3.818709135055542,
        3.8154728412628174,
        3.8359718322753906,
        3.8306427001953125,
        3.8323097229003906,
        3.839418411254883,
        3.8436737060546875,
        3.8528528213500977,
        3.8591740131378174,
        3.8777482509613037,
        3.88352370262146,
        3.8775532245635986
    ],
    "train_accuracy": [
        0.0416666679084301,
        0.0416666679084301,
        0.0,
        0.0,
        0.0416666679084301,
        0.0416666679084301,
        0.0416666679084301,
        0.0,
        0.0,
        0.0416666679084301,
        0.0,
        0.0833333358168602,
        0.0,
        0.0,
        0.0416666679084301
    ],
    "val_accuracy": [
        0.078125,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283,
        0.012820512987673283
    ]
}