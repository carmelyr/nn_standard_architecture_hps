{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2101839010437,
        "kernel_size": 5,
        "learning_rate": 0.0009933958471,
        "num_filters": 112,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 2,
        "residual": true
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 15,
    "train_loss": [
        1.2597079277038574,
        1.1004704236984253,
        0.9664373397827148,
        0.7689263224601746,
        0.7447907328605652,
        0.7084400057792664,
        0.6246575713157654,
        0.5932295918464661,
        0.5864660739898682,
        0.5372142195701599,
        0.4832521975040436,
        0.4892783463001251,
        0.43835607171058655,
        0.45491230487823486,
        0.40516185760498047
    ],
    "val_loss": [
        1.4756022691726685,
        1.461535096168518,
        1.4477320909500122,
        1.4262992143630981,
        1.3990875482559204,
        1.3632432222366333,
        1.3247613906860352,
        1.2896872758865356,
        1.2594295740127563,
        1.233237624168396,
        1.2253682613372803,
        1.2145065069198608,
        1.1896753311157227,
        1.1728326082229614,
        1.163367748260498,
        1.1494929790496826
    ],
    "train_accuracy": [
        0.2083333283662796,
        0.2916666567325592,
        0.3958333432674408,
        0.5,
        0.5416666865348816,
        0.5416666865348816,
        0.5833333134651184,
        0.6041666865348816,
        0.5625,
        0.6458333134651184,
        0.6458333134651184,
        0.6875,
        0.6666666865348816,
        0.6458333134651184,
        0.7083333134651184
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408
    ]
}