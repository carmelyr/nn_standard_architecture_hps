{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0609877129238,
        "ff_dim": 510,
        "hidden_units": 510,
        "learning_rate": 0.0001219988639,
        "num_heads": 4,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 8.02798248e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 36,
    "train_loss": [
        1.3565936088562012,
        5.96135139465332,
        3.5271496772766113,
        1.0076959133148193,
        1.9251270294189453,
        1.7440696954727173,
        0.7597513198852539,
        1.0940229892730713,
        1.3005640506744385,
        0.9099783301353455,
        0.6834853887557983,
        1.1051372289657593,
        1.242419958114624,
        1.0749257802963257,
        0.8561410307884216,
        0.7835120558738708,
        0.6867202520370483,
        0.6955308318138123,
        0.7559447288513184,
        0.7298999428749084,
        0.7206678986549377,
        0.657910943031311,
        0.7506306171417236,
        0.5789773464202881,
        0.6320008039474487,
        0.733731210231781,
        0.5730145573616028,
        0.6272693276405334,
        0.6691770553588867,
        0.6382461786270142,
        0.6442965269088745,
        0.6503052115440369,
        0.6712021827697754,
        0.648764431476593,
        0.6592411994934082,
        0.633750319480896
    ],
    "val_loss": [
        0.9854626059532166,
        8.11651611328125,
        5.013540744781494,
        1.5190908908843994,
        1.1374446153640747,
        1.0145835876464844,
        0.5848315358161926,
        1.5132520198822021,
        1.7831264734268188,
        1.291542410850525,
        0.6845468878746033,
        0.6925174593925476,
        0.7863748669624329,
        0.7275113463401794,
        0.6250012516975403,
        0.5850114822387695,
        0.7379199862480164,
        0.905207633972168,
        0.954744279384613,
        0.9193102121353149,
        0.8424994945526123,
        0.7466081380844116,
        0.6577553153038025,
        0.6192901134490967,
        0.607977032661438,
        0.6107178926467896,
        0.6220377087593079,
        0.6427921056747437,
        0.6741993427276611,
        0.7197688817977905,
        0.7594468593597412,
        0.7726775407791138,
        0.7763947248458862,
        0.771227240562439,
        0.7585354447364807,
        0.7395946979522705,
        0.7174180746078491
    ],
    "train_accuracy": [
        0.4375,
        0.53125,
        0.53125,
        0.53125,
        0.46875,
        0.46875,
        0.5,
        0.53125,
        0.53125,
        0.53125,
        0.53125,
        0.46875,
        0.46875,
        0.5,
        0.46875,
        0.53125,
        0.65625,
        0.5625,
        0.5625,
        0.625,
        0.5625,
        0.625,
        0.5625,
        0.78125,
        0.65625,
        0.4375,
        0.65625,
        0.5625,
        0.53125,
        0.53125,
        0.625,
        0.59375,
        0.5625,
        0.59375,
        0.625,
        0.59375
    ],
    "val_accuracy": [
        0.625,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.375,
        0.375,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.23214101791381836,
        0.21926546096801758,
        0.21951961517333984,
        0.21935486793518066,
        0.21982145309448242,
        0.22034740447998047,
        0.22066569328308105,
        0.22026920318603516,
        0.22107815742492676,
        0.21985912322998047,
        0.22008728981018066,
        0.22029447555541992,
        0.21979784965515137,
        0.22112154960632324,
        0.2208089828491211,
        0.22081947326660156,
        0.2207326889038086,
        0.22064661979675293,
        0.22050094604492188,
        0.22025394439697266,
        0.22044110298156738,
        0.21997785568237305,
        0.21984124183654785,
        0.22035717964172363,
        0.22063684463500977,
        0.2205824851989746,
        0.21958327293395996,
        0.21962666511535645,
        0.21999430656433105,
        0.22220778465270996,
        0.2222146987915039,
        0.22272944450378418,
        0.222808837890625,
        0.22572827339172363,
        0.22181415557861328,
        0.22390198707580566
    ]
}