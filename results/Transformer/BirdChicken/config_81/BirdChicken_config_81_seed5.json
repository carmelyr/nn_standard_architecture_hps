{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.068110276744,
        "ff_dim": 279,
        "hidden_units": 444,
        "learning_rate": 1.63705046e-05,
        "num_heads": 8,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 2.56177413e-05
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.8516585826873779,
        0.7668781876564026,
        0.8212786912918091,
        0.6356315612792969,
        0.8173387050628662,
        0.7682342529296875,
        0.7461060881614685,
        0.731437087059021,
        0.5945063829421997,
        0.6950231790542603,
        0.6719620227813721,
        0.6149668097496033,
        0.6675626039505005,
        0.6765788793563843,
        0.663743793964386,
        0.5771840214729309,
        0.5996183156967163,
        0.5852699279785156,
        0.4809032082557678,
        0.5780003666877747,
        0.5740826725959778,
        0.6143655776977539,
        0.6187636852264404,
        0.5050708651542664,
        0.6109398007392883,
        0.4539302885532379,
        0.4951818883419037,
        0.562063992023468,
        0.5786045789718628,
        0.4700756371021271,
        0.623245120048523,
        0.6528405547142029,
        0.4925612509250641,
        0.5287241339683533
    ],
    "val_loss": [
        0.6988264918327332,
        0.9514463543891907,
        0.9398015737533569,
        0.7468417882919312,
        0.6701959371566772,
        0.6741847991943359,
        0.7434971928596497,
        0.857190728187561,
        0.8628281950950623,
        0.7717069387435913,
        0.6824526786804199,
        0.6716619729995728,
        0.6771631240844727,
        0.7000733613967896,
        0.7490615844726562,
        0.7908856272697449,
        0.7970583438873291,
        0.7943288087844849,
        0.8003108501434326,
        0.7944247126579285,
        0.7746824026107788,
        0.7426681518554688,
        0.7070829272270203,
        0.6971315741539001,
        0.692561149597168,
        0.6916937232017517,
        0.6935585737228394,
        0.7008426189422607,
        0.7071188688278198,
        0.7117337584495544,
        0.7165454626083374,
        0.7230486273765564,
        0.7286222577095032,
        0.7364519834518433,
        0.7442710995674133
    ],
    "train_accuracy": [
        0.5,
        0.53125,
        0.53125,
        0.5625,
        0.46875,
        0.46875,
        0.53125,
        0.5625,
        0.59375,
        0.5625,
        0.6875,
        0.6875,
        0.59375,
        0.625,
        0.59375,
        0.6875,
        0.625,
        0.71875,
        0.8125,
        0.71875,
        0.625,
        0.6875,
        0.59375,
        0.8125,
        0.75,
        0.84375,
        0.71875,
        0.6875,
        0.6875,
        0.75,
        0.5625,
        0.78125,
        0.8125,
        0.625
    ],
    "val_accuracy": [
        0.625,
        0.25,
        0.25,
        0.25,
        0.75,
        0.75,
        0.375,
        0.25,
        0.25,
        0.375,
        0.625,
        0.75,
        0.75,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.2148270606994629,
        0.15004825592041016,
        0.14873862266540527,
        0.14951014518737793,
        0.15004825592041016,
        0.15065407752990723,
        0.15034198760986328,
        0.14817047119140625,
        0.1476588249206543,
        0.1488502025604248,
        0.14994430541992188,
        0.14887690544128418,
        0.1484980583190918,
        0.14672398567199707,
        0.14815592765808105,
        0.15113353729248047,
        0.14679217338562012,
        0.14722108840942383,
        0.14840340614318848,
        0.14748883247375488,
        0.1514911651611328,
        0.1495516300201416,
        0.14844703674316406,
        0.14700531959533691,
        0.14969325065612793,
        0.1473863124847412,
        0.14861083030700684,
        0.14666342735290527,
        0.1487576961517334,
        0.14992952346801758,
        0.14973115921020508,
        0.1470811367034912,
        0.14838504791259766,
        0.14998579025268555
    ]
}