{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0137457461769,
        "ff_dim": 839,
        "hidden_units": 476,
        "learning_rate": 2.32106058e-05,
        "num_heads": 2,
        "num_layers": 6,
        "pooling": "max",
        "weight_decay": 2.58271673e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 34,
    "train_loss": [
        1.905794382095337,
        1.649224877357483,
        1.530462384223938,
        1.345980167388916,
        1.3147761821746826,
        1.4498095512390137,
        1.1560053825378418,
        1.1751480102539062,
        1.1776317358016968,
        1.4152836799621582,
        1.0172181129455566,
        1.1914174556732178,
        1.2366856336593628,
        1.0492621660232544,
        0.9963571429252625,
        0.8495892286300659,
        1.0920058488845825,
        0.9195166826248169,
        1.0059269666671753,
        0.8831743001937866,
        0.9016053676605225,
        0.9036787152290344,
        0.7736190557479858,
        1.0390591621398926,
        0.8345455527305603,
        1.0271512269973755,
        0.9801178574562073,
        0.9803910851478577,
        0.9557644128799438,
        0.9539544582366943,
        0.9477124810218811,
        0.9493029713630676,
        0.924848735332489,
        0.9495342969894409
    ],
    "val_loss": [
        1.74213707447052,
        1.975480079650879,
        1.7702034711837769,
        1.424952507019043,
        1.3573036193847656,
        1.3929834365844727,
        1.4334968328475952,
        1.4730911254882812,
        1.479179859161377,
        1.4752405881881714,
        1.467055320739746,
        1.4695366621017456,
        1.4845209121704102,
        1.4798221588134766,
        1.4800300598144531,
        1.4777846336364746,
        1.4730297327041626,
        1.4882816076278687,
        1.4997458457946777,
        1.5129660367965698,
        1.5262068510055542,
        1.534575343132019,
        1.526119351387024,
        1.5249629020690918,
        1.5218182802200317,
        1.5217328071594238,
        1.5228562355041504,
        1.5161290168762207,
        1.5120725631713867,
        1.511712908744812,
        1.512174129486084,
        1.5105229616165161,
        1.5074974298477173,
        1.5074505805969238,
        1.5062918663024902
    ],
    "train_accuracy": [
        0.25,
        0.1875,
        0.3125,
        0.5,
        0.4375,
        0.5625,
        0.625,
        0.5625,
        0.5625,
        0.5,
        0.6875,
        0.4375,
        0.5625,
        0.75,
        0.8125,
        0.75,
        0.5625,
        0.8125,
        0.5625,
        0.8125,
        0.8125,
        0.6875,
        0.875,
        0.625,
        0.6875,
        0.625,
        0.625,
        0.6875,
        0.5625,
        0.8125,
        0.625,
        0.625,
        0.75,
        0.6875
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.1666666716337204,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        22.971730947494507,
        14.872384071350098,
        15.463277339935303,
        13.419252157211304,
        13.522176504135132,
        12.566388845443726,
        13.41745400428772,
        12.011027097702026,
        14.115392446517944,
        11.780608654022217,
        13.497915029525757,
        12.373335361480713,
        13.97425103187561,
        13.3110032081604,
        13.90075969696045,
        11.578566551208496,
        13.082846879959106,
        13.516024112701416,
        13.515238285064697,
        11.397428512573242,
        11.407634973526001,
        13.97809910774231,
        16.991945028305054,
        13.495190620422363,
        15.886853456497192,
        13.623769283294678,
        12.169144868850708,
        12.212524890899658,
        11.509207010269165,
        11.720322132110596,
        11.809506177902222,
        11.921832084655762,
        12.012210845947266,
        11.818874835968018
    ]
}