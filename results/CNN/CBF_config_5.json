{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1418779037326,
        "kernel_size": 7,
        "learning_rate": 0.0019347410864,
        "num_filters": 158,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "CBF",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            128
        ],
        "num_classes": 3
    },
    "epochs": 15,
    "train_loss": [
        0.8051836490631104,
        0.3672051429748535,
        0.19582407176494598,
        0.14022426307201385,
        0.07423325628042221,
        0.05448414385318756,
        0.061151135712862015,
        0.02609853446483612,
        0.018070386722683907,
        0.014834299683570862,
        0.017436781898140907,
        0.013488545082509518,
        0.018412381410598755,
        0.009617454372346401,
        0.00952876266092062
    ],
    "val_loss": [
        0.807621955871582,
        0.7778132557868958,
        0.7530059218406677,
        0.7293770909309387,
        0.7025402188301086,
        0.6669324040412903,
        0.6169084906578064,
        0.5734174847602844,
        0.5250236988067627,
        0.4694039821624756,
        0.4134417474269867,
        0.3654691278934479,
        0.3221813142299652,
        0.2899188697338104,
        0.27687183022499084,
        0.2774144113063812
    ],
    "train_accuracy": [
        0.3541666567325592,
        0.625,
        0.6875,
        0.6875,
        0.7083333134651184,
        0.7291666865348816,
        0.7083333134651184,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816,
        0.7291666865348816
    ],
    "val_accuracy": [
        0.4166666567325592,
        0.5833333134651184,
        0.5833333134651184,
        0.5833333134651184,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816
    ]
}