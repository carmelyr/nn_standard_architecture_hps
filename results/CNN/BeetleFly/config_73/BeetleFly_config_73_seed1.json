{
    "hyperparameters": {
        "activation": "sigmoid",
        "dropout_rate": 0.2937422396752,
        "kernel_size": 3,
        "learning_rate": 0.0013487527048,
        "num_filters": 248,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.6938016414642334,
        0.5702191591262817,
        0.4874654710292816,
        0.3276192843914032,
        0.2792651355266571,
        0.20729757845401764,
        0.18451783061027527,
        0.15112939476966858,
        0.06249655410647392,
        0.12007009238004684,
        0.03605113551020622,
        0.07399564981460571,
        0.018098946660757065,
        0.17420458793640137,
        0.028193453326821327,
        0.018439393490552902,
        0.013017763383686543,
        0.0496101938188076,
        0.02416415885090828,
        0.010300246998667717,
        0.01083772350102663,
        0.011593499220907688,
        0.01582839898765087,
        0.011529810726642609,
        0.0030899273697286844,
        0.005214533768594265,
        0.009057862684130669,
        0.009816611185669899,
        0.002275631530210376,
        0.0034494090359658003,
        0.0036603999324142933,
        0.0041593750938773155,
        0.0022018516901880503,
        0.0021568424999713898
    ],
    "val_loss": [
        0.6615799069404602,
        0.6611653566360474,
        0.6610808372497559,
        0.6611329913139343,
        0.6606138348579407,
        0.6606359481811523,
        0.6613909602165222,
        0.6633288860321045,
        0.664867639541626,
        0.6664522886276245,
        0.6687518954277039,
        0.6704955101013184,
        0.6725599765777588,
        0.6750025749206543,
        0.6872808337211609,
        0.7088051438331604,
        0.7368046641349792,
        0.7743169069290161,
        0.8166237473487854,
        0.871303379535675,
        0.9404314756393433,
        1.0232577323913574,
        1.1222546100616455,
        1.2374680042266846,
        1.3779528141021729,
        1.5416184663772583,
        1.730402946472168,
        1.932798981666565,
        2.166537284851074,
        2.4204282760620117,
        2.67387318611145,
        2.951988697052002,
        3.236616373062134,
        3.5292253494262695,
        3.819751739501953
    ],
    "train_accuracy": [
        0.5,
        0.78125,
        0.71875,
        0.875,
        0.875,
        0.9375,
        0.9375,
        0.9375,
        1.0,
        0.9375,
        1.0,
        0.9375,
        1.0,
        0.9375,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        4.540277004241943,
        0.05176901817321777,
        0.023183822631835938,
        0.029824018478393555,
        0.02290797233581543,
        0.02287006378173828,
        0.02253413200378418,
        0.023108959197998047,
        0.022721052169799805,
        0.022408008575439453,
        0.022884130477905273,
        0.02226114273071289,
        0.02232813835144043,
        0.02299785614013672,
        0.021987199783325195,
        0.021591663360595703,
        0.022330284118652344,
        0.02152419090270996,
        0.02229905128479004,
        0.02101302146911621,
        0.021863222122192383,
        0.022337913513183594,
        0.021594762802124023,
        0.021530866622924805,
        0.021769046783447266,
        0.022257089614868164,
        0.021317005157470703,
        0.022343873977661133,
        0.02297496795654297,
        0.02277517318725586,
        0.02200603485107422,
        0.022297143936157227,
        0.021264076232910156,
        0.021647930145263672
    ]
}