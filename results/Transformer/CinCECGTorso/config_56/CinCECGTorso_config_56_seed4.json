{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1799906420434,
        "ff_dim": 840,
        "hidden_units": 273,
        "learning_rate": 1.09356413e-05,
        "num_heads": 6,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 2.88015742e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        1.727892518043518,
        1.300609827041626,
        1.3104126453399658,
        1.7199796438217163,
        1.4277660846710205,
        1.4293580055236816,
        1.7225985527038574,
        1.0434409379959106,
        1.4380345344543457,
        1.3662465810775757,
        1.395280122756958,
        1.4567275047302246,
        1.5089564323425293,
        1.2209595441818237,
        1.397303819656372,
        1.1449027061462402,
        1.3018536567687988,
        1.1860402822494507,
        1.0820873975753784,
        1.077444314956665,
        1.3519961833953857,
        1.4632171392440796,
        1.285522699356079,
        1.1102501153945923,
        1.2149021625518799,
        1.376229166984558,
        1.3889648914337158,
        1.468178153038025,
        1.431165099143982,
        1.280820608139038,
        1.2620453834533691,
        1.3470419645309448,
        1.0476038455963135
    ],
    "val_loss": [
        1.81306791305542,
        1.3120445013046265,
        1.2509835958480835,
        1.239099144935608,
        1.3219057321548462,
        1.363400936126709,
        1.3494236469268799,
        1.3489114046096802,
        1.3052456378936768,
        1.3492943048477173,
        1.348745584487915,
        1.3631575107574463,
        1.3409290313720703,
        1.3710157871246338,
        1.383748173713684,
        1.382130742073059,
        1.3839681148529053,
        1.3964264392852783,
        1.3854894638061523,
        1.3863871097564697,
        1.3916105031967163,
        1.3943177461624146,
        1.3959832191467285,
        1.39437735080719,
        1.38998544216156,
        1.391937255859375,
        1.395115613937378,
        1.3942044973373413,
        1.3913159370422363,
        1.393048882484436,
        1.3920085430145264,
        1.3891749382019043,
        1.3873902559280396,
        1.3848544359207153
    ],
    "train_accuracy": [
        0.25,
        0.5625,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.25,
        0.625,
        0.3125,
        0.375,
        0.3125,
        0.3125,
        0.25,
        0.3125,
        0.25,
        0.4375,
        0.375,
        0.6875,
        0.625,
        0.5,
        0.375,
        0.375,
        0.3125,
        0.5,
        0.4375,
        0.4375,
        0.3125,
        0.4375,
        0.25,
        0.625,
        0.375,
        0.375,
        0.625
    ],
    "val_accuracy": [
        0.125,
        0.1875,
        0.4375,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        1.2031102180480957,
        1.2013819217681885,
        1.2005629539489746,
        1.2037580013275146,
        1.2066030502319336,
        1.2076714038848877,
        1.2045905590057373,
        1.2038729190826416,
        1.2048611640930176,
        1.2063188552856445,
        1.2077081203460693,
        1.2081921100616455,
        1.2084543704986572,
        1.2096996307373047,
        1.2074193954467773,
        1.208420753479004,
        1.2086067199707031,
        1.20916748046875,
        1.2079010009765625,
        1.2080302238464355,
        1.2076106071472168,
        1.2100534439086914,
        1.2083163261413574,
        1.2094745635986328,
        1.209305763244629,
        1.2107524871826172,
        1.210413932800293,
        1.2090537548065186,
        1.2163054943084717,
        1.2130203247070312,
        1.2092945575714111,
        1.2112362384796143,
        1.2088000774383545
    ]
}