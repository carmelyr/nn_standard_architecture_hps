{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3065148472549,
        "kernel_size": 6,
        "learning_rate": 0.0004271643125,
        "num_filters": 93,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.671354293823242,
        3.4899656772613525,
        3.3924970626831055,
        3.3479347229003906,
        3.287424087524414,
        3.2151803970336914,
        3.154110908508301,
        3.106414794921875,
        3.0672059059143066,
        3.02624773979187,
        2.9769234657287598,
        2.9268698692321777,
        2.881418228149414,
        2.8489367961883545,
        2.7693519592285156
    ],
    "val_loss": [
        3.5517003536224365,
        3.468740701675415,
        3.416409492492676,
        3.353153705596924,
        3.3152859210968018,
        3.2777292728424072,
        3.2541284561157227,
        3.203115940093994,
        3.1987063884735107,
        3.156925916671753,
        3.1372835636138916,
        3.1170132160186768,
        3.113417625427246,
        3.061227321624756,
        3.069228172302246,
        3.0163955688476562
    ],
    "train_accuracy": [
        0.03365384787321091,
        0.05662393197417259,
        0.06997863203287125,
        0.0822649598121643,
        0.10096153616905212,
        0.11057692021131516,
        0.12393162399530411,
        0.14049145579338074,
        0.15705128014087677,
        0.1538461595773697,
        0.17628204822540283,
        0.17681623995304108,
        0.19284188747406006,
        0.2003205120563507,
        0.2280982881784439
    ],
    "val_accuracy": [
        0.0,
        0.07264957576990128,
        0.06410256773233414,
        0.09401709586381912,
        0.08974359184503555,
        0.10256410390138626,
        0.09401709586381912,
        0.1388888955116272,
        0.1111111119389534,
        0.10683760792016983,
        0.12820513546466827,
        0.14316239953041077,
        0.14316239953041077,
        0.14957265555858612,
        0.14316239953041077,
        0.16025641560554504
    ]
}