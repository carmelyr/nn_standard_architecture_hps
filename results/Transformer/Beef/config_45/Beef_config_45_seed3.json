{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1894201741382,
        "ff_dim": 374,
        "hidden_units": 347,
        "learning_rate": 3.86354961e-05,
        "num_heads": 8,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 9.6499281e-06
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        2.10723614692688,
        1.9174091815948486,
        1.8063830137252808,
        1.787253975868225,
        1.7222816944122314,
        2.109485149383545,
        1.8681950569152832,
        1.938698649406433,
        1.8477591276168823,
        1.459602952003479,
        1.5493841171264648,
        1.4046494960784912,
        1.6122335195541382,
        1.7862313985824585,
        1.713340163230896,
        1.4833002090454102,
        1.5573322772979736,
        1.2738059759140015,
        1.5475715398788452,
        1.4380621910095215,
        1.5918052196502686,
        1.561519742012024,
        1.5035600662231445,
        1.8081605434417725,
        1.3972111940383911,
        1.5484213829040527,
        1.5872722864151,
        1.8268449306488037,
        1.6395483016967773,
        1.5142934322357178,
        1.6018283367156982
    ],
    "val_loss": [
        2.486534357070923,
        1.4559706449508667,
        1.6348496675491333,
        2.0219125747680664,
        2.402195692062378,
        2.5690083503723145,
        2.4562432765960693,
        2.2541544437408447,
        2.1159112453460693,
        1.981533169746399,
        1.8527021408081055,
        1.7465486526489258,
        1.6754344701766968,
        1.6555191278457642,
        1.6657911539077759,
        1.6794065237045288,
        1.689051628112793,
        1.7043803930282593,
        1.7241603136062622,
        1.748988151550293,
        1.7639328241348267,
        1.7727664709091187,
        1.782545566558838,
        1.787657618522644,
        1.7880054712295532,
        1.785460352897644,
        1.7859171628952026,
        1.7859339714050293,
        1.786859154701233,
        1.7873420715332031,
        1.7871345281600952,
        1.7849922180175781
    ],
    "train_accuracy": [
        0.3125,
        0.0625,
        0.1875,
        0.25,
        0.125,
        0.125,
        0.3125,
        0.1875,
        0.25,
        0.375,
        0.25,
        0.3125,
        0.25,
        0.125,
        0.1875,
        0.3125,
        0.375,
        0.5625,
        0.3125,
        0.25,
        0.25,
        0.4375,
        0.375,
        0.125,
        0.5,
        0.25,
        0.3125,
        0.125,
        0.25,
        0.3125,
        0.375
    ],
    "val_accuracy": [
        0.25,
        0.4166666567325592,
        0.5,
        0.3333333432674408,
        0.0833333358168602,
        0.0833333358168602,
        0.0833333358168602,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408
    ],
    "epoch_times": [
        0.17382001876831055,
        0.1526508331298828,
        0.15318536758422852,
        0.1532900333404541,
        0.15449070930480957,
        0.1519303321838379,
        0.15288686752319336,
        0.15469098091125488,
        0.15212678909301758,
        0.15226435661315918,
        0.15184402465820312,
        0.15177249908447266,
        0.15271663665771484,
        0.15145325660705566,
        0.15221357345581055,
        0.15248537063598633,
        0.15223407745361328,
        0.15318942070007324,
        0.1528005599975586,
        0.15319108963012695,
        0.15308070182800293,
        0.15136075019836426,
        0.1507868766784668,
        0.14965319633483887,
        0.15158867835998535,
        0.15165996551513672,
        0.1528463363647461,
        0.15334630012512207,
        0.15161442756652832,
        0.15151095390319824,
        0.15117454528808594
    ]
}