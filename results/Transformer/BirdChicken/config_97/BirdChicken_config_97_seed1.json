{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1683907598725,
        "ff_dim": 673,
        "hidden_units": 447,
        "learning_rate": 0.0003099832182,
        "num_heads": 4,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 8.1860333e-05
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.7450569272041321,
        6.809483528137207,
        2.8430182933807373,
        0.8816720843315125,
        0.762245774269104,
        0.7274409532546997,
        0.5324914455413818,
        0.8738703727722168,
        0.5677499771118164,
        0.6786710023880005,
        0.6386311650276184,
        0.7147636413574219,
        0.5118446946144104,
        0.6815254092216492,
        0.5064429640769958,
        0.4671253263950348,
        0.540171205997467,
        0.6305385828018188,
        0.608646035194397,
        0.5711990594863892,
        0.44730594754219055,
        0.5514541864395142,
        0.4996599555015564,
        0.5650460124015808,
        0.4952656030654907,
        0.4330917298793793,
        0.3975829482078552,
        0.42840278148651123,
        0.5117974877357483,
        0.403453528881073,
        0.44384080171585083,
        0.46498918533325195,
        0.3929416239261627,
        0.3783872723579407
    ],
    "val_loss": [
        0.8442809581756592,
        5.665224075317383,
        2.5731632709503174,
        1.2872334718704224,
        0.7142430543899536,
        0.7662460803985596,
        0.7536230087280273,
        0.8145749568939209,
        0.7370856404304504,
        0.8817049860954285,
        0.8683832883834839,
        0.9293402433395386,
        0.91652911901474,
        0.920565664768219,
        0.9458786249160767,
        0.9249944090843201,
        1.083631992340088,
        1.1191840171813965,
        1.0637800693511963,
        0.9786947965621948,
        0.9817695617675781,
        1.0615568161010742,
        1.1085140705108643,
        1.1084257364273071,
        1.0950806140899658,
        1.086022138595581,
        1.102618932723999,
        1.1364046335220337,
        1.170413613319397,
        1.17931067943573,
        1.1821476221084595,
        1.1839606761932373,
        1.1938798427581787,
        1.211317777633667,
        1.2403181791305542
    ],
    "train_accuracy": [
        0.5,
        0.46875,
        0.5,
        0.53125,
        0.4375,
        0.59375,
        0.625,
        0.46875,
        0.65625,
        0.5625,
        0.59375,
        0.71875,
        0.6875,
        0.625,
        0.78125,
        0.8125,
        0.71875,
        0.65625,
        0.59375,
        0.6875,
        0.78125,
        0.71875,
        0.8125,
        0.6875,
        0.71875,
        0.8125,
        0.8125,
        0.8125,
        0.71875,
        0.8125,
        0.78125,
        0.78125,
        0.84375,
        0.8125
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.5,
        0.375,
        0.375,
        0.625,
        0.375,
        0.5,
        0.625,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.375,
        0.5,
        0.625,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.25,
        0.25,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.18406987190246582,
        0.14376330375671387,
        0.14259743690490723,
        0.15151524543762207,
        0.14291930198669434,
        0.14351940155029297,
        0.14144444465637207,
        0.14069437980651855,
        0.142686128616333,
        0.1424560546875,
        0.14188098907470703,
        0.142625093460083,
        0.14270401000976562,
        0.14246773719787598,
        0.14215564727783203,
        0.14401030540466309,
        0.1440424919128418,
        0.14326167106628418,
        0.14418601989746094,
        0.14362883567810059,
        0.14428424835205078,
        0.1436774730682373,
        0.14430952072143555,
        0.14494562149047852,
        0.14441561698913574,
        0.1435849666595459,
        0.1435868740081787,
        0.1436920166015625,
        0.14489436149597168,
        0.14562463760375977,
        0.1457996368408203,
        0.14491820335388184,
        0.1436772346496582,
        0.1446211338043213
    ]
}