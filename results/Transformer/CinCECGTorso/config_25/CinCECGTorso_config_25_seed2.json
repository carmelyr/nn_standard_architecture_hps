{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2217601084509,
        "ff_dim": 327,
        "hidden_units": 455,
        "learning_rate": 2.84710583e-05,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "mean",
        "weight_decay": 5.14505646e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 31,
    "train_loss": [
        2.0140199661254883,
        2.0271244049072266,
        1.318888545036316,
        1.7723884582519531,
        1.2991728782653809,
        1.305903673171997,
        1.364533543586731,
        1.2482848167419434,
        1.1783097982406616,
        1.4427874088287354,
        1.5627483129501343,
        1.5370666980743408,
        1.3470438718795776,
        1.3077877759933472,
        0.798186719417572,
        1.1406762599945068,
        1.2549474239349365,
        1.3586901426315308,
        1.0426644086837769,
        1.2697787284851074,
        1.1647225618362427,
        1.081947684288025,
        1.2138289213180542,
        1.4590944051742554,
        1.1801544427871704,
        1.2564306259155273,
        1.3213191032409668,
        0.9718301892280579,
        1.1810882091522217,
        1.1305238008499146,
        1.1934072971343994
    ],
    "val_loss": [
        2.1010515689849854,
        1.3845099210739136,
        1.4683518409729004,
        1.6887943744659424,
        1.6197857856750488,
        1.5234053134918213,
        1.530813217163086,
        1.6602263450622559,
        1.743689775466919,
        1.7420339584350586,
        1.6922038793563843,
        1.6792787313461304,
        1.717927098274231,
        1.7914962768554688,
        1.8175759315490723,
        1.8147637844085693,
        1.8117434978485107,
        1.7805835008621216,
        1.7986506223678589,
        1.8152931928634644,
        1.83880615234375,
        1.8412706851959229,
        1.8309283256530762,
        1.8226163387298584,
        1.8364163637161255,
        1.8267170190811157,
        1.8274093866348267,
        1.8330862522125244,
        1.8190773725509644,
        1.8179872035980225,
        1.8240081071853638,
        1.836771011352539
    ],
    "train_accuracy": [
        0.1875,
        0.3125,
        0.4375,
        0.25,
        0.25,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.4375,
        0.375,
        0.375,
        0.6875,
        0.5625,
        0.4375,
        0.5,
        0.375,
        0.4375,
        0.5625,
        0.5625,
        0.5,
        0.4375,
        0.5625,
        0.5,
        0.4375,
        0.625,
        0.3125,
        0.5,
        0.375
    ],
    "val_accuracy": [
        0.125,
        0.4375,
        0.4375,
        0.25,
        0.1875,
        0.1875,
        0.3125,
        0.3125,
        0.25,
        0.25,
        0.1875,
        0.25,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.1875,
        0.1875,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        2.1432247161865234,
        2.1416053771972656,
        2.149624824523926,
        2.1474640369415283,
        2.154010057449341,
        2.144813299179077,
        2.1512844562530518,
        2.1509644985198975,
        2.1497764587402344,
        2.1518478393554688,
        2.141979932785034,
        2.150493621826172,
        2.1527390480041504,
        2.153038263320923,
        2.150722026824951,
        2.1513872146606445,
        2.1499736309051514,
        2.149144411087036,
        2.149946451187134,
        2.150543451309204,
        2.145759344100952,
        2.1527225971221924,
        2.149951934814453,
        2.1480355262756348,
        2.1588387489318848,
        2.1507203578948975,
        2.154978036880493,
        2.154841423034668,
        2.1510775089263916,
        2.1524648666381836,
        2.154137372970581
    ]
}