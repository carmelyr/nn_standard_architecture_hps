{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0927954665632,
        "ff_dim": 704,
        "hidden_units": 480,
        "learning_rate": 4.09657925e-05,
        "num_heads": 7,
        "num_layers": 5,
        "pooling": "max",
        "weight_decay": 3.9851944e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 33,
    "train_loss": [
        1.1454271078109741,
        0.889394223690033,
        0.8582219481468201,
        0.7423168420791626,
        0.7085957527160645,
        0.649910569190979,
        0.7495834827423096,
        0.71865314245224,
        0.5927236080169678,
        0.6653315424919128,
        0.6773412227630615,
        0.6576542854309082,
        0.6555019617080688,
        0.5846543312072754,
        0.630889892578125,
        0.6159439086914062,
        0.6554519534111023,
        0.5696449875831604,
        0.5230108499526978,
        0.5978399515151978,
        0.5376836061477661,
        0.6838566064834595,
        0.6091504096984863,
        0.6427887678146362,
        0.615730881690979,
        0.5758605599403381,
        0.5712823867797852,
        0.6072503924369812,
        0.5973989963531494,
        0.5177889466285706,
        0.5621212720870972,
        0.6218425035476685,
        0.5930271744728088
    ],
    "val_loss": [
        1.2405043840408325,
        0.8034113049507141,
        0.9143652319908142,
        0.7533544301986694,
        0.7753946185112,
        0.8441892862319946,
        0.8238493204116821,
        0.8648201823234558,
        0.9173962473869324,
        0.8962802886962891,
        0.8697813153266907,
        0.8499127626419067,
        0.8342515230178833,
        0.832926332950592,
        0.8329344391822815,
        0.8326791524887085,
        0.8353464007377625,
        0.8431859612464905,
        0.8601471781730652,
        0.8820328116416931,
        0.9138910174369812,
        0.9383137226104736,
        0.9461358785629272,
        0.9492486715316772,
        0.9452571272850037,
        0.9350019693374634,
        0.9279822707176208,
        0.9195318818092346,
        0.9150891900062561,
        0.9117327928543091,
        0.9084945917129517,
        0.9053009152412415,
        0.9019448757171631,
        0.9003011584281921
    ],
    "train_accuracy": [
        0.53125,
        0.3125,
        0.5,
        0.5625,
        0.625,
        0.625,
        0.53125,
        0.53125,
        0.625,
        0.625,
        0.59375,
        0.6875,
        0.59375,
        0.625,
        0.625,
        0.59375,
        0.625,
        0.65625,
        0.78125,
        0.59375,
        0.75,
        0.53125,
        0.5625,
        0.53125,
        0.6875,
        0.65625,
        0.78125,
        0.625,
        0.65625,
        0.8125,
        0.6875,
        0.53125,
        0.71875
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.625,
        0.25,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.3484046459197998,
        0.2267594337463379,
        0.22658324241638184,
        0.22571063041687012,
        0.22418808937072754,
        0.22556543350219727,
        0.2284541130065918,
        0.22691988945007324,
        0.226210355758667,
        0.22585725784301758,
        0.2264258861541748,
        0.2263631820678711,
        0.22814369201660156,
        0.22823858261108398,
        0.22583723068237305,
        0.2255711555480957,
        0.22625255584716797,
        0.22579026222229004,
        0.22589325904846191,
        0.22424793243408203,
        0.22499895095825195,
        0.22829198837280273,
        0.22631478309631348,
        0.22486662864685059,
        0.22684168815612793,
        0.2249431610107422,
        0.2278754711151123,
        0.22663497924804688,
        0.22722220420837402,
        0.22542405128479004,
        0.224808931350708,
        0.22725391387939453,
        0.22681975364685059
    ]
}