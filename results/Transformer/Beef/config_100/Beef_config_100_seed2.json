{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1745348366843,
        "ff_dim": 385,
        "hidden_units": 161,
        "learning_rate": 1.39996323e-05,
        "num_heads": 3,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 7.0120995e-06
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.8608982563018799,
        1.6210570335388184,
        1.8037009239196777,
        1.7924920320510864,
        2.0062367916107178,
        1.4897865056991577,
        1.7422571182250977,
        1.8732545375823975,
        1.6570680141448975,
        1.4900342226028442,
        2.084073543548584,
        1.674047589302063,
        1.6736197471618652,
        1.7225425243377686,
        1.6238327026367188,
        1.7238540649414062,
        1.7646673917770386,
        1.9083231687545776,
        1.8133776187896729,
        1.736527681350708,
        1.8161537647247314,
        1.6943782567977905,
        1.9477298259735107,
        1.7215073108673096,
        1.732535481452942,
        2.061797618865967,
        1.675366997718811,
        1.6589057445526123,
        1.494006633758545,
        1.5813384056091309,
        1.8275412321090698
    ],
    "val_loss": [
        1.5839515924453735,
        1.5832363367080688,
        1.5864067077636719,
        1.5960750579833984,
        1.601427435874939,
        1.6086574792861938,
        1.6174726486206055,
        1.6250776052474976,
        1.6281028985977173,
        1.6306873559951782,
        1.6328388452529907,
        1.6343787908554077,
        1.6357094049453735,
        1.636513113975525,
        1.6369867324829102,
        1.6372700929641724,
        1.636804461479187,
        1.6369158029556274,
        1.6377835273742676,
        1.6386069059371948,
        1.639074683189392,
        1.6389503479003906,
        1.6387887001037598,
        1.6382375955581665,
        1.6379222869873047,
        1.637475848197937,
        1.6373372077941895,
        1.6370878219604492,
        1.6369075775146484,
        1.6367801427841187,
        1.6368025541305542,
        1.636888027191162
    ],
    "train_accuracy": [
        0.1875,
        0.25,
        0.125,
        0.25,
        0.25,
        0.375,
        0.1875,
        0.0625,
        0.125,
        0.375,
        0.1875,
        0.25,
        0.3125,
        0.3125,
        0.4375,
        0.1875,
        0.375,
        0.1875,
        0.25,
        0.125,
        0.125,
        0.1875,
        0.0625,
        0.25,
        0.1875,
        0.125,
        0.3125,
        0.3125,
        0.1875,
        0.25,
        0.1875
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.25,
        0.25,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408
    ],
    "epoch_times": [
        0.1739039421081543,
        0.05292510986328125,
        0.04889822006225586,
        0.050427913665771484,
        0.0490725040435791,
        0.04924583435058594,
        0.050803184509277344,
        0.050165653228759766,
        0.048879384994506836,
        0.04749894142150879,
        0.04657793045043945,
        0.04611563682556152,
        0.04564714431762695,
        0.0520021915435791,
        0.04848837852478027,
        0.04609346389770508,
        0.04592394828796387,
        0.04562115669250488,
        0.04563713073730469,
        0.045418500900268555,
        0.04618549346923828,
        0.04568290710449219,
        0.04571843147277832,
        0.045847415924072266,
        0.04753756523132324,
        0.04653501510620117,
        0.04662132263183594,
        0.04713177680969238,
        0.046944618225097656,
        0.04523348808288574,
        0.04513144493103027
    ]
}