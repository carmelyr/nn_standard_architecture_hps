{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1616262012497,
        "hidden_units": 25,
        "learning_rate": 0.0095644347257,
        "num_layers": 1,
        "weight_decay": 0.0050800025904
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 36,
        "val_size": 9,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 41,
    "train_loss": [
        0.9701622724533081,
        0.4756232500076294,
        0.44594839215278625,
        0.4069133400917053,
        0.3922770619392395,
        0.35967350006103516,
        0.3026876449584961,
        0.31106409430503845,
        0.23643548786640167,
        0.2377563863992691,
        0.26685330271720886,
        0.21807333827018738,
        0.1889612376689911,
        0.16070270538330078,
        0.13827216625213623,
        0.12382838129997253,
        0.13983458280563354,
        0.10531637072563171,
        0.0860498696565628,
        0.10786106437444687,
        0.1299964040517807,
        0.09355749934911728,
        0.06233661621809006,
        0.08818947523832321,
        0.07670240104198456,
        0.09534350782632828,
        0.0960741713643074,
        0.06406842172145844,
        0.1057581827044487,
        0.1427028328180313,
        0.0651184618473053,
        0.09288733452558517,
        0.05617829039692879,
        0.099173903465271,
        0.07344003766775131,
        0.0525454618036747,
        0.05682970955967903,
        0.13144005835056305,
        0.08223560452461243,
        0.07866503298282623,
        0.06664440780878067
    ],
    "val_loss": [
        0.7669680714607239,
        0.8526923060417175,
        0.9172468185424805,
        0.9329746961593628,
        0.881199061870575,
        0.8450741767883301,
        0.7449115514755249,
        0.7128391265869141,
        0.6669843792915344,
        0.6559427976608276,
        0.618857204914093,
        0.6118881106376648,
        0.6532618403434753,
        0.6525807976722717,
        0.6502322554588318,
        0.6559473872184753,
        0.6668574810028076,
        0.6940211057662964,
        0.6785289645195007,
        0.6729759573936462,
        0.6624343395233154,
        0.6882607340812683,
        0.6675145626068115,
        0.6646142601966858,
        0.6641450524330139,
        0.6491161584854126,
        0.6675682067871094,
        0.7112933993339539,
        0.7015045285224915,
        0.7106363773345947,
        0.6992436051368713,
        0.7002179026603699,
        0.6952817440032959,
        0.7385138869285583,
        0.7612434029579163,
        0.7734628915786743,
        0.7809020280838013,
        0.7935771346092224,
        0.816585898399353,
        0.8356640338897705,
        0.8608512878417969,
        0.8789377808570862
    ],
    "train_accuracy": [
        0.4166666567325592,
        0.7777777910232544,
        0.7777777910232544,
        0.8333333134651184,
        0.8888888955116272,
        0.8611111044883728,
        0.9166666865348816,
        0.9166666865348816,
        0.9722222089767456,
        0.9444444179534912,
        0.9166666865348816,
        0.9444444179534912,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9444444179534912,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9722222089767456,
        0.9444444179534912,
        1.0,
        0.9722222089767456,
        1.0,
        1.0,
        1.0,
        0.9444444179534912,
        0.9722222089767456,
        1.0,
        0.9722222089767456
    ],
    "val_accuracy": [
        0.4444444477558136,
        0.4444444477558136,
        0.5555555820465088,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.7777777910232544,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816,
        0.6666666865348816
    ],
    "epoch_times": [
        0.004974842071533203,
        0.006561756134033203,
        0.004911184310913086,
        0.0045239925384521484,
        0.004732847213745117,
        0.004741191864013672,
        0.004786968231201172,
        0.004647970199584961,
        0.004873991012573242,
        0.005232810974121094,
        0.004766941070556641,
        0.004831075668334961,
        0.005815267562866211,
        0.004848003387451172,
        0.004825115203857422,
        0.004722118377685547,
        0.0048596858978271484,
        0.004802227020263672,
        0.004723310470581055,
        0.004724025726318359,
        0.004651069641113281,
        0.004781961441040039,
        0.0047380924224853516,
        0.004620790481567383,
        0.004666805267333984,
        0.004576683044433594,
        0.004683971405029297,
        0.004683017730712891,
        0.004644870758056641,
        0.004633665084838867,
        0.004675149917602539,
        0.00463104248046875,
        0.004639148712158203,
        0.004662752151489258,
        0.004770040512084961,
        0.004717826843261719,
        0.004597902297973633,
        0.00467991828918457,
        0.004747152328491211,
        0.004669904708862305,
        0.004729747772216797
    ]
}