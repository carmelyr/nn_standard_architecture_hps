{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.3161516587151,
        "kernel_size": 6,
        "learning_rate": 0.0012825204594,
        "num_filters": 160,
        "num_layers": 1,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        0.761329710483551,
        0.5218096375465393,
        0.24366635084152222,
        0.14554397761821747,
        0.1247754618525505,
        0.10740360617637634,
        0.08140572160482407,
        0.09116136282682419,
        0.06735505908727646,
        0.07276390492916107,
        0.057956062257289886,
        0.03980157524347305,
        0.04565563052892685,
        0.03369612619280815,
        0.0301827322691679,
        0.024731913581490517,
        0.02348671853542328,
        0.02037152834236622,
        0.01953163929283619,
        0.013384477235376835,
        0.012577986344695091,
        0.012112773954868317,
        0.01226971298456192,
        0.011142547242343426,
        0.008043520152568817,
        0.009908175095915794,
        0.005259685218334198,
        0.00520777702331543,
        0.00723619619384408,
        0.0056312428787350655,
        0.0055136727169156075,
        0.003700446803122759,
        0.003914474509656429,
        0.004637028090655804
    ],
    "val_loss": [
        0.7151777744293213,
        0.5404826998710632,
        0.45621711015701294,
        0.43054017424583435,
        0.42861345410346985,
        0.4377196729183197,
        0.45150652527809143,
        0.4652659296989441,
        0.4898138642311096,
        0.5183907747268677,
        0.5456929206848145,
        0.5739615559577942,
        0.6026185154914856,
        0.6247480511665344,
        0.649342954158783,
        0.6780964732170105,
        0.7099631428718567,
        0.7446449398994446,
        0.7808504104614258,
        0.8173786997795105,
        0.8541998863220215,
        0.8902015686035156,
        0.9243115782737732,
        0.9590653777122498,
        0.9886007905006409,
        1.0184814929962158,
        1.047415852546692,
        1.0763585567474365,
        1.1064729690551758,
        1.1338958740234375,
        1.1619162559509277,
        1.1898781061172485,
        1.21674382686615,
        1.2433750629425049,
        1.2701239585876465
    ],
    "train_accuracy": [
        0.59375,
        0.75,
        0.90625,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.75,
        1.0,
        1.0,
        0.875,
        0.875,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.16917037963867188,
        0.022683382034301758,
        0.017113447189331055,
        0.01416921615600586,
        0.013329029083251953,
        0.013330221176147461,
        0.014643430709838867,
        0.013802766799926758,
        0.013289928436279297,
        0.012850522994995117,
        0.014076948165893555,
        0.014389276504516602,
        0.013158798217773438,
        0.013530731201171875,
        0.014989376068115234,
        0.01057291030883789,
        0.01115107536315918,
        0.011139154434204102,
        0.010543107986450195,
        0.010936975479125977,
        0.011609554290771484,
        0.011079072952270508,
        0.011602401733398438,
        0.011616706848144531,
        0.011638879776000977,
        0.011472702026367188,
        0.01290440559387207,
        0.011189460754394531,
        0.011798381805419922,
        0.011200904846191406,
        0.011539936065673828,
        0.012199163436889648,
        0.011143207550048828,
        0.011783123016357422
    ]
}