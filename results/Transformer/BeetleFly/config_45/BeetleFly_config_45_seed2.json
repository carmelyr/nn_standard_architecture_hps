{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1894201741382,
        "ff_dim": 374,
        "hidden_units": 347,
        "learning_rate": 3.86354961e-05,
        "num_heads": 8,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 9.6499281e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.7073858380317688,
        0.7998248934745789,
        0.7581723928451538,
        0.6818916201591492,
        0.6479941606521606,
        0.7921320796012878,
        0.6250948309898376,
        0.8099789023399353,
        0.7748534679412842,
        0.662933349609375,
        0.6458035111427307,
        0.6030044555664062,
        0.5900595784187317,
        0.8433210849761963,
        0.7061794400215149,
        0.6803889274597168,
        0.9036884307861328,
        0.7594703435897827,
        0.5411708354949951,
        0.7741348743438721,
        0.759296715259552,
        0.7948299646377563,
        0.5657409429550171,
        0.7318176031112671,
        0.6837985515594482,
        0.6924700736999512,
        0.6653555035591125,
        0.7965304255485535,
        0.663828432559967,
        0.7256839871406555,
        0.706261396408081
    ],
    "val_loss": [
        0.9182829856872559,
        0.9875614047050476,
        1.0691355466842651,
        1.1334749460220337,
        1.185778260231018,
        1.2570676803588867,
        1.3428106307983398,
        1.4462928771972656,
        1.4963144063949585,
        1.538524866104126,
        1.5797977447509766,
        1.6225584745407104,
        1.6636279821395874,
        1.704541563987732,
        1.7258446216583252,
        1.746952772140503,
        1.768393635749817,
        1.7879078388214111,
        1.8066965341567993,
        1.8243781328201294,
        1.8325835466384888,
        1.8400163650512695,
        1.8474963903427124,
        1.855257511138916,
        1.8626433610916138,
        1.8700244426727295,
        1.8732609748840332,
        1.87601900100708,
        1.878760576248169,
        1.8816920518875122,
        1.8844903707504272,
        1.8874704837799072
    ],
    "train_accuracy": [
        0.59375,
        0.53125,
        0.5625,
        0.65625,
        0.71875,
        0.53125,
        0.71875,
        0.53125,
        0.53125,
        0.625,
        0.65625,
        0.625,
        0.71875,
        0.5,
        0.5625,
        0.65625,
        0.46875,
        0.53125,
        0.6875,
        0.5625,
        0.5625,
        0.53125,
        0.71875,
        0.71875,
        0.625,
        0.65625,
        0.59375,
        0.53125,
        0.65625,
        0.5625,
        0.5625
    ],
    "val_accuracy": [
        0.375,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.1251223087310791,
        0.11903023719787598,
        0.11719369888305664,
        0.11780118942260742,
        0.11736607551574707,
        0.11598920822143555,
        0.1185767650604248,
        0.12213587760925293,
        0.11618757247924805,
        0.11932754516601562,
        0.11666989326477051,
        0.11518239974975586,
        0.11403894424438477,
        0.11621904373168945,
        0.11485695838928223,
        0.11511492729187012,
        0.11496996879577637,
        0.1163487434387207,
        0.11789870262145996,
        0.11689233779907227,
        0.1151268482208252,
        0.11684918403625488,
        0.11815261840820312,
        0.11750221252441406,
        0.11682391166687012,
        0.11571073532104492,
        0.11685872077941895,
        0.11673521995544434,
        0.11724615097045898,
        0.12079834938049316,
        0.11893796920776367
    ]
}