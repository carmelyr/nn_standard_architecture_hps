{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.4967077720736,
        "kernel_size": 4,
        "learning_rate": 0.0002032480355,
        "num_filters": 75,
        "num_layers": 5,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 31,
    "train_loss": [
        1.8701181411743164,
        1.8778818845748901,
        1.905470848083496,
        1.7641445398330688,
        1.7280184030532837,
        1.87338387966156,
        1.5645498037338257,
        1.8633681535720825,
        1.7520955801010132,
        1.71896493434906,
        1.596821665763855,
        1.7928646802902222,
        1.7731469869613647,
        1.8243341445922852,
        1.8325096368789673,
        1.4807795286178589,
        1.7273082733154297,
        1.686440110206604,
        1.6915377378463745,
        1.584398627281189,
        1.6203298568725586,
        1.6474180221557617,
        1.6903457641601562,
        1.5747767686843872,
        1.4452067613601685,
        1.6419496536254883,
        1.5169296264648438,
        1.6233006715774536,
        1.5629898309707642,
        1.5137429237365723,
        1.5626338720321655
    ],
    "val_loss": [
        1.6060194969177246,
        1.606321930885315,
        1.607459545135498,
        1.6080032587051392,
        1.6097055673599243,
        1.6119108200073242,
        1.61224365234375,
        1.6124215126037598,
        1.6141945123672485,
        1.6141949892044067,
        1.6136188507080078,
        1.6163029670715332,
        1.61654531955719,
        1.6182422637939453,
        1.6178689002990723,
        1.61697256565094,
        1.6159595251083374,
        1.615538239479065,
        1.6188907623291016,
        1.6188641786575317,
        1.621446967124939,
        1.623399257659912,
        1.6209362745285034,
        1.6229685544967651,
        1.623002052307129,
        1.6203759908676147,
        1.6185994148254395,
        1.619612216949463,
        1.6205991506576538,
        1.6246156692504883,
        1.6236165761947632,
        1.6230601072311401
    ],
    "train_accuracy": [
        0.1458333283662796,
        0.1041666641831398,
        0.2291666716337204,
        0.2083333283662796,
        0.2708333432674408,
        0.1875,
        0.3541666567325592,
        0.2083333283662796,
        0.2291666716337204,
        0.3125,
        0.2708333432674408,
        0.2291666716337204,
        0.2291666716337204,
        0.1666666716337204,
        0.2916666567325592,
        0.375,
        0.25,
        0.2291666716337204,
        0.2291666716337204,
        0.2083333283662796,
        0.2291666716337204,
        0.25,
        0.2916666567325592,
        0.3958333432674408,
        0.3333333432674408,
        0.2916666567325592,
        0.2916666567325592,
        0.3958333432674408,
        0.2916666567325592,
        0.3541666567325592,
        0.3333333432674408
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408
    ],
    "epoch_times": [
        0.05168318748474121,
        0.1873481273651123,
        0.061481475830078125,
        0.0515437126159668,
        0.047241926193237305,
        0.04738187789916992,
        0.04724717140197754,
        0.04799246788024902,
        0.0484166145324707,
        0.05244636535644531,
        0.04731249809265137,
        0.0474858283996582,
        0.05149483680725098,
        0.04347562789916992,
        0.045331478118896484,
        0.047118186950683594,
        0.048561811447143555,
        0.04585075378417969,
        0.045018911361694336,
        0.04788398742675781,
        0.04424881935119629,
        0.04484367370605469,
        0.04279446601867676,
        0.038889408111572266,
        0.04857921600341797,
        0.04713129997253418,
        0.041655778884887695,
        0.0444188117980957,
        0.046151161193847656,
        0.03418540954589844,
        0.03677797317504883
    ]
}