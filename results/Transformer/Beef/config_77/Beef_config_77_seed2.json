{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1596912679621,
        "ff_dim": 324,
        "hidden_units": 94,
        "learning_rate": 0.0002225834019,
        "num_heads": 4,
        "num_layers": 3,
        "pooling": "max",
        "weight_decay": 2.40272327e-05
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 32,
    "train_loss": [
        2.3542287349700928,
        1.9196945428848267,
        1.9603960514068604,
        1.6710646152496338,
        1.8533401489257812,
        1.6274079084396362,
        1.8411533832550049,
        1.6121838092803955,
        1.6960262060165405,
        1.6021918058395386,
        1.4884110689163208,
        1.8895317316055298,
        1.4330428838729858,
        1.6466270685195923,
        1.65871000289917,
        1.5716534852981567,
        1.6752917766571045,
        1.6391488313674927,
        1.6230604648590088,
        1.5584677457809448,
        1.508120059967041,
        1.4298397302627563,
        1.676157832145691,
        1.7795064449310303,
        1.499121904373169,
        1.7550013065338135,
        1.4786407947540283,
        1.523116111755371,
        1.5197200775146484,
        1.2819453477859497,
        1.483071208000183,
        1.3396817445755005
    ],
    "val_loss": [
        2.5304808616638184,
        1.7561663389205933,
        1.5592783689498901,
        1.7853384017944336,
        2.0468757152557373,
        2.174586534500122,
        2.0737464427948,
        1.92181396484375,
        1.763528823852539,
        1.6915768384933472,
        1.643517017364502,
        1.6170696020126343,
        1.5957980155944824,
        1.5931061506271362,
        1.598574161529541,
        1.605861783027649,
        1.6194318532943726,
        1.6260719299316406,
        1.6272468566894531,
        1.6318272352218628,
        1.645687222480774,
        1.6500324010849,
        1.6537760496139526,
        1.6581820249557495,
        1.6613140106201172,
        1.6600608825683594,
        1.6603622436523438,
        1.658509373664856,
        1.6570982933044434,
        1.6572097539901733,
        1.6554805040359497,
        1.6546732187271118,
        1.6519304513931274
    ],
    "train_accuracy": [
        0.25,
        0.3125,
        0.1875,
        0.1875,
        0.25,
        0.25,
        0.125,
        0.1875,
        0.375,
        0.375,
        0.375,
        0.125,
        0.4375,
        0.5,
        0.3125,
        0.1875,
        0.1875,
        0.1875,
        0.0625,
        0.25,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.1875,
        0.25,
        0.3125,
        0.375,
        0.5625,
        0.4375,
        0.6875
    ],
    "val_accuracy": [
        0.3333333432674408,
        0.25,
        0.3333333432674408,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25,
        0.25
    ],
    "epoch_times": [
        0.16735363006591797,
        0.06752562522888184,
        0.06434440612792969,
        0.06540441513061523,
        0.0562286376953125,
        0.0637667179107666,
        0.06168413162231445,
        0.06472301483154297,
        0.05973005294799805,
        0.058403968811035156,
        0.057394981384277344,
        0.05632376670837402,
        0.058008670806884766,
        0.053945064544677734,
        0.05831408500671387,
        0.060224294662475586,
        0.062103986740112305,
        0.060318946838378906,
        0.0606381893157959,
        0.05958676338195801,
        0.0568852424621582,
        0.05733919143676758,
        0.05292773246765137,
        0.05719399452209473,
        0.051024436950683594,
        0.05002403259277344,
        0.0500795841217041,
        0.04869484901428223,
        0.05064129829406738,
        0.05414295196533203,
        0.05246543884277344,
        0.04779505729675293
    ]
}