{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1730946524547,
        "ff_dim": 381,
        "hidden_units": 73,
        "learning_rate": 0.0003341229776,
        "num_heads": 7,
        "num_layers": 2,
        "pooling": "mean",
        "weight_decay": 1.83256354e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 35,
    "train_loss": [
        1.7618528604507446,
        1.5286712646484375,
        1.5922218561172485,
        1.8325945138931274,
        1.3189934492111206,
        1.235396385192871,
        1.0958702564239502,
        1.2495734691619873,
        1.2979927062988281,
        1.2699111700057983,
        1.2463269233703613,
        1.26878023147583,
        1.5036629438400269,
        1.0618211030960083,
        1.1451125144958496,
        1.23046875,
        1.3684560060501099,
        1.1896806955337524,
        1.127210259437561,
        1.0014307498931885,
        0.9875141382217407,
        1.2291510105133057,
        0.9579560160636902,
        0.861714780330658,
        0.7257713079452515,
        1.2106536626815796,
        1.0317548513412476,
        1.073028326034546,
        1.1137340068817139,
        1.1356974840164185,
        1.0576353073120117,
        0.9873843789100647,
        0.8391361832618713,
        0.9386523962020874,
        1.1128841638565063
    ],
    "val_loss": [
        2.090224504470825,
        1.3769361972808838,
        1.5476069450378418,
        1.399908185005188,
        1.4069114923477173,
        1.3105839490890503,
        1.4176536798477173,
        1.5356438159942627,
        1.5394998788833618,
        1.5045835971832275,
        1.491837739944458,
        1.4945502281188965,
        1.479140281677246,
        1.4989523887634277,
        1.5039244890213013,
        1.5738112926483154,
        1.6514617204666138,
        1.6292884349822998,
        1.6159327030181885,
        1.6120717525482178,
        1.5917325019836426,
        1.6347510814666748,
        1.6556878089904785,
        1.7156108617782593,
        1.7136869430541992,
        1.71503746509552,
        1.7134901285171509,
        1.6988451480865479,
        1.694528579711914,
        1.70330810546875,
        1.7161673307418823,
        1.7262613773345947,
        1.7359998226165771,
        1.7439566850662231,
        1.7411773204803467,
        1.7429554462432861
    ],
    "train_accuracy": [
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.375,
        0.3125,
        0.5,
        0.3125,
        0.5,
        0.375,
        0.25,
        0.375,
        0.4375,
        0.5625,
        0.5,
        0.4375,
        0.375,
        0.375,
        0.4375,
        0.5625,
        0.625,
        0.5,
        0.625,
        0.6875,
        0.875,
        0.375,
        0.4375,
        0.5,
        0.4375,
        0.5,
        0.5,
        0.6875,
        0.625,
        0.5,
        0.5
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.25,
        0.3125,
        0.4375,
        0.4375,
        0.3125,
        0.1875,
        0.25,
        0.3125,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.41689467430114746,
        0.3658573627471924,
        0.3657710552215576,
        0.36495399475097656,
        0.3663797378540039,
        0.3663442134857178,
        0.3673229217529297,
        0.3707590103149414,
        0.36687469482421875,
        0.3663017749786377,
        0.3672628402709961,
        0.3693108558654785,
        0.3693540096282959,
        0.36818385124206543,
        0.3686506748199463,
        0.36922407150268555,
        0.3698079586029053,
        0.3684706687927246,
        0.36908912658691406,
        0.36893272399902344,
        0.3688466548919678,
        0.36838412284851074,
        0.3701152801513672,
        0.3696596622467041,
        0.37038683891296387,
        0.36923933029174805,
        0.3700861930847168,
        0.37197065353393555,
        0.3696022033691406,
        0.3706076145172119,
        0.37000346183776855,
        0.36795687675476074,
        0.37026476860046387,
        0.3701636791229248,
        0.3716013431549072
    ]
}