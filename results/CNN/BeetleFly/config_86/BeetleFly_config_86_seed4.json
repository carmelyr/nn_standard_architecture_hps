{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2473234240535,
        "kernel_size": 6,
        "learning_rate": 0.0043122453105,
        "num_filters": 232,
        "num_layers": 3,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8877589106559753,
        0.6855667233467102,
        3.5586302280426025,
        0.12816043198108673,
        0.32448145747184753,
        0.38612058758735657,
        0.17371664941310883,
        0.06810653954744339,
        0.019011378288269043,
        0.024720152840018272,
        0.06390241533517838,
        0.05147241801023483,
        0.03091471828520298,
        0.04977919161319733,
        0.005116920452564955,
        0.020700668916106224,
        0.0026443214155733585,
        0.0023605506867170334,
        0.0018237652257084846,
        0.001801099395379424,
        0.0016445766668766737,
        0.00868379045277834,
        0.014995284378528595,
        0.0011969123734161258,
        0.009036606177687645,
        0.0023825555108487606,
        0.004485434386879206,
        0.0010293851373717189,
        0.002102518919855356,
        0.00041639801929704845,
        0.0007817453006282449,
        0.00020479563681874424
    ],
    "val_loss": [
        0.6909754276275635,
        0.8292712569236755,
        0.5134018659591675,
        1.6009601354599,
        4.046241283416748,
        6.258475303649902,
        7.406395435333252,
        7.502166748046875,
        6.978957176208496,
        6.182226657867432,
        5.633053779602051,
        5.883027076721191,
        6.938591003417969,
        8.136824607849121,
        9.17008113861084,
        10.212008476257324,
        10.911494255065918,
        11.571569442749023,
        12.00983715057373,
        12.290322303771973,
        12.577880859375,
        12.767717361450195,
        12.863007545471191,
        12.745406150817871,
        12.650627136230469,
        12.408164978027344,
        12.22172737121582,
        11.980117797851562,
        11.76884651184082,
        11.656250953674316,
        11.38036060333252,
        11.216224670410156,
        11.071088790893555
    ],
    "train_accuracy": [
        0.59375,
        0.625,
        0.59375,
        0.90625,
        0.96875,
        0.875,
        0.9375,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.375,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.07477617263793945,
        0.02733755111694336,
        0.017540454864501953,
        0.016379356384277344,
        0.015908002853393555,
        0.016561269760131836,
        0.02055811882019043,
        0.017362356185913086,
        0.015836000442504883,
        0.019700050354003906,
        0.018723011016845703,
        0.0285494327545166,
        0.01851177215576172,
        0.017561674118041992,
        0.017389535903930664,
        0.01964855194091797,
        0.023360490798950195,
        0.020707368850708008,
        0.019812822341918945,
        0.017117977142333984,
        0.016906023025512695,
        0.017232656478881836,
        0.01599860191345215,
        0.015685319900512695,
        0.015366554260253906,
        0.014913797378540039,
        0.015442609786987305,
        0.015717267990112305,
        0.014697790145874023,
        0.01497340202331543,
        0.015891313552856445,
        0.02256321907043457
    ]
}