{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1094612738984,
        "kernel_size": 5,
        "learning_rate": 0.0094414308661,
        "num_filters": 213,
        "num_layers": 1,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 31,
    "train_loss": [
        0.6721400022506714,
        0.724272608757019,
        0.22671188414096832,
        0.12466303259134293,
        0.12245438247919083,
        0.0945688933134079,
        0.06754755973815918,
        0.03729493170976639,
        0.02949926070868969,
        0.02989095076918602,
        0.02870536595582962,
        0.015528237447142601,
        0.015022756531834602,
        0.007641679607331753,
        0.006507691461592913,
        0.005120077636092901,
        0.005423623602837324,
        0.005824754014611244,
        0.004777371883392334,
        0.005721917375922203,
        0.0032978204544633627,
        0.002997657749801874,
        0.0021490862127393484,
        0.002562781563028693,
        0.0022391139063984156,
        0.003028417471796274,
        0.0024028585758060217,
        0.0011235473211854696,
        0.0016683844150975347,
        0.0007831678376533091,
        0.0010406611254438758
    ],
    "val_loss": [
        0.7399253249168396,
        1.4981493949890137,
        1.9140818119049072,
        2.5138559341430664,
        2.8421640396118164,
        2.880040407180786,
        2.8480281829833984,
        2.9247326850891113,
        3.1211507320404053,
        3.2991373538970947,
        3.442996025085449,
        3.5685954093933105,
        3.66420841217041,
        3.726877450942993,
        3.7767958641052246,
        3.8167266845703125,
        3.8491954803466797,
        3.8825345039367676,
        3.9197041988372803,
        3.9606385231018066,
        4.0077385902404785,
        4.052124977111816,
        4.093835830688477,
        4.129360675811768,
        4.160704612731934,
        4.192822456359863,
        4.222053527832031,
        4.250142574310303,
        4.273679733276367,
        4.293543815612793,
        4.309545993804932,
        4.321402072906494
    ],
    "train_accuracy": [
        0.59375,
        0.78125,
        0.90625,
        1.0,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.75,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.05372357368469238,
        0.05005168914794922,
        0.018173933029174805,
        0.014475822448730469,
        0.01945972442626953,
        0.016075611114501953,
        0.01897430419921875,
        0.013458728790283203,
        0.013345003128051758,
        0.01431131362915039,
        0.015401124954223633,
        0.020658016204833984,
        0.017261028289794922,
        0.014788150787353516,
        0.013277530670166016,
        0.013738632202148438,
        0.01604604721069336,
        0.01353907585144043,
        0.016096115112304688,
        0.023981571197509766,
        0.014800786972045898,
        0.014690876007080078,
        0.014751672744750977,
        0.014112710952758789,
        0.021999359130859375,
        0.014124393463134766,
        0.013921022415161133,
        0.013155698776245117,
        0.02047133445739746,
        0.013508796691894531,
        0.017292261123657227
    ]
}