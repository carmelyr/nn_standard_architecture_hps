{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1382521285016,
        "ff_dim": 622,
        "hidden_units": 115,
        "learning_rate": 0.000930904845,
        "num_heads": 4,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 8.4801146e-06
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            470,
            1
        ],
        "num_classes": 5
    },
    "epochs": 33,
    "train_loss": [
        1.7832807302474976,
        1.9810272455215454,
        1.6730300188064575,
        1.8583368062973022,
        1.5859801769256592,
        1.6020300388336182,
        1.2697064876556396,
        1.347854495048523,
        1.1016442775726318,
        1.3409078121185303,
        1.2200865745544434,
        0.9153367877006531,
        1.1406774520874023,
        1.18501615524292,
        1.1027605533599854,
        0.9854788780212402,
        0.8965865969657898,
        1.0794777870178223,
        0.7303754091262817,
        1.0156936645507812,
        0.9602664709091187,
        0.729693591594696,
        0.7144551873207092,
        0.7256601452827454,
        0.7736186981201172,
        0.8072831630706787,
        0.9244653582572937,
        0.8366702795028687,
        0.4930412173271179,
        0.7037980556488037,
        0.9926148653030396,
        0.7461727857589722,
        0.8857529163360596
    ],
    "val_loss": [
        1.6407476663589478,
        2.314971685409546,
        1.7545795440673828,
        1.5444692373275757,
        1.747307300567627,
        1.8061127662658691,
        1.744834065437317,
        1.7717984914779663,
        1.8736357688903809,
        1.6900759935379028,
        1.6600466966629028,
        1.7209054231643677,
        1.797747254371643,
        1.8255730867385864,
        1.7567338943481445,
        1.6305832862854004,
        1.6320148706436157,
        1.6519404649734497,
        1.697963833808899,
        1.7239705324172974,
        1.7544875144958496,
        1.758583903312683,
        1.7700594663619995,
        1.7947158813476562,
        1.821170687675476,
        1.8360933065414429,
        1.8367453813552856,
        1.834798812866211,
        1.8291893005371094,
        1.827520728111267,
        1.825474739074707,
        1.8226343393325806,
        1.8128033876419067,
        1.8033099174499512
    ],
    "train_accuracy": [
        0.25,
        0.0625,
        0.1875,
        0.25,
        0.25,
        0.375,
        0.375,
        0.25,
        0.5,
        0.5,
        0.4375,
        0.75,
        0.5625,
        0.375,
        0.5625,
        0.5625,
        0.625,
        0.5,
        0.75,
        0.6875,
        0.5625,
        0.6875,
        0.75,
        0.75,
        0.75,
        0.6875,
        0.625,
        0.6875,
        0.875,
        0.8125,
        0.5625,
        0.75,
        0.625
    ],
    "val_accuracy": [
        0.4166666567325592,
        0.25,
        0.25,
        0.0833333358168602,
        0.1666666716337204,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.25,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.5,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592
    ],
    "epoch_times": [
        0.2582688331604004,
        0.060831546783447266,
        0.0550081729888916,
        0.05864357948303223,
        0.06257009506225586,
        0.06046557426452637,
        0.060341835021972656,
        0.05891227722167969,
        0.05875253677368164,
        0.05675959587097168,
        0.052590131759643555,
        0.05092310905456543,
        0.05167412757873535,
        0.05115008354187012,
        0.054465532302856445,
        0.0532078742980957,
        0.05506753921508789,
        0.05634617805480957,
        0.05397367477416992,
        0.05084657669067383,
        0.051184654235839844,
        0.050139427185058594,
        0.04954791069030762,
        0.050353050231933594,
        0.04974079132080078,
        0.05437636375427246,
        0.053876399993896484,
        0.053726911544799805,
        0.05396676063537598,
        0.049388885498046875,
        0.04956698417663574,
        0.04955863952636719,
        0.047071218490600586
    ]
}