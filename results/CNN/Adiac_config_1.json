{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2101839010437,
        "kernel_size": 5,
        "learning_rate": 0.0009933958471,
        "num_filters": 112,
        "num_layers": 2,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.633863925933838,
        3.432650327682495,
        3.3362090587615967,
        3.2775676250457764,
        3.194786310195923,
        3.139798164367676,
        3.1020007133483887,
        3.069157361984253,
        3.0180463790893555,
        2.9682888984680176,
        2.9291908740997314,
        2.88169527053833,
        2.8514864444732666,
        2.818293809890747,
        2.7733476161956787
    ],
    "val_loss": [
        3.5568346977233887,
        3.4835753440856934,
        3.418827533721924,
        3.386580228805542,
        3.3407046794891357,
        3.2995660305023193,
        3.253978967666626,
        3.2348856925964355,
        3.2131552696228027,
        3.1996049880981445,
        3.177835464477539,
        3.1743762493133545,
        3.1188554763793945,
        3.101142406463623,
        3.0646798610687256,
        3.062964916229248
    ],
    "train_accuracy": [
        0.03899572789669037,
        0.08012820780277252,
        0.09294871985912323,
        0.10042735189199448,
        0.12553419172763824,
        0.13461539149284363,
        0.13835470378398895,
        0.14423076808452606,
        0.1607905924320221,
        0.1736111044883728,
        0.1875,
        0.18002136051654816,
        0.19604700803756714,
        0.2013888955116272,
        0.21207265555858612
    ],
    "val_accuracy": [
        0.03125,
        0.044871795922517776,
        0.0555555559694767,
        0.08119658380746841,
        0.07264957576990128,
        0.08974359184503555,
        0.08547008782625198,
        0.09829059988260269,
        0.11324786394834518,
        0.10897435992956161,
        0.1111111119389534,
        0.13247863948345184,
        0.10256410390138626,
        0.13247863948345184,
        0.13461539149284363,
        0.14529915153980255
    ]
}