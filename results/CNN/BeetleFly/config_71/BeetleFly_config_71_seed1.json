{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.3791936432688,
        "kernel_size": 5,
        "learning_rate": 0.0019169244138,
        "num_filters": 64,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 37,
    "train_loss": [
        0.8561728596687317,
        0.5722004771232605,
        0.6274359822273254,
        0.5206126570701599,
        0.529188871383667,
        0.571881890296936,
        0.3794468343257904,
        0.3926416039466858,
        0.4085942208766937,
        0.32347020506858826,
        0.37274667620658875,
        0.3383961617946625,
        0.29116764664649963,
        0.2447381317615509,
        0.21483510732650757,
        0.3048214912414551,
        0.17632146179676056,
        0.19275248050689697,
        0.1387617290019989,
        0.14375042915344238,
        0.17459917068481445,
        0.08346027135848999,
        0.17559927701950073,
        0.10907570272684097,
        0.09781527519226074,
        0.07767961174249649,
        0.1067851185798645,
        0.13229109346866608,
        0.09586811065673828,
        0.04729106277227402,
        0.05931803956627846,
        0.06493957340717316,
        0.05823199078440666,
        0.05598689615726471,
        0.04720061644911766,
        0.052552737295627594,
        0.08378423005342484
    ],
    "val_loss": [
        0.7320834398269653,
        0.7320820689201355,
        0.7319052219390869,
        0.7313265800476074,
        0.7308943867683411,
        0.7303022146224976,
        0.728291392326355,
        0.7281172275543213,
        0.7292386293411255,
        0.730562686920166,
        0.7329524755477905,
        0.7378581762313843,
        0.7412675619125366,
        0.7467442750930786,
        0.754973292350769,
        0.7633642554283142,
        0.7698996663093567,
        0.7720240950584412,
        0.780108630657196,
        0.7934882640838623,
        0.8114861249923706,
        0.8330593109130859,
        0.8592557907104492,
        0.8914890885353088,
        0.9260913729667664,
        0.9664593935012817,
        1.0095783472061157,
        1.0568742752075195,
        1.1142634153366089,
        1.1901527643203735,
        1.2666839361190796,
        1.3453289270401,
        1.4156116247177124,
        1.495437741279602,
        1.568671703338623,
        1.6372261047363281,
        1.6958988904953003,
        1.7566070556640625
    ],
    "train_accuracy": [
        0.46875,
        0.71875,
        0.59375,
        0.78125,
        0.6875,
        0.65625,
        0.8125,
        0.84375,
        0.84375,
        0.90625,
        0.875,
        0.875,
        0.90625,
        0.9375,
        0.96875,
        0.90625,
        0.9375,
        0.96875,
        0.96875,
        0.96875,
        0.9375,
        1.0,
        0.9375,
        0.96875,
        1.0,
        1.0,
        1.0,
        0.90625,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.09971165657043457,
        0.14192676544189453,
        0.023370742797851562,
        0.02436351776123047,
        0.02460193634033203,
        0.023877859115600586,
        0.023237943649291992,
        0.023861408233642578,
        0.023412466049194336,
        0.023955345153808594,
        0.024615049362182617,
        0.024431943893432617,
        0.023695945739746094,
        0.02376103401184082,
        0.024158716201782227,
        0.023966550827026367,
        0.028178691864013672,
        0.024778366088867188,
        0.025020360946655273,
        0.023101806640625,
        0.023053884506225586,
        0.026013612747192383,
        0.02282238006591797,
        0.02120518684387207,
        0.02485513687133789,
        0.02227163314819336,
        0.021839380264282227,
        0.022328615188598633,
        0.02229142189025879,
        0.0227968692779541,
        0.02314281463623047,
        0.02286386489868164,
        0.02185821533203125,
        0.02232646942138672,
        0.020838499069213867,
        0.02090907096862793,
        0.022431373596191406
    ]
}