{
    "hyperparameters": {
        "activation": "tanh",
        "dropout_rate": 0.1733779454086,
        "hidden_units": 49,
        "learning_rate": 0.0001208266625,
        "num_layers": 1,
        "weight_decay": 0.0080295474643
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 312,
        "val_size": 78,
        "input_shape": [
            176,
            1
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.661083936691284,
        3.547098159790039,
        3.540400743484497,
        3.6436853408813477,
        3.4802238941192627,
        3.4729156494140625,
        3.35129451751709,
        3.261291742324829,
        3.169992208480835,
        3.1896145343780518,
        3.5182571411132812,
        3.106966257095337,
        3.244720458984375,
        3.3701298236846924,
        3.201057195663452
    ],
    "val_loss": [
        3.6388731002807617,
        3.631999969482422,
        3.607680559158325,
        3.573606491088867,
        3.520958423614502,
        3.4530951976776123,
        3.3707737922668457,
        3.320672035217285,
        3.262237548828125,
        3.212540626525879,
        3.1754837036132812,
        3.1521801948547363,
        3.1258955001831055,
        3.111100196838379,
        3.088701009750366,
        3.0729267597198486
    ],
    "train_accuracy": [
        0.0416666679084301,
        0.0416666679084301,
        0.0833333358168602,
        0.0,
        0.0833333358168602,
        0.0416666679084301,
        0.0416666679084301,
        0.1666666716337204,
        0.2083333283662796,
        0.25,
        0.0833333358168602,
        0.25,
        0.0833333358168602,
        0.0833333358168602,
        0.2083333283662796
    ],
    "val_accuracy": [
        0.03125,
        0.03846153989434242,
        0.025641025975346565,
        0.03846153989434242,
        0.025641025975346565,
        0.06410256773233414,
        0.11538461595773697,
        0.1666666716337204,
        0.1538461595773697,
        0.19230769574642181,
        0.19230769574642181,
        0.1666666716337204,
        0.20512820780277252,
        0.1794871836900711,
        0.21794871985912323,
        0.1666666716337204
    ]
}