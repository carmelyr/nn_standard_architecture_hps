{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.2217601084509,
        "ff_dim": 327,
        "hidden_units": 455,
        "learning_rate": 2.84710583e-05,
        "num_heads": 6,
        "num_layers": 5,
        "pooling": "mean",
        "weight_decay": 5.14505646e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 36,
    "train_loss": [
        1.343753695487976,
        1.602537989616394,
        1.45389723777771,
        1.368330478668213,
        1.632014513015747,
        1.6868900060653687,
        1.112048625946045,
        1.393718957901001,
        1.2463444471359253,
        1.400589108467102,
        1.67106032371521,
        1.1888864040374756,
        1.3725173473358154,
        1.1410365104675293,
        1.2193268537521362,
        1.1304258108139038,
        0.9785060882568359,
        1.2785567045211792,
        1.786857008934021,
        0.7907587289810181,
        0.8770400285720825,
        0.9993434548377991,
        1.2485969066619873,
        1.0872963666915894,
        1.2150018215179443,
        1.069536566734314,
        1.273309350013733,
        0.9710938930511475,
        1.1454969644546509,
        1.3175829648971558,
        1.163109540939331,
        1.1443912982940674,
        1.0530965328216553,
        1.2147982120513916,
        1.0010535717010498,
        1.2255425453186035
    ],
    "val_loss": [
        2.9892711639404297,
        1.3144363164901733,
        1.5544549226760864,
        1.4212168455123901,
        1.306827187538147,
        1.3463714122772217,
        1.2984647750854492,
        1.409546136856079,
        1.4959115982055664,
        1.4524052143096924,
        1.4814014434814453,
        1.5712695121765137,
        1.4515650272369385,
        1.3675378561019897,
        1.375150442123413,
        1.3789297342300415,
        1.3936183452606201,
        1.4419289827346802,
        1.5920838117599487,
        1.593412160873413,
        1.5116562843322754,
        1.4747705459594727,
        1.4501734972000122,
        1.4395644664764404,
        1.4531524181365967,
        1.465023159980774,
        1.463357925415039,
        1.476780891418457,
        1.4707807302474976,
        1.4656851291656494,
        1.4461467266082764,
        1.4359856843948364,
        1.4350882768630981,
        1.4421154260635376,
        1.4571903944015503,
        1.4611316919326782,
        1.4780137538909912
    ],
    "train_accuracy": [
        0.375,
        0.3125,
        0.25,
        0.625,
        0.3125,
        0.25,
        0.5,
        0.375,
        0.5625,
        0.375,
        0.25,
        0.375,
        0.375,
        0.4375,
        0.625,
        0.625,
        0.5,
        0.4375,
        0.3125,
        0.6875,
        0.75,
        0.625,
        0.5625,
        0.5,
        0.3125,
        0.625,
        0.375,
        0.5,
        0.5625,
        0.4375,
        0.5,
        0.5625,
        0.5,
        0.625,
        0.5625,
        0.5
    ],
    "val_accuracy": [
        0.1875,
        0.4375,
        0.3125,
        0.4375,
        0.375,
        0.3125,
        0.375,
        0.375,
        0.375,
        0.375,
        0.25,
        0.3125,
        0.4375,
        0.4375,
        0.4375,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.375,
        0.4375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.5,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.4375
    ],
    "epoch_times": [
        2.19852352142334,
        2.1469593048095703,
        2.1506149768829346,
        2.1558010578155518,
        2.1531355381011963,
        2.15915846824646,
        2.1614019870758057,
        2.153473377227783,
        2.1502554416656494,
        2.1609768867492676,
        2.150017023086548,
        2.1677708625793457,
        2.162213087081909,
        2.150965929031372,
        2.1595563888549805,
        2.159569501876831,
        2.158135175704956,
        2.1574203968048096,
        2.1669070720672607,
        2.1560580730438232,
        2.160174608230591,
        2.1632254123687744,
        2.1608476638793945,
        2.1576907634735107,
        2.151813507080078,
        2.156235933303833,
        2.1604816913604736,
        2.1566083431243896,
        2.162452459335327,
        2.157259225845337,
        2.157686233520508,
        2.157524585723877,
        2.1583399772644043,
        2.1592533588409424,
        2.147179365158081,
        2.1480507850646973
    ]
}