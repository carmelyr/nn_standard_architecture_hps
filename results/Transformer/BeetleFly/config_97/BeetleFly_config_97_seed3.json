{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1683907598725,
        "ff_dim": 673,
        "hidden_units": 447,
        "learning_rate": 0.0003099832182,
        "num_heads": 4,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 8.1860333e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        1.2938053607940674,
        6.639739036560059,
        2.958977222442627,
        0.8636397123336792,
        0.797660231590271,
        1.4889492988586426,
        1.0562148094177246,
        0.7248682379722595,
        1.2215389013290405,
        0.9886455535888672,
        0.7219002842903137,
        0.7656693458557129,
        0.6894941926002502,
        0.6663199067115784,
        0.7293007373809814,
        0.8785973191261292,
        0.8518100380897522,
        0.765173614025116,
        0.7284517288208008,
        0.7775006890296936,
        0.6228935122489929,
        0.715331494808197,
        0.7688614130020142,
        0.6124902963638306,
        0.6052155494689941,
        0.7121074199676514,
        0.6615578532218933,
        0.5900158286094666,
        0.7378518581390381,
        0.6690890789031982,
        0.717410683631897,
        0.6694175004959106,
        0.632726788520813,
        0.6981601715087891
    ],
    "val_loss": [
        0.8579308390617371,
        9.728242874145508,
        3.881363868713379,
        0.8160214424133301,
        0.638559877872467,
        1.918652057647705,
        1.641903042793274,
        0.7595009803771973,
        0.6945432424545288,
        0.6621682047843933,
        0.7775139808654785,
        0.7958185076713562,
        0.7892422080039978,
        0.6964485049247742,
        0.6428958177566528,
        0.637860119342804,
        0.6651857495307922,
        0.8045317530632019,
        0.8914645910263062,
        0.8328242897987366,
        0.7001959085464478,
        0.6445943713188171,
        0.6466074585914612,
        0.6587142944335938,
        0.6962255239486694,
        0.7414018511772156,
        0.7970249652862549,
        0.8090828657150269,
        0.7894547581672668,
        0.7533376216888428,
        0.7207565307617188,
        0.701218843460083,
        0.6929517984390259,
        0.688787043094635,
        0.6899570822715759
    ],
    "train_accuracy": [
        0.46875,
        0.53125,
        0.53125,
        0.5625,
        0.53125,
        0.53125,
        0.5625,
        0.65625,
        0.4375,
        0.46875,
        0.625,
        0.53125,
        0.53125,
        0.5625,
        0.53125,
        0.4375,
        0.5625,
        0.53125,
        0.5625,
        0.5,
        0.625,
        0.6875,
        0.46875,
        0.625,
        0.71875,
        0.46875,
        0.59375,
        0.6875,
        0.5625,
        0.5625,
        0.5625,
        0.5625,
        0.65625,
        0.4375
    ],
    "val_accuracy": [
        0.75,
        0.375,
        0.375,
        0.75,
        0.75,
        0.375,
        0.375,
        0.5,
        0.625,
        0.75,
        0.375,
        0.375,
        0.375,
        0.375,
        0.625,
        0.625,
        0.5,
        0.375,
        0.375,
        0.375,
        0.5,
        0.625,
        0.625,
        0.625,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.5
    ],
    "epoch_times": [
        0.15103626251220703,
        0.14506888389587402,
        0.14381837844848633,
        0.14441227912902832,
        0.14412927627563477,
        0.14352893829345703,
        0.14387273788452148,
        0.1435098648071289,
        0.14397597312927246,
        0.14508795738220215,
        0.14460539817810059,
        0.14500856399536133,
        0.1439063549041748,
        0.14417791366577148,
        0.1430072784423828,
        0.14502382278442383,
        0.14367175102233887,
        0.143418550491333,
        0.14719557762145996,
        0.14306259155273438,
        0.14332985877990723,
        0.14428281784057617,
        0.14331316947937012,
        0.1443309783935547,
        0.14473748207092285,
        0.14511823654174805,
        0.14432406425476074,
        0.14516639709472656,
        0.14476323127746582,
        0.145538330078125,
        0.1454305648803711,
        0.1438748836517334,
        0.14565467834472656,
        0.1463456153869629
    ]
}