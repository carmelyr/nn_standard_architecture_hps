{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1089844650306,
        "kernel_size": 6,
        "learning_rate": 0.000216213952,
        "num_filters": 160,
        "num_layers": 5,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "Beef",
        "train_size": 48,
        "val_size": 12,
        "input_shape": [
            1,
            470
        ],
        "num_classes": 5
    },
    "epochs": 45,
    "train_loss": [
        1.8435367345809937,
        1.206783413887024,
        1.2260489463806152,
        1.1282516717910767,
        0.9100258350372314,
        0.8791611194610596,
        0.8112240433692932,
        0.7454710006713867,
        0.6998785138130188,
        0.6276777982711792,
        0.6034882068634033,
        0.6058489680290222,
        0.5532762408256531,
        0.49095186591148376,
        0.43616190552711487,
        0.38415923714637756,
        0.43313273787498474,
        0.30558767914772034,
        0.4536552429199219,
        0.290256142616272,
        0.28756117820739746,
        0.3215761184692383,
        0.27213358879089355,
        0.29091915488243103,
        0.20337410271167755,
        0.23926673829555511,
        0.20507436990737915,
        0.23429369926452637,
        0.2262265533208847,
        0.2004043012857437,
        0.3405017554759979,
        0.19782908260822296,
        0.21903903782367706,
        0.24288012087345123,
        0.21487344801425934,
        0.22598664462566376,
        0.3178844153881073,
        0.17178618907928467,
        0.2005220502614975,
        0.17507009208202362,
        0.1630009263753891,
        0.18298856914043427,
        0.19230258464813232,
        0.20334427058696747,
        0.17606274783611298
    ],
    "val_loss": [
        1.6150641441345215,
        1.6156607866287231,
        1.6159720420837402,
        1.6162956953048706,
        1.6166023015975952,
        1.6170506477355957,
        1.6172603368759155,
        1.6164082288742065,
        1.615407943725586,
        1.6167173385620117,
        1.6175001859664917,
        1.6152688264846802,
        1.610533595085144,
        1.6072945594787598,
        1.6000148057937622,
        1.5935792922973633,
        1.601502776145935,
        1.623372197151184,
        1.6708275079727173,
        1.7586930990219116,
        1.7966758012771606,
        1.7616022825241089,
        1.7689188718795776,
        1.8739100694656372,
        1.8924850225448608,
        1.9148083925247192,
        2.07890248298645,
        2.2772557735443115,
        2.3962299823760986,
        2.404343843460083,
        2.5445268154144287,
        2.277092695236206,
        2.111703395843506,
        2.1081788539886475,
        2.1977860927581787,
        2.274202346801758,
        2.432330369949341,
        2.1767497062683105,
        2.2546281814575195,
        2.694463014602661,
        2.4665510654449463,
        1.8648492097854614,
        1.95578134059906,
        2.255225896835327,
        2.712002992630005,
        3.6013457775115967
    ],
    "train_accuracy": [
        0.1458333283662796,
        0.5208333134651184,
        0.4583333432674408,
        0.5208333134651184,
        0.6666666865348816,
        0.5833333134651184,
        0.6458333134651184,
        0.7083333134651184,
        0.7291666865348816,
        0.7916666865348816,
        0.8333333134651184,
        0.8125,
        0.8125,
        0.8541666865348816,
        0.8541666865348816,
        0.875,
        0.875,
        0.9166666865348816,
        0.7916666865348816,
        0.9375,
        0.9375,
        0.875,
        0.875,
        0.8958333134651184,
        0.9375,
        0.9166666865348816,
        0.9375,
        0.9375,
        0.9166666865348816,
        0.9166666865348816,
        0.875,
        0.8958333134651184,
        0.8958333134651184,
        0.8958333134651184,
        0.875,
        0.9375,
        0.875,
        0.9375,
        0.8958333134651184,
        0.9375,
        0.9375,
        0.9583333134651184,
        0.9375,
        0.9375,
        0.9375
    ],
    "val_accuracy": [
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.1666666716337204,
        0.25,
        0.25,
        0.25,
        0.4166666567325592,
        0.4166666567325592,
        0.4166666567325592,
        0.25,
        0.25,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.25,
        0.25,
        0.25,
        0.5,
        0.4166666567325592,
        0.1666666716337204,
        0.25,
        0.3333333432674408,
        0.3333333432674408,
        0.4166666567325592,
        0.3333333432674408,
        0.5,
        0.4166666567325592,
        0.3333333432674408,
        0.5833333730697632,
        0.4166666567325592,
        0.5833333730697632,
        0.4166666567325592,
        0.4166666567325592,
        0.5833333730697632,
        0.5833333730697632,
        0.5,
        0.4166666567325592,
        0.3333333432674408
    ],
    "epoch_times": [
        0.10801982879638672,
        0.03147745132446289,
        0.02341604232788086,
        0.022387981414794922,
        0.0229647159576416,
        0.022974252700805664,
        0.022256851196289062,
        0.022515535354614258,
        0.025638103485107422,
        0.021605730056762695,
        0.022715091705322266,
        0.025014400482177734,
        0.02425694465637207,
        0.02582097053527832,
        0.021550893783569336,
        0.02211165428161621,
        0.02151179313659668,
        0.022050857543945312,
        0.022954225540161133,
        0.022495269775390625,
        0.021787643432617188,
        0.021607637405395508,
        0.02265167236328125,
        0.021625757217407227,
        0.022130966186523438,
        0.021168947219848633,
        0.021086931228637695,
        0.020875930786132812,
        0.020523548126220703,
        0.021206140518188477,
        0.021998167037963867,
        0.022069692611694336,
        0.022306203842163086,
        0.021286964416503906,
        0.021522045135498047,
        0.021364212036132812,
        0.021045923233032227,
        0.02158975601196289,
        0.021268844604492188,
        0.02138829231262207,
        0.021802425384521484,
        0.02071690559387207,
        0.021802902221679688,
        0.02175617218017578,
        0.02100086212158203
    ]
}