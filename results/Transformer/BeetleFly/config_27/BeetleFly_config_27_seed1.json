{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2010700786861,
        "ff_dim": 525,
        "hidden_units": 133,
        "learning_rate": 6.61386273e-05,
        "num_heads": 6,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 8.1394854e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        1.7502013444900513,
        1.2165336608886719,
        1.0068169832229614,
        0.7726486921310425,
        0.7410081028938293,
        0.7416936159133911,
        0.8185250163078308,
        0.7793864607810974,
        0.7449774742126465,
        0.7794231176376343,
        0.6471373438835144,
        0.7433033585548401,
        0.7406232953071594,
        0.712139904499054,
        0.6345984935760498,
        0.7821255326271057,
        0.6468987464904785,
        0.5717737078666687,
        0.7127187848091125,
        0.6338961124420166,
        0.8114334344863892,
        0.7526945471763611,
        0.6983336210250854,
        0.7308835983276367,
        0.6051970720291138,
        0.5407440662384033,
        0.6964383125305176,
        0.6497513055801392,
        0.6214526891708374,
        0.6922324895858765,
        0.6471758484840393,
        0.7125293612480164,
        0.6565796136856079,
        0.6579409241676331
    ],
    "val_loss": [
        2.3463053703308105,
        1.3803341388702393,
        0.7936437726020813,
        0.5952970385551453,
        0.527711808681488,
        0.5712680816650391,
        0.6030625104904175,
        0.6217355132102966,
        0.6121917963027954,
        0.5758471488952637,
        0.5427839756011963,
        0.5346297025680542,
        0.5350716710090637,
        0.534424364566803,
        0.5382397770881653,
        0.5423291325569153,
        0.5435676574707031,
        0.541718065738678,
        0.538169264793396,
        0.5344159603118896,
        0.5318869352340698,
        0.5301971435546875,
        0.5312317609786987,
        0.5327438712120056,
        0.5351967811584473,
        0.5365608334541321,
        0.5376956462860107,
        0.5387784242630005,
        0.5415741205215454,
        0.5430630445480347,
        0.5440175533294678,
        0.5456038117408752,
        0.5474086403846741,
        0.5483015775680542,
        0.5485143661499023
    ],
    "train_accuracy": [
        0.4375,
        0.4375,
        0.4375,
        0.5,
        0.5,
        0.53125,
        0.53125,
        0.53125,
        0.46875,
        0.5625,
        0.59375,
        0.59375,
        0.375,
        0.46875,
        0.5,
        0.5,
        0.59375,
        0.625,
        0.625,
        0.59375,
        0.5,
        0.53125,
        0.5625,
        0.59375,
        0.59375,
        0.75,
        0.53125,
        0.6875,
        0.65625,
        0.53125,
        0.59375,
        0.53125,
        0.59375,
        0.59375
    ],
    "val_accuracy": [
        0.25,
        0.125,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.2342827320098877,
        0.06934666633605957,
        0.06715917587280273,
        0.06799960136413574,
        0.06824922561645508,
        0.06695795059204102,
        0.06937742233276367,
        0.06872415542602539,
        0.06620955467224121,
        0.06679534912109375,
        0.06613349914550781,
        0.06717467308044434,
        0.06649613380432129,
        0.06678271293640137,
        0.06679248809814453,
        0.06707882881164551,
        0.06630778312683105,
        0.06709790229797363,
        0.06791567802429199,
        0.07027482986450195,
        0.06662440299987793,
        0.06743264198303223,
        0.06722307205200195,
        0.06600356101989746,
        0.06517672538757324,
        0.06693410873413086,
        0.06740903854370117,
        0.0661776065826416,
        0.06553292274475098,
        0.06449079513549805,
        0.06455707550048828,
        0.065338134765625,
        0.06615114212036133,
        0.06483340263366699
    ]
}