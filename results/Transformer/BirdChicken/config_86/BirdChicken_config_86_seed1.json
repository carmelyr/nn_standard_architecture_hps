{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.0010936313822,
        "ff_dim": 301,
        "hidden_units": 310,
        "learning_rate": 4.33077252e-05,
        "num_heads": 3,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 4.9994474e-06
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.8044836521148682,
        0.9894487857818604,
        0.7826947569847107,
        0.8542038202285767,
        0.8273781538009644,
        0.6793907880783081,
        0.6365995407104492,
        0.6480152010917664,
        0.6031326651573181,
        0.5945705771446228,
        0.5972023606300354,
        0.5909217000007629,
        0.5621270537376404,
        0.5572658777236938,
        0.5620049238204956,
        0.5497052669525146,
        0.5549102425575256,
        0.5443978905677795,
        0.5416949987411499,
        0.5305911302566528,
        0.5179976224899292,
        0.5189998745918274,
        0.5110076665878296,
        0.515270471572876,
        0.5047411918640137,
        0.5055609345436096,
        0.5003020167350769,
        0.500022828578949,
        0.5012452006340027,
        0.5017977952957153,
        0.4959791600704193,
        0.5022717118263245
    ],
    "val_loss": [
        1.008004069328308,
        0.7423739433288574,
        0.5271179676055908,
        0.750365138053894,
        0.7910215854644775,
        0.6291188597679138,
        0.5654789805412292,
        0.6183944344520569,
        0.6678193807601929,
        0.7174839377403259,
        0.7479769587516785,
        0.7141832709312439,
        0.6411792635917664,
        0.5791060924530029,
        0.5464842319488525,
        0.5376590490341187,
        0.5374860763549805,
        0.5498645305633545,
        0.5627256035804749,
        0.5641411542892456,
        0.5551049113273621,
        0.5498812198638916,
        0.5467114448547363,
        0.5468534231185913,
        0.549146294593811,
        0.5530344247817993,
        0.5580511093139648,
        0.5606796741485596,
        0.562764585018158,
        0.5640502572059631,
        0.5640237331390381,
        0.5626177787780762,
        0.5594788789749146
    ],
    "train_accuracy": [
        0.5,
        0.5625,
        0.53125,
        0.5625,
        0.5625,
        0.53125,
        0.53125,
        0.53125,
        0.6875,
        0.6875,
        0.6875,
        0.65625,
        0.65625,
        0.75,
        0.75,
        0.78125,
        0.78125,
        0.78125,
        0.78125,
        0.8125,
        0.71875,
        0.75,
        0.78125,
        0.78125,
        0.8125,
        0.78125,
        0.78125,
        0.75,
        0.75,
        0.71875,
        0.71875,
        0.71875
    ],
    "val_accuracy": [
        0.25,
        0.625,
        0.75,
        0.5,
        0.375,
        0.75,
        0.75,
        0.625,
        0.5,
        0.5,
        0.375,
        0.375,
        0.75,
        0.625,
        0.75,
        0.75,
        0.75,
        0.875,
        0.75,
        0.75,
        0.875,
        0.875,
        0.75,
        0.75,
        0.75,
        0.75,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875,
        0.875
    ],
    "epoch_times": [
        0.17503595352172852,
        0.13345932960510254,
        0.13284969329833984,
        0.1306614875793457,
        0.13222885131835938,
        0.13407254219055176,
        0.1328737735748291,
        0.1340188980102539,
        0.13183283805847168,
        0.13510394096374512,
        0.13283419609069824,
        0.1345198154449463,
        0.13638830184936523,
        0.1323871612548828,
        0.13392424583435059,
        0.13452816009521484,
        0.13263654708862305,
        0.1331496238708496,
        0.13320565223693848,
        0.13295507431030273,
        0.13503026962280273,
        0.13304424285888672,
        0.13442039489746094,
        0.13454556465148926,
        0.13273906707763672,
        0.13444924354553223,
        0.13378047943115234,
        0.13420963287353516,
        0.13309717178344727,
        0.1330876350402832,
        0.1353003978729248,
        0.13330626487731934
    ]
}