{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1461233295313,
        "ff_dim": 275,
        "hidden_units": 96,
        "learning_rate": 0.0008371103943,
        "num_heads": 5,
        "num_layers": 2,
        "pooling": "mean",
        "weight_decay": 5.42662206e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 33,
    "train_loss": [
        1.8052411079406738,
        1.7031316757202148,
        1.5248233079910278,
        1.627331256866455,
        1.074745535850525,
        1.1439476013183594,
        1.358114242553711,
        1.174186110496521,
        1.6662465333938599,
        1.093218445777893,
        1.0142124891281128,
        1.0204604864120483,
        0.8908015489578247,
        1.074009656906128,
        0.9081287384033203,
        1.0352940559387207,
        1.1269499063491821,
        0.6682061553001404,
        0.687109649181366,
        0.8394854664802551,
        0.4933342933654785,
        0.703439474105835,
        0.733518123626709,
        0.8313998579978943,
        0.8513607382774353,
        0.7299261689186096,
        0.5524144768714905,
        0.6181166172027588,
        0.7682902812957764,
        0.682776153087616,
        0.7690152525901794,
        0.6881077289581299,
        0.6792356967926025
    ],
    "val_loss": [
        1.6334760189056396,
        1.4423012733459473,
        1.9748574495315552,
        1.329469919204712,
        1.5184885263442993,
        1.6984442472457886,
        1.4641773700714111,
        1.445156455039978,
        1.5155425071716309,
        1.5616257190704346,
        1.5835508108139038,
        1.5114306211471558,
        1.5777816772460938,
        1.7530109882354736,
        1.9008634090423584,
        1.8282355070114136,
        1.8386691808700562,
        1.8674006462097168,
        2.000049352645874,
        2.0563149452209473,
        2.0575599670410156,
        1.97340726852417,
        2.01908802986145,
        2.0733652114868164,
        2.1041226387023926,
        2.0730230808258057,
        2.034111261367798,
        2.0070228576660156,
        2.032247543334961,
        2.085143566131592,
        2.1273763179779053,
        2.1571269035339355,
        2.160524845123291,
        2.162135601043701
    ],
    "train_accuracy": [
        0.25,
        0.3125,
        0.1875,
        0.25,
        0.5625,
        0.375,
        0.4375,
        0.4375,
        0.3125,
        0.4375,
        0.5,
        0.625,
        0.5625,
        0.4375,
        0.5625,
        0.5625,
        0.5,
        0.875,
        0.8125,
        0.75,
        0.875,
        0.8125,
        0.6875,
        0.625,
        0.625,
        0.75,
        0.875,
        0.8125,
        0.5625,
        0.75,
        0.625,
        0.625,
        0.6875
    ],
    "val_accuracy": [
        0.375,
        0.3125,
        0.0625,
        0.4375,
        0.25,
        0.1875,
        0.375,
        0.375,
        0.3125,
        0.3125,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.5,
        0.4375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375
    ],
    "epoch_times": [
        0.27563977241516113,
        0.22761774063110352,
        0.23344945907592773,
        0.23206210136413574,
        0.23051023483276367,
        0.23231816291809082,
        0.23710012435913086,
        0.22896289825439453,
        0.22597765922546387,
        0.22626471519470215,
        0.2276158332824707,
        0.22831058502197266,
        0.2332763671875,
        0.22953343391418457,
        0.22693824768066406,
        0.2362818717956543,
        0.22781109809875488,
        0.22685718536376953,
        0.22644472122192383,
        0.22599482536315918,
        0.23476862907409668,
        0.22985601425170898,
        0.23135137557983398,
        0.23481392860412598,
        0.23976993560791016,
        0.22939300537109375,
        0.22982549667358398,
        0.22794628143310547,
        0.22951912879943848,
        0.23344182968139648,
        0.22975468635559082,
        0.22708845138549805,
        0.22605657577514648
    ]
}