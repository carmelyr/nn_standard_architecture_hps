{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1580375267873,
        "ff_dim": 459,
        "hidden_units": 358,
        "learning_rate": 2.02694669e-05,
        "num_heads": 2,
        "num_layers": 4,
        "pooling": "max",
        "weight_decay": 8.60114039e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 32,
    "train_loss": [
        2.0464928150177,
        1.6747589111328125,
        1.6355072259902954,
        1.5505834817886353,
        1.5919122695922852,
        1.8181198835372925,
        1.344822645187378,
        1.421493411064148,
        1.2860369682312012,
        1.344486951828003,
        1.39542818069458,
        1.4921438694000244,
        1.5283907651901245,
        1.1511588096618652,
        1.4224421977996826,
        1.3006449937820435,
        1.5773690938949585,
        1.162853717803955,
        1.2348402738571167,
        1.1778123378753662,
        0.931071937084198,
        1.4193434715270996,
        1.3122758865356445,
        1.5507513284683228,
        1.382932186126709,
        1.2006715536117554,
        1.6197878122329712,
        1.457309365272522,
        1.6681751012802124,
        1.5192666053771973,
        1.3010832071304321,
        1.353813648223877
    ],
    "val_loss": [
        2.0066819190979004,
        1.3730731010437012,
        1.3048007488250732,
        1.736878514289856,
        2.294668197631836,
        2.414677143096924,
        2.2116739749908447,
        1.9271481037139893,
        1.7939648628234863,
        1.7396873235702515,
        1.7126615047454834,
        1.6988085508346558,
        1.7261474132537842,
        1.7337758541107178,
        1.7193114757537842,
        1.7077250480651855,
        1.7169901132583618,
        1.7428724765777588,
        1.7494535446166992,
        1.779799222946167,
        1.7816832065582275,
        1.7773181200027466,
        1.7699720859527588,
        1.7711747884750366,
        1.7786715030670166,
        1.7818541526794434,
        1.7785706520080566,
        1.7765616178512573,
        1.7773008346557617,
        1.7803970575332642,
        1.7831884622573853,
        1.7869672775268555,
        1.7916706800460815
    ],
    "train_accuracy": [
        0.1875,
        0.25,
        0.3125,
        0.25,
        0.3125,
        0.125,
        0.375,
        0.5,
        0.4375,
        0.375,
        0.4375,
        0.4375,
        0.375,
        0.375,
        0.3125,
        0.4375,
        0.1875,
        0.5625,
        0.375,
        0.375,
        0.625,
        0.25,
        0.3125,
        0.125,
        0.3125,
        0.5625,
        0.125,
        0.5,
        0.1875,
        0.1875,
        0.25,
        0.4375
    ],
    "val_accuracy": [
        0.3125,
        0.3125,
        0.4375,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125,
        0.125
    ],
    "epoch_times": [
        1.1474878787994385,
        1.146914005279541,
        1.1452827453613281,
        1.1479840278625488,
        1.1493666172027588,
        1.1548705101013184,
        1.1504807472229004,
        1.1516237258911133,
        1.1501898765563965,
        1.1515438556671143,
        1.1512165069580078,
        1.1534459590911865,
        1.151684045791626,
        1.1500144004821777,
        1.1501893997192383,
        1.1489760875701904,
        1.1533868312835693,
        1.152143955230713,
        1.152294635772705,
        1.151205062866211,
        1.1537177562713623,
        1.1522855758666992,
        1.1524882316589355,
        1.1512465476989746,
        1.1527159214019775,
        1.1538426876068115,
        1.1530566215515137,
        1.1523594856262207,
        1.1536438465118408,
        1.152282476425171,
        1.1529655456542969,
        1.1529996395111084
    ]
}