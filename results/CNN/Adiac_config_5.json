{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1160591257181,
        "kernel_size": 4,
        "learning_rate": 0.0001077011965,
        "num_filters": 72,
        "num_layers": 2,
        "pooling": "average",
        "pooling_size": 1,
        "residual": false
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.635754108428955,
        3.4834797382354736,
        3.4049062728881836,
        3.33589506149292,
        3.3092129230499268,
        3.261719226837158,
        3.2225797176361084,
        3.179079294204712,
        3.1402807235717773,
        3.106868028640747,
        3.076586961746216,
        3.047137498855591,
        3.0107126235961914,
        3.00359845161438,
        2.9572832584381104
    ],
    "val_loss": [
        3.5669333934783936,
        3.515610933303833,
        3.471311569213867,
        3.4429073333740234,
        3.4224841594696045,
        3.4042530059814453,
        3.3850936889648438,
        3.381795883178711,
        3.362190008163452,
        3.35264253616333,
        3.3320491313934326,
        3.3333740234375,
        3.327911138534546,
        3.318967819213867,
        3.2999303340911865,
        3.2906227111816406
    ],
    "train_accuracy": [
        0.03739316388964653,
        0.05982905998826027,
        0.07478632777929306,
        0.08867521584033966,
        0.10042735189199448,
        0.10630341619253159,
        0.11965811997652054,
        0.1367521435022354,
        0.14957265555858612,
        0.15010683238506317,
        0.15705128014087677,
        0.16292734444141388,
        0.1805555522441864,
        0.18536324799060822,
        0.19871795177459717
    ],
    "val_accuracy": [
        0.015625,
        0.049145299941301346,
        0.044871795922517776,
        0.049145299941301346,
        0.05128205195069313,
        0.061965811997652054,
        0.061965811997652054,
        0.08547008782625198,
        0.07051282376050949,
        0.0833333358168602,
        0.08119658380746841,
        0.08547008782625198,
        0.09615384787321091,
        0.09401709586381912,
        0.08974359184503555,
        0.09401709586381912
    ]
}