{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.1636708476067,
        "ff_dim": 274,
        "hidden_units": 163,
        "learning_rate": 1.61686888e-05,
        "num_heads": 7,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 5.4546884e-06
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 34,
    "train_loss": [
        1.5084508657455444,
        1.186006784439087,
        1.3034603595733643,
        0.8542805910110474,
        1.051877737045288,
        0.7088444828987122,
        0.7305558919906616,
        0.8026043772697449,
        0.7661024332046509,
        0.6706855893135071,
        0.8050345182418823,
        0.8916676044464111,
        0.89128577709198,
        0.8948643803596497,
        0.7671612501144409,
        0.7563535571098328,
        0.6606835126876831,
        0.7287598848342896,
        0.6552115678787231,
        0.7869174480438232,
        0.7085487842559814,
        0.7541937828063965,
        0.8932225108146667,
        0.6378965973854065,
        0.6628111600875854,
        0.8687760233879089,
        0.7989211678504944,
        0.6920135617256165,
        0.6369937062263489,
        0.797553539276123,
        0.7014350295066833,
        0.6981566548347473,
        0.7547693848609924,
        0.7066375017166138
    ],
    "val_loss": [
        0.9676083326339722,
        0.8405033946037292,
        0.7386822700500488,
        0.6703580617904663,
        0.6433053612709045,
        0.6614494323730469,
        0.718732476234436,
        0.7977861762046814,
        0.8678079843521118,
        0.911920428276062,
        0.9247952103614807,
        0.9196583032608032,
        0.9045401215553284,
        0.8819988965988159,
        0.8578519225120544,
        0.8318072557449341,
        0.8045334815979004,
        0.7901848554611206,
        0.7751794457435608,
        0.7629066109657288,
        0.7508506178855896,
        0.7391870617866516,
        0.7302488684654236,
        0.7268232703208923,
        0.7235478162765503,
        0.7209050059318542,
        0.7190147638320923,
        0.7174710631370544,
        0.7166616320610046,
        0.7167364358901978,
        0.716892659664154,
        0.7172197103500366,
        0.7178232073783875,
        0.7186652421951294,
        0.7195808291435242
    ],
    "train_accuracy": [
        0.46875,
        0.5,
        0.53125,
        0.4375,
        0.34375,
        0.5,
        0.53125,
        0.5,
        0.46875,
        0.5625,
        0.5,
        0.5625,
        0.40625,
        0.5625,
        0.53125,
        0.53125,
        0.53125,
        0.53125,
        0.65625,
        0.5625,
        0.625,
        0.5,
        0.40625,
        0.65625,
        0.5625,
        0.375,
        0.53125,
        0.53125,
        0.6875,
        0.40625,
        0.5625,
        0.53125,
        0.5,
        0.625
    ],
    "val_accuracy": [
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.11197733879089355,
        0.05710268020629883,
        0.05785346031188965,
        0.05286383628845215,
        0.05674028396606445,
        0.05536913871765137,
        0.0536649227142334,
        0.05424904823303223,
        0.05218791961669922,
        0.0511014461517334,
        0.05225348472595215,
        0.051224708557128906,
        0.05106091499328613,
        0.05164051055908203,
        0.051911354064941406,
        0.05097675323486328,
        0.052930593490600586,
        0.052124738693237305,
        0.051282405853271484,
        0.05129718780517578,
        0.05133199691772461,
        0.051131248474121094,
        0.05112314224243164,
        0.05106759071350098,
        0.05153012275695801,
        0.051048994064331055,
        0.05151796340942383,
        0.05108809471130371,
        0.05117368698120117,
        0.05116581916809082,
        0.050560951232910156,
        0.05018973350524902,
        0.05171918869018555,
        0.05064129829406738
    ]
}