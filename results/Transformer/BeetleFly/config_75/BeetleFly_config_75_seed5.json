{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.085929710744,
        "ff_dim": 588,
        "hidden_units": 222,
        "learning_rate": 0.0001061877299,
        "num_heads": 3,
        "num_layers": 2,
        "pooling": "mean",
        "weight_decay": 1.93873466e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 33,
    "train_loss": [
        1.274336576461792,
        0.9333623051643372,
        0.7249922752380371,
        0.8401957154273987,
        0.8605853319168091,
        0.891564130783081,
        0.842146098613739,
        0.8603559136390686,
        0.804577112197876,
        0.6808737516403198,
        0.7001782059669495,
        0.6381873488426208,
        0.7766947150230408,
        0.5315051674842834,
        0.6713560819625854,
        0.682512640953064,
        0.6362340450286865,
        0.5809641480445862,
        0.6052587032318115,
        0.6528274416923523,
        0.5685332417488098,
        0.674262285232544,
        0.6803374886512756,
        0.5535123348236084,
        0.6948795914649963,
        0.6177858114242554,
        0.6980833411216736,
        0.6558210253715515,
        0.6102545261383057,
        0.6361975073814392,
        0.6551475524902344,
        0.5639897584915161,
        0.6616879105567932
    ],
    "val_loss": [
        1.3293983936309814,
        1.0366542339324951,
        0.7070363759994507,
        0.6089714765548706,
        0.6815809011459351,
        0.7657183408737183,
        0.9048200249671936,
        1.06984281539917,
        1.029435157775879,
        0.8639764189720154,
        0.777647078037262,
        0.7178902626037598,
        0.6668056845664978,
        0.6445362567901611,
        0.6471318602561951,
        0.6598131656646729,
        0.6693862080574036,
        0.6693137288093567,
        0.6719805002212524,
        0.6798515319824219,
        0.679398775100708,
        0.6648772954940796,
        0.6586764454841614,
        0.6539231538772583,
        0.647439181804657,
        0.6427410244941711,
        0.6402143239974976,
        0.6405168771743774,
        0.6419610977172852,
        0.6445252895355225,
        0.646619439125061,
        0.6491844654083252,
        0.6518975496292114,
        0.6547962427139282
    ],
    "train_accuracy": [
        0.46875,
        0.4375,
        0.5,
        0.53125,
        0.5625,
        0.53125,
        0.53125,
        0.5625,
        0.5625,
        0.625,
        0.6875,
        0.5625,
        0.4375,
        0.75,
        0.6875,
        0.53125,
        0.5625,
        0.6875,
        0.71875,
        0.65625,
        0.71875,
        0.53125,
        0.65625,
        0.78125,
        0.5,
        0.625,
        0.5625,
        0.53125,
        0.625,
        0.625,
        0.625,
        0.65625,
        0.5625
    ],
    "val_accuracy": [
        0.5,
        0.5,
        0.375,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625,
        0.625,
        0.625,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.625
    ],
    "epoch_times": [
        0.07514715194702148,
        0.040612220764160156,
        0.03553199768066406,
        0.03559994697570801,
        0.0363001823425293,
        0.039098262786865234,
        0.03736996650695801,
        0.03870201110839844,
        0.03624367713928223,
        0.03756904602050781,
        0.03986954689025879,
        0.03937411308288574,
        0.03751349449157715,
        0.03570699691772461,
        0.035856008529663086,
        0.037687063217163086,
        0.03684425354003906,
        0.03658151626586914,
        0.038869380950927734,
        0.037580251693725586,
        0.03741884231567383,
        0.0393524169921875,
        0.04021048545837402,
        0.04021596908569336,
        0.036672353744506836,
        0.037760019302368164,
        0.03738999366760254,
        0.03856039047241211,
        0.03853201866149902,
        0.039031982421875,
        0.03684687614440918,
        0.036900997161865234,
        0.03936505317687988
    ]
}