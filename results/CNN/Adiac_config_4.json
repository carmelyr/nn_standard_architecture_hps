{
    "hyperparameters": {
        "activation": "tanh",
        "dropout_rate": 0.3992928270495,
        "kernel_size": 3,
        "learning_rate": 0.0012033252542,
        "num_filters": 145,
        "num_layers": 1,
        "pooling": "max",
        "pooling_size": 1,
        "residual": false
    },
    "dataset_stats": {
        "name": "Adiac",
        "train_size": 1872,
        "val_size": 468,
        "input_shape": [
            1,
            176
        ],
        "num_classes": 37
    },
    "epochs": 15,
    "train_loss": [
        3.6780428886413574,
        3.4885921478271484,
        3.38974928855896,
        3.3475635051727295,
        3.3233401775360107,
        3.2633285522460938,
        3.2156503200531006,
        3.1640803813934326,
        3.1469409465789795,
        3.127044200897217,
        3.0808486938476562,
        3.048032760620117,
        3.0162315368652344,
        2.9667835235595703,
        2.935894727706909
    ],
    "val_loss": [
        3.4713168144226074,
        3.503565549850464,
        3.4792864322662354,
        3.447800636291504,
        3.455854654312134,
        3.4170165061950684,
        3.377387762069702,
        3.379176378250122,
        3.3421733379364014,
        3.3418896198272705,
        3.3053855895996094,
        3.2718751430511475,
        3.2586441040039062,
        3.2515861988067627,
        3.255113363265991,
        3.2403922080993652
    ],
    "train_accuracy": [
        0.05395299196243286,
        0.06784188002347946,
        0.08493589609861374,
        0.08386752009391785,
        0.08814102411270142,
        0.09989316016435623,
        0.11057692021131516,
        0.11752136796712875,
        0.13247863948345184,
        0.13408119976520538,
        0.1458333283662796,
        0.1586538404226303,
        0.16025641560554504,
        0.18482905626296997,
        0.1885683834552765
    ],
    "val_accuracy": [
        0.046875,
        0.06410256773233414,
        0.0555555559694767,
        0.0683760717511177,
        0.0683760717511177,
        0.0683760717511177,
        0.07478632777929306,
        0.0833333358168602,
        0.09401709586381912,
        0.08119658380746841,
        0.09829059988260269,
        0.11324786394834518,
        0.12393162399530411,
        0.10683760792016983,
        0.11965811997652054,
        0.12820513546466827
    ]
}