{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.0437363810925,
        "kernel_size": 4,
        "learning_rate": 0.0003864861313,
        "num_filters": 66,
        "num_layers": 3,
        "pooling": "average",
        "pooling_size": 1
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 39,
    "train_loss": [
        0.6876295208930969,
        0.4247152805328369,
        0.30605897307395935,
        0.2108345925807953,
        0.14353078603744507,
        0.10230030864477158,
        0.0793766900897026,
        0.0671318992972374,
        0.04560032859444618,
        0.032929111272096634,
        0.02329634688794613,
        0.020937945693731308,
        0.013965955935418606,
        0.015139725059270859,
        0.01046009361743927,
        0.011479883454740047,
        0.006557848770171404,
        0.005133291706442833,
        0.004427850712090731,
        0.00486406497657299,
        0.005395982880145311,
        0.003928384277969599,
        0.003314058529213071,
        0.0034004964400082827,
        0.00231936015188694,
        0.002621240681037307,
        0.0019814977422356606,
        0.001845362945459783,
        0.002072612289339304,
        0.001699035638011992,
        0.0018319853115826845,
        0.0017570607597008348,
        0.0011656626593321562,
        0.0015530582750216126,
        0.0015256942715495825,
        0.0014299745671451092,
        0.00126987777184695,
        0.0010730718495324254,
        0.0009745528222993016
    ],
    "val_loss": [
        0.6951537132263184,
        0.6953976154327393,
        0.687868595123291,
        0.6776341795921326,
        0.6690713763237,
        0.6597793698310852,
        0.6508939266204834,
        0.6435984969139099,
        0.6412897706031799,
        0.6406675577163696,
        0.6478180885314941,
        0.667772650718689,
        0.7054308652877808,
        0.7587664127349854,
        0.8283203840255737,
        0.9043737053871155,
        0.9815402030944824,
        1.0603948831558228,
        1.141434907913208,
        1.2228175401687622,
        1.303153395652771,
        1.3867771625518799,
        1.4678819179534912,
        1.5453368425369263,
        1.6169477701187134,
        1.6829453706741333,
        1.746260404586792,
        1.8063206672668457,
        1.8627978563308716,
        1.9160362482070923,
        1.9662277698516846,
        2.01401948928833,
        2.062467098236084,
        2.107750177383423,
        2.1473302841186523,
        2.190014123916626,
        2.2314298152923584,
        2.268220901489258,
        2.3006842136383057,
        2.3316290378570557
    ],
    "train_accuracy": [
        0.5625,
        0.8125,
        0.84375,
        0.9375,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625,
        0.625
    ],
    "epoch_times": [
        0.19215059280395508,
        0.18157052993774414,
        0.02445244789123535,
        0.023050546646118164,
        0.02612471580505371,
        0.022453784942626953,
        0.0221710205078125,
        0.02295970916748047,
        0.02223062515258789,
        0.021484851837158203,
        0.02283787727355957,
        0.02262091636657715,
        0.021008729934692383,
        0.021590232849121094,
        0.024286508560180664,
        0.021778106689453125,
        0.021385669708251953,
        0.02357172966003418,
        0.022831439971923828,
        0.023325204849243164,
        0.025748014450073242,
        0.024231910705566406,
        0.024441242218017578,
        0.023411273956298828,
        0.023980140686035156,
        0.024371623992919922,
        0.024028778076171875,
        0.02565765380859375,
        0.025115489959716797,
        0.028066158294677734,
        0.025070905685424805,
        0.02555060386657715,
        0.02352285385131836,
        0.02324366569519043,
        0.02297234535217285,
        0.02259230613708496,
        0.023145675659179688,
        0.023552417755126953,
        0.02273106575012207
    ]
}