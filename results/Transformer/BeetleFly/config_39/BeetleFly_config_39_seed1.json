{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2793253565781,
        "ff_dim": 262,
        "hidden_units": 286,
        "learning_rate": 4.80360971e-05,
        "num_heads": 5,
        "num_layers": 4,
        "pooling": "mean",
        "weight_decay": 2.30251771e-05
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        1.0038765668869019,
        0.6699150800704956,
        0.7437965869903564,
        0.7303980588912964,
        0.7782403230667114,
        0.7099161744117737,
        0.5455960631370544,
        0.7531983852386475,
        0.5474874973297119,
        0.7658500671386719,
        0.7485828995704651,
        0.711186945438385,
        0.6212314963340759,
        0.8204636573791504,
        0.5618250966072083,
        0.6955367922782898,
        0.6486131548881531,
        0.6575475335121155,
        0.6184037327766418,
        0.6648902297019958,
        0.6870328783988953,
        0.6482256054878235,
        0.6950181126594543,
        0.6445931792259216,
        0.7437601685523987,
        0.5865904688835144,
        0.7771289944648743,
        0.6853593587875366,
        0.6669512391090393,
        0.6633548140525818,
        0.6333805918693542,
        0.6291877031326294
    ],
    "val_loss": [
        1.1994297504425049,
        0.951113760471344,
        0.801071047782898,
        0.8680181503295898,
        1.022424340248108,
        1.159407138824463,
        1.175591230392456,
        1.1259608268737793,
        1.1073329448699951,
        1.100583553314209,
        1.0950257778167725,
        1.084672451019287,
        1.0744836330413818,
        1.0718847513198853,
        1.0722904205322266,
        1.0720179080963135,
        1.0754247903823853,
        1.0755723714828491,
        1.0647274255752563,
        1.0485605001449585,
        1.0321696996688843,
        1.0285025835037231,
        1.0290676355361938,
        1.026835322380066,
        1.0210459232330322,
        1.0136770009994507,
        1.0079665184020996,
        1.003928303718567,
        0.9993359446525574,
        0.9944456815719604,
        0.9898183345794678,
        0.9872986674308777,
        0.9848690032958984
    ],
    "train_accuracy": [
        0.4375,
        0.53125,
        0.65625,
        0.59375,
        0.625,
        0.6875,
        0.71875,
        0.59375,
        0.71875,
        0.65625,
        0.65625,
        0.625,
        0.65625,
        0.625,
        0.71875,
        0.625,
        0.65625,
        0.6875,
        0.6875,
        0.5625,
        0.59375,
        0.625,
        0.625,
        0.53125,
        0.53125,
        0.6875,
        0.59375,
        0.59375,
        0.5625,
        0.75,
        0.65625,
        0.71875
    ],
    "val_accuracy": [
        0.375,
        0.375,
        0.625,
        0.75,
        0.75,
        0.625,
        0.625,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75,
        0.75
    ],
    "epoch_times": [
        0.20907855033874512,
        0.10094118118286133,
        0.09465885162353516,
        0.09543609619140625,
        0.0958099365234375,
        0.09476161003112793,
        0.09188270568847656,
        0.09387636184692383,
        0.09327173233032227,
        0.09238266944885254,
        0.09228086471557617,
        0.09343481063842773,
        0.09177446365356445,
        0.09325432777404785,
        0.09414434432983398,
        0.09402322769165039,
        0.09446072578430176,
        0.09485673904418945,
        0.09434127807617188,
        0.09407329559326172,
        0.09463930130004883,
        0.0943152904510498,
        0.09376907348632812,
        0.09493899345397949,
        0.09389853477478027,
        0.0945291519165039,
        0.09508085250854492,
        0.09471344947814941,
        0.09515213966369629,
        0.09519624710083008,
        0.09620952606201172,
        0.09563207626342773
    ]
}