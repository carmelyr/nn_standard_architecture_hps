{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.2774381294866,
        "ff_dim": 629,
        "hidden_units": 186,
        "learning_rate": 0.0001494264167,
        "num_heads": 3,
        "num_layers": 3,
        "pooling": "mean",
        "weight_decay": 8.50894394e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 34,
    "train_loss": [
        1.8273935317993164,
        1.6685458421707153,
        1.3506602048873901,
        1.6251224279403687,
        1.3661065101623535,
        1.3185744285583496,
        1.363928198814392,
        1.456165075302124,
        1.5806548595428467,
        1.2507559061050415,
        1.1078548431396484,
        0.991202712059021,
        1.0158023834228516,
        1.2314133644104004,
        1.1180357933044434,
        1.1984074115753174,
        0.9972310066223145,
        1.4406802654266357,
        1.202226996421814,
        1.012009620666504,
        1.2424967288970947,
        0.9391486644744873,
        1.2764564752578735,
        1.036464810371399,
        0.8961355090141296,
        1.0440603494644165,
        0.8969374895095825,
        1.0352853536605835,
        1.231231927871704,
        1.1850334405899048,
        1.035021185874939,
        0.9931131601333618,
        0.9171929359436035,
        0.9566041827201843
    ],
    "val_loss": [
        3.0172135829925537,
        1.3421900272369385,
        1.8288973569869995,
        1.4451816082000732,
        1.1968997716903687,
        1.329115390777588,
        1.4984467029571533,
        1.3453478813171387,
        1.2555322647094727,
        1.2693681716918945,
        1.2375212907791138,
        1.2655746936798096,
        1.2676055431365967,
        1.3481591939926147,
        1.3496990203857422,
        1.3717124462127686,
        1.2856411933898926,
        1.2707555294036865,
        1.269653081893921,
        1.3036094903945923,
        1.3033843040466309,
        1.300478219985962,
        1.3115695714950562,
        1.3069119453430176,
        1.321303367614746,
        1.3372846841812134,
        1.3595783710479736,
        1.3711053133010864,
        1.3687055110931396,
        1.3672993183135986,
        1.3597137928009033,
        1.3549373149871826,
        1.3541460037231445,
        1.3581206798553467,
        1.358180284500122
    ],
    "train_accuracy": [
        0.375,
        0.375,
        0.4375,
        0.25,
        0.375,
        0.5,
        0.3125,
        0.1875,
        0.3125,
        0.375,
        0.5,
        0.5,
        0.5,
        0.4375,
        0.3125,
        0.375,
        0.625,
        0.375,
        0.4375,
        0.4375,
        0.375,
        0.625,
        0.375,
        0.625,
        0.5625,
        0.5,
        0.625,
        0.625,
        0.375,
        0.4375,
        0.5,
        0.6875,
        0.75,
        0.625
    ],
    "val_accuracy": [
        0.125,
        0.4375,
        0.1875,
        0.1875,
        0.375,
        0.25,
        0.125,
        0.25,
        0.25,
        0.25,
        0.5,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.375,
        0.4375,
        0.5,
        0.5,
        0.5625,
        0.4375,
        0.4375,
        0.5,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375,
        0.4375
    ],
    "epoch_times": [
        0.6005983352661133,
        0.5360269546508789,
        0.5336222648620605,
        0.5334548950195312,
        0.5343589782714844,
        0.5355374813079834,
        0.5349142551422119,
        0.5350098609924316,
        0.5363900661468506,
        0.5368773937225342,
        0.5358729362487793,
        0.5374870300292969,
        0.5372898578643799,
        0.5375230312347412,
        0.5354454517364502,
        0.5375380516052246,
        0.5336215496063232,
        0.5363674163818359,
        0.5359859466552734,
        0.5375041961669922,
        0.5369198322296143,
        0.5367264747619629,
        0.5356225967407227,
        0.5394890308380127,
        0.5372281074523926,
        0.539076566696167,
        0.5378844738006592,
        0.5403728485107422,
        0.5401687622070312,
        0.53835129737854,
        0.5380575656890869,
        0.5383706092834473,
        0.5375099182128906,
        0.5388805866241455
    ]
}