{
    "hyperparameters": {
        "activation": "gelu",
        "dropout_rate": 0.1642170252408,
        "ff_dim": 576,
        "hidden_units": 164,
        "learning_rate": 8.31797856e-05,
        "num_heads": 4,
        "num_layers": 2,
        "pooling": "max",
        "weight_decay": 1.81819156e-05
    },
    "dataset_stats": {
        "name": "CinCECGTorso",
        "train_size": 64,
        "val_size": 16,
        "input_shape": [
            1639,
            1
        ],
        "num_classes": 4
    },
    "epochs": 32,
    "train_loss": [
        1.7601464986801147,
        1.48188054561615,
        1.7532609701156616,
        1.7835183143615723,
        1.3567845821380615,
        1.68537175655365,
        1.0243889093399048,
        1.5593328475952148,
        1.1564416885375977,
        1.4292346239089966,
        1.2660526037216187,
        1.4066444635391235,
        1.535828709602356,
        1.2916604280471802,
        1.8415991067886353,
        1.3456146717071533,
        0.889449954032898,
        0.9944648742675781,
        1.3152049779891968,
        1.1601476669311523,
        0.9575300812721252,
        1.3288986682891846,
        1.2100917100906372,
        1.446675419807434,
        1.3539003133773804,
        1.112336277961731,
        1.1890156269073486,
        1.4108295440673828,
        1.1308741569519043,
        1.3831342458724976,
        1.207777500152588,
        1.3161804676055908
    ],
    "val_loss": [
        2.8861167430877686,
        1.6216590404510498,
        1.3768094778060913,
        1.4197217226028442,
        1.4736204147338867,
        1.489884614944458,
        1.551232933998108,
        1.5691518783569336,
        1.5404736995697021,
        1.5058313608169556,
        1.4851891994476318,
        1.4648510217666626,
        1.4706851243972778,
        1.5029189586639404,
        1.5092045068740845,
        1.5210314989089966,
        1.5102016925811768,
        1.4975974559783936,
        1.488541603088379,
        1.4842865467071533,
        1.4937783479690552,
        1.4913690090179443,
        1.4909085035324097,
        1.4805101156234741,
        1.4694925546646118,
        1.4596145153045654,
        1.4529831409454346,
        1.4526501893997192,
        1.4541784524917603,
        1.4579434394836426,
        1.460750937461853,
        1.4625861644744873,
        1.4605408906936646
    ],
    "train_accuracy": [
        0.375,
        0.3125,
        0.25,
        0.3125,
        0.25,
        0.375,
        0.625,
        0.125,
        0.5625,
        0.4375,
        0.375,
        0.1875,
        0.25,
        0.375,
        0.125,
        0.375,
        0.5625,
        0.5625,
        0.375,
        0.5,
        0.625,
        0.4375,
        0.5625,
        0.25,
        0.4375,
        0.5625,
        0.5,
        0.375,
        0.5,
        0.1875,
        0.4375,
        0.4375
    ],
    "val_accuracy": [
        0.125,
        0.125,
        0.1875,
        0.3125,
        0.375,
        0.3125,
        0.125,
        0.1875,
        0.25,
        0.25,
        0.3125,
        0.375,
        0.375,
        0.3125,
        0.25,
        0.25,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.25,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125,
        0.3125
    ],
    "epoch_times": [
        0.42208337783813477,
        0.3784785270690918,
        0.3825392723083496,
        0.3831603527069092,
        0.380126953125,
        0.37993454933166504,
        0.37936878204345703,
        0.3825054168701172,
        0.37941718101501465,
        0.3808252811431885,
        0.382504940032959,
        0.379863977432251,
        0.38422155380249023,
        0.38395047187805176,
        0.38397765159606934,
        0.38161230087280273,
        0.38097524642944336,
        0.380603551864624,
        0.38510966300964355,
        0.3858630657196045,
        0.3838207721710205,
        0.38329315185546875,
        0.3838059902191162,
        0.38375043869018555,
        0.38334035873413086,
        0.3833329677581787,
        0.3828766345977783,
        0.38397908210754395,
        0.3818209171295166,
        0.3860769271850586,
        0.3852689266204834,
        0.38483738899230957
    ]
}