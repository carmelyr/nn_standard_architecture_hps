{
    "hyperparameters": {
        "activation": "elu",
        "dropout_rate": 0.2496015182267,
        "kernel_size": 4,
        "learning_rate": 0.0003936855102,
        "num_filters": 180,
        "num_layers": 3,
        "pooling": "max",
        "pooling_size": 2
    },
    "dataset_stats": {
        "name": "BeetleFly",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            1,
            512
        ],
        "num_classes": 2
    },
    "epochs": 32,
    "train_loss": [
        0.7813356518745422,
        0.3531131148338318,
        0.3017468750476837,
        0.24351422488689423,
        0.2542361617088318,
        0.19161178171634674,
        0.13036680221557617,
        0.11339978873729706,
        0.13313782215118408,
        0.1143612340092659,
        0.08681593835353851,
        0.08354377746582031,
        0.055972591042518616,
        0.05893274024128914,
        0.06624472886323929,
        0.06215020641684532,
        0.02553090639412403,
        0.021169913932681084,
        0.021121928468346596,
        0.017308443784713745,
        0.017659353092312813,
        0.03544718027114868,
        0.03596733510494232,
        0.048632703721523285,
        0.021879561245441437,
        0.007686966098845005,
        0.004977555014193058,
        0.010067960247397423,
        0.0066896770149469376,
        0.016987623646855354,
        0.006730168592184782,
        0.017060548067092896
    ],
    "val_loss": [
        0.6875417232513428,
        0.6721491813659668,
        0.6679403781890869,
        0.6831796169281006,
        0.6936229467391968,
        0.6912129521369934,
        0.6904042959213257,
        0.6971113681793213,
        0.6806790828704834,
        0.6737328171730042,
        0.68658447265625,
        0.7234925031661987,
        0.7616550326347351,
        0.8307834267616272,
        0.9268763065338135,
        1.00140380859375,
        0.9863786697387695,
        0.9643404483795166,
        0.944932758808136,
        0.9511793255805969,
        1.00153648853302,
        1.0904923677444458,
        1.1050019264221191,
        1.0963577032089233,
        1.2194939851760864,
        1.4084460735321045,
        1.6211355924606323,
        1.8428385257720947,
        2.0683135986328125,
        2.2781829833984375,
        2.4255735874176025,
        2.5463290214538574,
        2.5639491081237793
    ],
    "train_accuracy": [
        0.40625,
        0.84375,
        0.875,
        0.875,
        0.84375,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        0.96875,
        1.0,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        0.96875,
        1.0,
        0.96875,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "val_accuracy": [
        0.625,
        0.75,
        0.625,
        0.5,
        0.375,
        0.375,
        0.25,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.25,
        0.25,
        0.25,
        0.375,
        0.375,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375,
        0.375
    ],
    "epoch_times": [
        0.09301924705505371,
        0.17003560066223145,
        0.026448488235473633,
        0.025807857513427734,
        0.02392411231994629,
        0.02536606788635254,
        0.022912025451660156,
        0.022518396377563477,
        0.022746562957763672,
        0.02059650421142578,
        0.018018245697021484,
        0.01853632926940918,
        0.018305540084838867,
        0.018310070037841797,
        0.018599271774291992,
        0.020166397094726562,
        0.019852876663208008,
        0.020356178283691406,
        0.019829988479614258,
        0.020064592361450195,
        0.0211489200592041,
        0.022000551223754883,
        0.02308368682861328,
        0.022621870040893555,
        0.021532535552978516,
        0.02150273323059082,
        0.022116422653198242,
        0.021728515625,
        0.02190876007080078,
        0.0214231014251709,
        0.0237886905670166,
        0.024593591690063477
    ]
}