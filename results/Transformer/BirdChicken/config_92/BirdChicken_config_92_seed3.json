{
    "hyperparameters": {
        "activation": "relu",
        "dropout_rate": 0.0609877129238,
        "ff_dim": 510,
        "hidden_units": 510,
        "learning_rate": 0.0001219988639,
        "num_heads": 4,
        "num_layers": 6,
        "pooling": "mean",
        "weight_decay": 8.02798248e-05
    },
    "dataset_stats": {
        "name": "BirdChicken",
        "train_size": 32,
        "val_size": 8,
        "input_shape": [
            512,
            1
        ],
        "num_classes": 2
    },
    "epochs": 35,
    "train_loss": [
        0.8491765260696411,
        5.093350410461426,
        2.147751569747925,
        2.0468015670776367,
        1.3593525886535645,
        0.8169213533401489,
        0.7630957365036011,
        0.8105171322822571,
        0.6171061396598816,
        0.7459598183631897,
        0.760044276714325,
        0.573074460029602,
        0.7011839747428894,
        0.6541946530342102,
        0.6015579104423523,
        0.6308250427246094,
        0.5957406759262085,
        0.6136067509651184,
        0.5508056282997131,
        0.5589132905006409,
        0.5656545162200928,
        0.5316358804702759,
        0.5909608006477356,
        0.5507480502128601,
        0.5459349751472473,
        0.5431238412857056,
        0.4954005479812622,
        0.5976014733314514,
        0.5516700744628906,
        0.49326834082603455,
        0.5173043012619019,
        0.4668179750442505,
        0.4665002226829529,
        0.4983632266521454,
        0.49703505635261536
    ],
    "val_loss": [
        0.8580865859985352,
        3.1536660194396973,
        1.2204859256744385,
        2.7269721031188965,
        1.9126944541931152,
        0.6295760869979858,
        0.6821709275245667,
        1.1136788129806519,
        0.839180052280426,
        0.6432662606239319,
        0.6469521522521973,
        0.637677013874054,
        0.7900761961936951,
        0.8564600944519043,
        0.7819339036941528,
        0.6623035669326782,
        0.6409611701965332,
        0.651584804058075,
        0.6796402931213379,
        0.7425464391708374,
        0.7696627378463745,
        0.7440725564956665,
        0.6835897564888,
        0.6524973511695862,
        0.6448553800582886,
        0.650564432144165,
        0.672225832939148,
        0.6946408152580261,
        0.707668125629425,
        0.6967805027961731,
        0.6828453540802002,
        0.6757534146308899,
        0.6753255724906921,
        0.6703097820281982,
        0.6688573956489563,
        0.6676195859909058
    ],
    "train_accuracy": [
        0.375,
        0.46875,
        0.5,
        0.53125,
        0.5625,
        0.5625,
        0.5625,
        0.53125,
        0.59375,
        0.46875,
        0.5,
        0.6875,
        0.5625,
        0.59375,
        0.625,
        0.625,
        0.71875,
        0.71875,
        0.78125,
        0.75,
        0.6875,
        0.71875,
        0.6875,
        0.75,
        0.71875,
        0.75,
        0.78125,
        0.75,
        0.75,
        0.8125,
        0.75,
        0.8125,
        0.78125,
        0.8125,
        0.78125
    ],
    "val_accuracy": [
        0.375,
        0.625,
        0.75,
        0.5,
        0.375,
        0.625,
        0.75,
        0.375,
        0.375,
        0.625,
        0.625,
        0.625,
        0.625,
        0.375,
        0.5,
        0.625,
        0.5,
        0.625,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.375,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
    ],
    "epoch_times": [
        0.2563302516937256,
        0.2209007740020752,
        0.21944284439086914,
        0.21944522857666016,
        0.22007417678833008,
        0.21954774856567383,
        0.22009801864624023,
        0.21967267990112305,
        0.21951532363891602,
        0.21948504447937012,
        0.21910667419433594,
        0.21857547760009766,
        0.220109224319458,
        0.22025012969970703,
        0.22059941291809082,
        0.2200620174407959,
        0.2199387550354004,
        0.21978497505187988,
        0.22016429901123047,
        0.21931958198547363,
        0.21932339668273926,
        0.21877288818359375,
        0.21974992752075195,
        0.22097206115722656,
        0.22107696533203125,
        0.22071218490600586,
        0.21992754936218262,
        0.2227497100830078,
        0.21962761878967285,
        0.22066569328308105,
        0.21987056732177734,
        0.21929287910461426,
        0.21977448463439941,
        0.21957802772521973,
        0.2203502655029297
    ]
}